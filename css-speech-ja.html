<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8">
<title>CSS Speech Module（日本語訳）</title>

<link rel="stylesheet" href="common.css" type="text/css" />
<link rel="stylesheet" href="common-css.css" type="text/css" />

<style>

.type, .type > a {
	font-style:italic;
	color: #832;
}

dl.termdefs {
	margin-left : 2em;
}
dl.termdefs > dt {
	font-weight: normal;
}


#aural-box {
	position: relative;
	display: block;
	overflow-y: hidden;
	margin: 0;
	padding: 0;
	border: none;
	height: 20.5em;
	line-height: 1em;
	white-space: nowrap;
}
#aural-box > li {
	position: absolute;
	display: block;
	padding: 0;
	margin: 0;
}

#aural-box > li > * {
	position: absolute;
}

#aural-box > li > *:nth-child(1) {
	left: 2.5em;
	top: -0.5em;
}

#aural-box > li > *:nth-child(2) {
	top:0;
	left:0;
	border: solid black 1px;
	border-style: solid none none solid;
	width: 2em;
}

#aural-box > li > *:nth-child(3) {
	bottom:0;
	left:0;
	border: solid silver 1px;
	border-style: none none solid solid;
	width: 2em;
}

#aural-box > li > *:nth-child(4) {
	left: 2.5em;
	bottom: -0.5em;
}

</style>
<script src="common0.js" ></script>
<script src="common1.js" async></script>

<script>
Util.ready = function(){
	const source_data = {
		collectParts: Util.collectParts,
		generate: expand,
	};
	Util.switchWordsInit(source_data);
}


function expand(){
	const link_map = this.link_map;
	const class_map = {
		p: 'property',
		f: 'func',
		t: 'type', // value type
		tp: 'type',
		u: 'unit',
		vt: 'type',
		v: 'value',
		at: 'at-rule',
		pe: 'pseudo',
		P: 'production',
		css: 'css',
		e: 'element',
		sS: 'element',
		a: 'attr',
	};
	const tag_map = {
		p: 'code',
		at: 'code',
		t: 'var',
		tp: 'var',
		vt: 'var',
		css: 'code',
		pe: 'code',
		f: 'code',
		d: 'code',
		c: 'code',
		e: 'code',
		sS: 'code',
		a: 'code',
		u: 'code',
		f: 'code',
		v: 'code',
		en: 'span',
		P: 'var',
		V: 'var',
	}
	let context_prop = '';

	return this.html.replace(
		/%[\w\-~一-鿆]+|`(.+?)([$@\^])(\w*)/g,
		create_html
	);

	function create_html(match, key, indicator, klass){
if(!indicator) {//%
	return '<var>' + match.slice(1) + '</var>';
}

let text = key;
let href = '';
let classname = class_map[klass];
let tag = tag_map[klass];


switch(klass){
case 'r': // ref
	text = '[' + key + ']';
	href = '#ref-' + key;
	break;
case 'vv': 
	context_prop = '#' + key + '-';
	return '';
	break;
case 'v': 
	href = context_prop + key;
	break;
case 't': //
	href = context_prop + key;
	text = '&lt;' + key + '&gt;';
	break;
case 'tp': // property value type
	text = '&lt;‘<code class="property">' + key + '</code>’&gt;';
	klass = 'p';
	break;
case 'f': // funcdef
	text = key + '()';
	break;
case 'pe': 
	text = '::' + key;
	break;
case 'en':
	text = '<span lang="en-x-a1">' + key + '</span>';
	break;
}

if(tag) {
	text = '<' + tag + (
		classname ? ' class="' + classname + '"' : ''
	) + '>' + text + '</' + tag + '>';
}


if(indicator !== '^'){
	href = link_map[klass ? (klass + '.' + key) : key] || href;
	if(!href){
		console.log(match); // check error
		return match;
	}

	switch(indicator){
	case '$':
		text = '<a href="' + href + '">' + text + '</a>';
		break;
	case '@':
		text = '<dfn id="' + href.slice(1) + '">' + text + '</dfn>';
		break;
	}
}

return text;

	}
}

</script>


<script type="text/plain" id="_source_data">


●●options

spec_title:CSS Speech Module
spec_date:2018-07-05
trans_update:2018-02-07
source_checked:120320
spec_status:NOTE
page_state_key:CSS
original_url:https://drafts.csswg.org/css-speech-1/
		https://www.w3.org/TR/css3-speech/
		https://drafts.csswg.org/css3-speech/

ref_id_prefix:ref-
conformance:css
copyright:2018,permissive
trans_1st_pub:2013-10-30


●●original_id_map


aural-dimension:
generic-voice:
conventions:
conformance-classes:

	voice-volume-
voice-volume-silent:
voice-volume-x-soft:
voice-volume-soft:
voice-volume-medium:
voice-volume-loud:
voice-volume-x-loud:
voice-volume-decibel:

	voice-balance-
voice-balance-number:
voice-balance-left:
voice-balance-center:
voice-balance-right:
voice-balance-leftwards:
voice-balance-rightwards:

	speak-
speak-auto:
speak-never:
speak-always:

	speak-as-
speak-as-normal:
speak-as-spell-out:
speak-as-digits:
speak-as-literal-punctuation:
speak-as-no-punctuation:

	pause-before-, pause-after-
pause-time:
pause-none:
pause-x-weak:
pause-weak:
pause-medium:
pause-strong:
pause-x-strong:

	rest-before-, rest-after-
rest-time:
rest-none:
rest-x-weak:
rest-weak:
rest-medium:
rest-strong:
rest-x-strong:

	cue-before-, cue-after-
cue-uri:
cue-decibel:
cue-none:

	voice-family-
voice-family-name:
voice-family-generic-voice:
voice-family-preserve:
voice-family-age:
voice-family-gender:
voice-family-integer:
	voice-family-male:
	voice-family-female:
	voice-family-neutral:
	voice-family-child:
	voice-family-young:
	voice-family-old:

	voice-rate-
voice-rate-normal:
voice-rate-x-slow:
voice-rate-slow:
voice-rate-medium:
voice-rate-fast:
voice-rate-x-fast:
voice-rate-percentage:

	voice-pitch-, voice-range-
voice-pitch-frequency:
voice-pitch-absolute:
voice-pitch-x-low:
voice-pitch-low:
voice-pitch-medium:
voice-pitch-high:
voice-pitch-x-high:
voice-pitch-frequency:
voice-pitch-semitones:
voice-pitch-percentage:

	voice-stress-
voice-stress-normal:
voice-stress-strong:
voice-stress-moderate:
voice-stress-none:
voice-stress-reduced:

	voice-duration-
voice-duration-auto:
voice-duration-time:


●●link_map


	●prop
p.display:~CSS2VISUREN#display-prop
	~CSSDISP
p.visibility:~CSS2VISUFX#propdef-visibility
p.padding:~CSS2BOX#propdef-padding
p.border:~CSS2BOX#propdef-border
p.margin:~CSS2BOX#propdef-margin
p.font-family:~CSSFONT#propdef-font-family
p.content:~CSS22/generate.html#content
	[CSS-CONTENT-3]
p.list-style-type:~CSSWG/css-lists/#propdef-list-style-type
p.list-style-image:~CSSWG/css-lists/#propdef-list-style-image

p.cue-after:#cue-after
p.cue-before:#cue-before
p.cue:#cue
p.pause-after:#pause-after
p.pause-before:#pause-before
p.pause:#pause
p.preserve:#preserve
p.rest-after:#rest-after
p.rest-before:#rest-before
p.rest:#rest
p.silent:#silent
p.speak-as:#speak-as
p.speak:#speak
p.voice-balance:#voice-balance
p.voice-duration:#voice-duration
p.voice-family:#voice-family
p.voice-pitch:#voice-pitch
p.voice-range:#voice-range
p.voice-rate:#voice-rate
p.voice-stress:#voice-stress
p.voice-volume:#voice-volume

v.inherit:~CASCADE#valdef-all-inherit
v.initial:~CASCADE#valdef-all-initial

実数:~CSSVAL#number
整数:~CSSVAL#integer
百分率:~CSSVAL#percentage
識別子:~CSSVAL#identifier
文字列:~CSSVAL#string
次元:~CSSVAL#dimension
周波数:~CSSVAL#frequency
時間:~CSSVAL#time
~URL:~CSSVAL#url-value
	t.frequency:~CSSVAL#frequency-value
	t.time:~CSSVAL#time-value
	t.number:~CSSVAL#number-value
	t.integer:~CSSVAL#integer-value
	t.percentage:~CSSVAL#percentage-value
	t.url:~CSSVAL#url-value

	●

sS.sub:~SSML11#edef_sub
sS.audio:~SSML11#edef_audio
sS.break:~SSML11#edef_break
sS.prosody:~SSML11#edef_prosody
sS.emphasis:~SSML11#edef_emphasis
sS.say-as:~SSML11#edef_say-as
sS.voice:~SSML11#edef_voice


~pause:#pause-props
~pauseの相殺:#collapsed-pauses
~voice選定:#voice-selection
指示音:#cue-props
音声指示:#cue-props
~rest:#rest-props

聴覚~box~model:#aural-box-model
聴覚~次元:#aural-dimension
視覚~box~model:~CSS2BOX#

~SSML:#ref-SSML


●●words_table1


SSML11:http://www.w3.org/TR/speech-synthesis11/


●●words_table



	●声／音／話
SSML:
TTS:
	TTS:text-to-speech
音:sound::~
音響:sound::~
	大きさの無い音::no sound
発声-:announce::~:アナウンス
音声:audio::~:オーディオ
指示音:cue::~:キュー
音声指示:audio cue::~:オーディオキュー
聴覚:aural::~
	aurally
聴取れる:audible な::聴き取れる
	それに伴う音声節:relevant audible passages
聴感:auditory::聴覚
icon:::アイコン
環境:environment:~
聴感上の:acoustic::~
媒体:media::~:メディア
描画-:render::~
音声化-:aural に render::~
音声化:aural-rendering::~
音声化1:rendition::音声化
	具現化／具体化
	レンダリング
	~~声に出され:aloud
発話-:speak::~
発話:speech::~
	spoken
発話用:speaking::~
発話速度:speaking rate::~
速度:rate::~
読上げら:read out:読み上げら
読まれ:read され:~
合成-:synthesize::~
合成:synthesis::~
	:post-synthesis
合成器:synthesizer::~
合成的:synthetic::合成による
処理器:processor::~:プロセッサ
入力:input:~
出力:output:~

知覚-:perceive:~
	知覚し得る:perceivable
bell:::ベル
	聴き分け:discernible

聴感音量:loudness::~:ラウドネス
	強めの:-loud
出力音量:volume::~:ボリューム
peak:::ピーク
decibel:::デシベル
無音:silence::~
無音に:silent に::~
	silently
尺度:scale:~
	尺度／音階:
利得:ゲイン:gain::~
平均:average:~
mixing:::ミキシング
channel:::チャネル
	対数の::logarithmic

聴取者:listener:聴き取り者::リスナー
聴取:listening:聴き取り::リスニング
	聴き手
	聴取者から見て:relative to the listener’ position
	周囲:around listener position

背景雑音:background noise:~::バックグラウンドノイズ
	静かな:quiet な
	騒がしい:noisy な
	環境下:context


	●音質
音階:scale::~:スケール
半音:semitone::~
半音単位:semitone::~
	半音による等分平均律〜音階::equal temperament chromatic scale
dynamic-range:dynamic range::ダイナミックレンジ
clipping-threshold:::クリッピング限界
spectrum:::スペクトル
特性:characteristics::~
歪み:distortion:~
忠実さ:fidelity:~
音符:note::~:ノート
基本周波数:fundamental frequency::~
周波数:frequency::~

	●音（時間／空間／次元
三次元の:three-dimensional:~
次元:dimension:~
側面方向:lateral:~
軸:axis::~
仰角:elevation::~

分離:separation::~
分離-:separate::~
	隔てられ:separated
分布:distribution::~
信号:signal::~
圧縮-:compress:~
圧縮:compression::~
振幅:amplitude::~
増幅:amplification::~
増幅-:amplify::~
減衰-:attenuate::~
減衰:attenuation::~
波形:waveform::~
差分:offset:~
可変度:variability:~
変動範囲:variation:~
変動-:oscillate:~

遅延:delay::~:ディレイ
timing:::タイミング
	不慮のタイムラグ::unexpected lag
lag:::タイムラグ
時間的:temporal:~
時間:time:~
区間:interval:~
時区間:time interval:~
持続時間:duration::~
rest:
pause:
音高:pitch::~:ピッチ
	間／ためらい
	より音高が高い::~higher-pitched
	高い／広い:high
Hertz::Hz
kiloHertz::kHz
位相変位:phase shifting:~::フェイズシフティング

stage:::ステージ
	音響ステージ::sound stage
	音声ステージ::audio stage
		（音場は sound field）
	音響システム::sound system
surround:::サラウンド
	サラウンド音響::surround sound
角度:angle:~
方位角:azimuth:~
mono:::モノ
mono-aural:::モノラル
stereo:::ステレオ
	stereo-capable
中央:center:~::センター
	地点／点:point
	位置:position
	中央に均等化::centered equalization
空間:space:~
空間的:spatial:~
方向::direction:~
距離:distance:~

	●声／抑揚
voice:
font:::フォント
	声音／話声／人声／ボイス／人工声音／有声音
年齢:age:~
年齢層:age category:~
方言:dialect::~
	方言による差異を吸収::cater for dialectic variations
性別:gender::~
男性:male::~
中性:neutral::~
女性:female::~
少年:young boy::~
子供の:child:~
大人の:adult:~
平坦:flat:~
単調:monotonic:~
	話声
	読み綴る::spell
	読み綴る::spell out
	綴り::spellings
音素:phoneme::~
音標:phonetic::~
	音標による記法:phonetic notation
発音:pronunciation::~
発音-:pronounce::~
	発音上の:phonetic::~
調子:tone:~
抑揚:intonation::~:イントネーション
屈折:inflection::~:インフレクション
lexicon:::辞書
	発音辞書
強勢:emphasis::~
強勢-:emphasize::~
	瞬時の~~強勢:stress
	全く強勢されない::totally de-emphasized
強度:strength::~
韻律:prosodic::~
境界:boundary::~
分断:break::~
accent:::アクセント
	~accent付き:accented
	~accentなしの:unaccented
活発:animated:~


	●文字／構文／値／単位
comma:::カンマ
comment:::コメント
感嘆符:exclamation mark:~
識別子:identifier:~
整数:integer:~
実数:number:~
数字:digit:~
成分:component:~
alphabet:::アルファベット
	~alphabet式::alphabetic
略語:abbreviation:~
頭字語:acronyms:~
bullet:::ビュレット
hash:::ハッシュ
hyphen:::ハイフン
文字列:string:~
一字:letter:~
	一字ごとに:letter-by-letter／one letter at a time
文字:character:~
単位:unit:~
百分率:percentage:~
構文:syntax:~
括弧類:braces:~
約物:punctuation:~
	約物:punctuation characters
空白:whitespace:~
	空白:space
semicolon:::セミコロン
forward-slash:forward slash::スラッシュ
keyword:::キーワード
token:::トークン
text:::テキスト
stream:::ストリーム
妥当:valid:~
無効:invalid:~
値:value:~
名前:name:~
型:type:~
	度:degrees
	負の:negative
	正の:positive
精確:precise:~
精度:precision:~
資源:resource:~::リソース
比率:ratio:~
範囲:range:~
割合分:fraction:~
	4 分の 1::quarter
	二乗::squares
	2 の 12 乗根::twelfth root of two
	2 倍:twice
	ミリ秒:milliseconds
	秒:seconds
引用符:quotes:~
	引用符で括る:quote
	引用符で括られていない:unquoted
	数:number
	数値:numerical value
	数値的に:numerically

	●CSS ／木
CSS:
flow:::フロー
整形:formatting:~
URL:
絶対:absolute:~
絶対的:absolute:~
相殺-:collapse:~
相殺:collapsing:~
margin:::マージン
class:::クラス
canvas:::キャンバス
文書:document:~
子:child:~
子孫:descendant:~
先祖:ancestor:~
親:parent:~
木:tree:~::ツリー
要素:element:~
根:root:~::ルート
部分木:subtree:~::部分ツリー
同胞:sibling:~
深さ:depth:~
階層的:hierarchical:~

属性:attribute:~
box:::ボックス
基底線:base line:~

算出-:compute:~
算出値:computed value:~
使用値:used value:~
指定値:specified value:~
継承-:inherit:~
継承:inheritance:~
継承値:inherited value:~
初期:initial:~
初期値:initial value:~
	適用対象:applies to
内容:content:~
文脈:context:~
counter:::カウンタ

選択子:selector:~::セレクタ
prop:property::プロパティ
疑似要素:pseudo-element:~
規則:rule:~::ルール
略式:shorthand:~
style:::スタイル
stylesheet:style sheet::スタイルシート
視覚:visual:~
視覚的:visual:~
関数:function:~

	●仕様
目標:goal:~
能:ability:~
実際:actual:~
実際の:actual な:~
類似する::analogous な:~
付録:appendix:~
適切:appropriate:~
技術的:technical:~
技法:technique:~
通例的:usual:~
代表的:typical:~
概して:typical に:~
互換性:compatibility:~
後方互換:backwards compatible:~
共通的な:common に:よくある
	共通的な〜でない::uncommon
共通的に:common に:よく
将来:future:~
将来の:future:~
将来的:future:~
一般:general:~
方式:manner:~
統一的:universal:~
	〜そうにない:unlikely
利便性:usability:~
	利便性:increasing usability
有用:useful:~
仕方:way:~
UA:user agent:UA
algo:algorithm::アルゴリズム
自動的:automatic:~
可用:available:~
背景:background:~
情報:information:~
参考:informative:~
基本的:basic:~
最良:best:~
能力:capabilities:~
	〜能力がある:-capable
	能力がある:capable of
機能性:functionality:~

概念的:conceptual:~
	具体的:concrete
条文:conditional statements:~
条件付き:conditional:~
効果:effect:~
有効:effective:~
実質的:effective:~
正確:exact:~
	きっかり:exactly
	例:example
明示的:explicit:~
	事実，::in fact
要因:factor:~
特色機能:feature:~
	featuring
	著名な:famous
柔軟:flexible:~
違法:illegal:~
	合法的に::legitimately
暗黙の:implied:~
一貫性:consistency:~
	一貫性が損なわれ:inconsistencies:~
業界:industry-wide:~
自然:natural:~
仕組み:mechanism:~
	必要に応じて::wherever necessary
通常:normal:~
通常時:normal:~
異論:objections:~
option:::オプション
原則:principle:~
system:::システム
慣行:convention:~
custom:::カスタム
	~custom化:customization
	状況:circumstances
	状況:situations
局面:scenario:~
見本:sample:~
意味論:semantics:~
強制的:forceful:~
公式的:formal:~
単純:simple:~
単純化-:simplify:~
	似た／類似する:similar
精巧:sophisticated:~
特別:special:~
特有の:specific な:~
特有:specific:~
特定の:specific な:~
	特に:specifically
仕様:spec:~
特殊性:specificities:~
標準:standard:~
標準的:standard:~
	標準~化:standardize
詳細度合い:verbosity:~
冗長さ:redundancies:~
model:::モデル
現代的:modern:~
module:::モジュール
定例の:regular な:~
直に:direct に:~
図式:diagram:~
論題:topic:~
草案:draft:~
厳密に:strict に:~
複雑:complex:~
準拠-:comply:~
	準拠する:compliant
現実的:realistic:~
用語:term:~
	明らか:obvious:~
	〜とは対照的に:opposed
	逆に:opposite
	逆に，:conversely
	~~選択肢:list of possibilities
	可能性:possibility
	可能:possible
	可能な限り:as possible
	生じ得る:any potential
	備える:prepare
	相応の:pretty
	を想定する:we refer to 〜
	概ね:roughly
	排他的:mutually-exclusive
	不一致:discrepancies
	そのため、:consequently
	ある程度の:certain degree of
	例示-:demonstrate
	にもかかわらず:despite
	そのままの形:as-is
	傾向にある:tend
	従って，:therefore
	何故なら:because
	十分:enough
	〜し易く:ease
	稀:rare
	ほどよく:reasonable 〜 well／reasonably
	具体例として:For instance
	適した:suitable
	支持を受けて:in favor of
	たまたま:happen to
	示す:illustrates
	必要がある:needed
	場合によっては:possibly
	であろう:seems
	:although

	●仕様（動詞
support:::サポート
	未~supportの::unsupported
定義-:define:~
	定義-済みの:predefined
	きちんと定義された:well-defined
定義:definition:~
依存-:depend:~
	〜に依存する:-dependent
独立:independent:~
非推奨に:deprecate:~
導出-:derive:~
	述べら:describe さ:~
	説明:description:~
設計-:design:~
設計:design:~
指名され:designate:指定を受け
		なり得るものと:potentially
指定-:specify:~
詳細な:detailed:~
決定-:determine:~
付帯-:accompany:~
適用:application:~
適用-:apply:~
取組まれ:address され:取り組まれ
影響-:affect:~
理解-:understand:~
利用者:user:~::ユーザ
	利用-:use
version:::バージョン
選好:preference:~
選好-:prefer:~
欲され:desire され:~
	〜たい:wish
求めら:want さ:~
作者:author:~
著作-:author:~
著作:authoring:~
避ける:avoid する:~
	ないようにする:avoid
挙動する:behave する:ふるまう
挙動:behavior::ふるまい
適合:conforming:~
確保-:ensure:~
予期-:expect:~
fall-back:fall back::フォールバック
取扱い:handling:取り扱い
実装-:implement:~
実装:implementation:~
実装側:implementers:~
向上-:improve:~
指示-:indicate:~
意図-:intend:~
干渉-:interfere:~
解釈:interpretation:~
制限:limitation:~
制限-:limit:~
意味:meaning:~
意味-:mean:~
有意義:meaningful:~
記法:notation:~
許容-:allow:~
許可-:permit:~
供-:provide:~
供さな:provide しな:~
提起-:raise:~
認識-:recognize:~
	認識し得る:recognizable
推奨-:recommend:~
抑制-:reduce:~
関係性:relationship:~
関係度:relationship:~
関係-:relate:~
相関-:relate:~
相関:relation:~
配慮:considerations:~
見なさ:consider さ:~
寄与-:contribute:~
制御-:control:~
制御:control:~
判定基準:criteria:~
明確化-:clarify:~
明確さ:clarity:~
視野:scope:~
	視野~外:out-of-scope
改訂:revision:~
意味論:semantics:~
	模倣する::emulate
可能化-:enable:~
	できるようにする:enable
要求-:require:~
要件:requirements:~
要求:requirements:~
	要する:require
勧告候補:Candidate Recommendation:~
編集者草案:Editor’s Draft:~
risk:::リスク
導入-:introduce:~
協同:cooperation:~
手引き:guide:~
開発-:develope:~
受容-:accept:~

	扱われ:treated
	書かれた時点::At the time of writing
	記し-::written
	〜とする:assume
	備えて
		抵触する::breaking
	表される／表す:express
	知らせる:know about
	知識を持ち得る:knowledgeable
	としても知られている:known as
	もたらす:lead to
	制作
	外れる:deviate
	から決まる:as dictated by
	作り直し:re-work
	〜に則って:according to
	織り込む:take into account
	-:achievable
	得る:achieve
	得られ:achieved
	試みる:try
	容認し得る:tolerable
	伝える:inform:~
	〜に基づいて:based
	上手く扱う:manage
	満たす:meet
	留意すべき:notable:~
	注:note
	概要:outlines
	〜しないようにする:prevent
	より精緻化-:refine the level of precision
	関わらず:regardless
	〜についての:with regards to
	〜に関係なく:irrespective:~
	ままにされ:remain
	〜に留意:reminder…
	緩められ:loose

	●未分類（動詞
近似的:approximate:~
	およそ／約:approximately
	ある程度の誤差と引き換えに:albeit at the cost of a certain degree of approximation
作動中:active::~:アクティブ
作動中の:active::~:アクティブな
	作動中でない~~状態::deactivated
追加-:add:~
追加の:additional:~
	加えて，:addition
	加えて、:additionally
加算-:add:~
減算:subtract:~

加法的:additive:~
	合算される:take additively
	:combined additively
連接-:adjoin:~
連接:adjoining:~
調整-:adjust:~
結付けら:associate さ:結び付けら
	結び付け:associations
計算-:calculate:~
	再~計算:re-calculate
計算:calculation:~
変化:change:~
変更-:change:~
変更点:changes:~
cascade:::カスケード
切詰めら:clamp さ:切り詰めら
切上げて:clamp して:切り上げて
切上げら:clamp さ:切り上げら
切下げて:clamp して:切り下げて

clip:::クリップ
組合わせ:combination:組み合わせ
組合わさ:combine さ:組み合わさ
	〜から（鳴らされ）::coming from
比較-:compare:~
	比較-時:comparing
	比較的:comparably
	強めの:-loud
優先度:priority:~
	優先度~付きの:prioritized
	優先される:takes precedence

接続-:connect:~
消費-:consume:~
変換:conversion:~
変換-:convert:~
	~~伝達:convey:~
作成-:create:~
作成者:creator:~
宣言-:declare:~
宣言:declaration:~
宣言的:declarative:~
減分:decrement:~
	-:monotonically non-decreasing
増分:increment:~
	増大／拡大::increases
	non-decreasing (conceptually increasing)
専用の:dedicated な:~
	区切りの:-separated
	区切られ:delimited
	区別する:disambiguate
downgrade:::ダウングレード
列挙:enumeration:~
	ごとに変わり得る:varies across
無視-:ignore:~
	取り込む:importing
access:::アクセス
	~access不能:inaccessible

挿入-:insert:~
対話:interaction:やりとり
対話-:interact:やりとり
操作-:manipulate:~
対応付けら:map さ:~
対応付け:mapping:~
marker:::マーカ
	付与され:marked
markup:::マークアップ
照合:matching:~
合致-:match:~
	該当する:match
再生-:play:~
再生:playback:~
	再生-時:playing
生成-:generate:~
	生成-済み:pre-generated
生産-:produce:~
処理-:process:~
処理:processing:~
前処理:preprocessing:~
	後処理:post-
共存-:coexist:~
存在-:exist:~
既存の:existing:~
	~~存在:presence
録音:recording:~
録音-:record:~
	録音-済みの::pre-recorded
	予め録音-済みの::previously recorded
参照-:reference:~
	〜としても知られる::referred-to
置換-:replace:~
挿入-:insert:~
表現-:represent:~
予約-:reserve:~
	予約-済み:reserved
解決-:resolve:~
制約-:restrict:~
	返す::return

被選択:selected:選択
選択-:select:~
選択:selection:~
選定-:select:~
選定:selection:~
	併用:used together with
誘発-:trigger:~
更新-:update:~
併合-:merge:~
移動-:move:~
入子に:nest:~
付番:numbering:~
付番方式:numbering scheme:~
省略-:omit:~
	順序:order:~
上書き:override:~
	複数の:duplicated or different
埋込みの:embed された
escape:::エスケープ

	等しい:equal
等式:equation:~
等価性:equivalence:~
等価:equivalent:~
評価-:evaluate:~
評価:evaluation:~
	再~評価-:re-evaluate
	再~評価:re-evaluation
固定:fixed:~
	固定的な:fixed
改めら:alter さ:~
相違:difference:~
	異なる:different
	種々の:different

体験-:experience:~
呈示:presentation:~
開始-:start:~
	読み取り:reading
	読み取る／書き出す:reads and/or writes
	与えられ:given
	習得:learning
	捉えられる／眺めて:seen
	真上から眺めて:seen from the top
	伴われる:pertaining
	揃え:alignment
	緩和-:alleviate:~
	割り当てられ:allocate され:~
	選ばれ:chosen
	現れる:appear
	配置:arrangement
	呼ばれ:called
	含む:contain
	対応-:correspond
	対象外:not covered
	生じる:occur
	行われる:take place
	渡され:passed
	渡す／:~passing
	含める:include
	含められ:included
	含め:including
	欠いて:lack
	挙げられ:listed
	在る:located at
	-:performed
	補われ:complemented
	前に〜が補われる:prefixed
	量る:quantified as
	囲まれた:surrounded
	切り替え時:switching
	占める:takes up
	一部になる:take part
	指導:teaching
	変わり得る:may~vary
	種々の:varying
	見つからない:missing
	-:excluding
	〜からなる:consists

	●未分類
HTML:
	HTML:(x)HTML5
navi:navigation::ナビ
援助:aids:~
相対的:relative:~
相対:relative:~
	比して::relative to
	相対的に::relatively
種別:type:~
level:::レベル
glyph:::グリフ
graphic:::グラフィック
	graphic的:graphical
hint:::ヒント情報
index:::インデックス
instance:::インスタンス
interface:::インタフェース
list:::リスト
item:::アイテム
mode:::モード
digital:::デジタル
	~digital化:digitize
engine:::エンジン
screen-reader:screen reader::スクリーンリーダ

代替:alternative:~
層:layer:~
既定:default:~::デフォルト
動的:dynamic:~
逐語的:literal:~

無限:infinity:~
時計回りの:clockwise:~
反時計回りの:counter-clockwise:~
	下限／上限:minimum and maximum boundaries
	脱落:drop
	より速く:faster
深層:深い層
	深層へ伝わる:get carried down
	近い:close
	近く:close to
	近く:closely
	近付く::be closer to
	隣り合う:consecutive
結合-:combine::~
	継ぎ目無く:seamless に
	よりゆっくり:slower
	最終結果:end-result
基底:base:~

完全:complete:~

code:::コード
codec:::コーデック
file:::ファイル
形式:format::~
内在的:intrinsic:~
	intrinsically
layout:::レイアウト
調節-:calibrate:~
	-calibrated
環境設定-:configure:~
	言語:language
自然言語:language°:~
French::フランス語
English::英語
	English language
外国語:foreign:~
	人:people
個人:person:~
個人的:personal:~
個性:personality:~
物理的:physical:~
身体能力:physical ability:~
source:::ソース
monologue:::モノローグ
朗読:declamation:~
機器:device:~
headphone:::ヘッドフォン
	a pair of headphones
speaker:::スピーカ
混成:mixed:~
混合-:mix:~
修飾:modifier:~
設定群:settings:~
設定-:set:~
再設定-:reset:~
段:step:~
	段階:step:~
構造的:structural:構造
構造:structure:~
変種:variant:~
強い:strong な:~
強く:strong に:~
	stronger／strongest
	累積され:combined multiplicatively

文化的:cultural:~
生物学的:biological:~
言語的:linguistic:~
錯覚効果:illusion:~
	印字不能な~~状況:print-disabled
	工業用:industrial
	医療用:medical
	車の運転時:driving vehicle
	年少者:young children
	在宅鑑賞:home entertainment
	周囲 360 度 平面:envisioned 360 degrees plane
	背後:behind
	低視力者:blind, visually-impaired
	電子本:e-book
	思慮分別:discretion
	図書館:library
	夜中の読書:night-reading
	穏やかな音楽:soft music

	繰り返され:repeated
	依然として:still
	からなる:setup
	形:form
	連結:joining
	種類:kinds
	程度:level
	行:line
	線形に比例するように:linearly-proportional manner
	存在そのものがない:no manifestation
	重み:substantial
	ばらつきが生じ得る:may be discrete variations
	高度に:highly
	2 個:two
	〜の並び:sequence

	●指示語
新たな:new:~
現在の:current:~
部分的:partial:~
特定0の:particular:ある特定の

phrase:::フレーズ
見出し:heading:~
段落:paragraph:~
単語:word:~
	あたりの語数::words per
	文:sentence
	片:piece
	部分:part
	節:section

	左:left
	右:right
	右手側:right hand side
	左手側:left hand side
	右側:right side
	左側:left side
	:left-right
	左右軸:left-right axis
	左右間:left-right
	左右端:left and right extremities
	左右:left and right
	左右両側:left and right sides
	正面:in front of
	中間:intermediary
	点在する:interspersed
	端:extremity
	隣接する:adjacent

	直後に／続く:immediately
	〜から〜まで:inclusive
	より大きい:greater
	より小さい:smaller
	最も内側の:innermost:~
	幅広い:broad variety
	〜の代わりに:instead
	全〜:full
	全く:totally
	全くの:total
	単に:merely
	結果:result
	結果の:resulted
	結果の:resulting
	種々の:various
	いくつかの:several
	大きく:greatly
	費やす:how long
	自身::itself
	周辺:around
	どこであれ:At any point
	2 個目:the second
	別の:another
	またがる:across
	すでに:already
	上の::above
	以前に／予め:previously
	〜に先立って:prior
	前者:former
	単独の:single
	同じ:same
	同じになる:identical
	現在:currently
	次の:the following
	次に従って:as follows
	全体:entire
	各:each
	以前の:earlier
	再び:again
	すべての:all
	0:zero
	更なる:further
	更に，:furthermore
	半分:half:~
	最小:minimum:~
	最も:most:~
	次の:next:~
	他の:other
	他の場合:otherwise
	最も外側の:outermost
	外側:outside
	非:non
	ずっと:much more
	複数の:multiple
	 1:~multiplicatively
	〜倍:multiplied
	毎分あたり:per minute
	いくつもの:numerous
	大きな:major
	最大:maximum
	低／狭い:low
	より低い:lower
	最も長い:longest
	最初の:first
	最後の:last
	後者:latter
	周辺／近い:near
	ときには:sometimes
	一方:whereas
	併用:altogether
	の中で:amongst
	:become
	:in cases where
	:causes
	:during
	:end
	neither
	nor
	per
	plus
	pre
	:show
	-:span
	1:~tell
	:whereby
	:while
	-:whilst
	なる:yields


●●ref_normative

[CSS-VALUES-3]
    Tab Atkins; fantasai. CSS Values and Units Module Level 3. 29 September 2016. W3C Candidate Recommendation. (Work in progress.) URL: https://www.w3.org/TR/2016/CR-css-values-3-20160929/ 
[CSS2]
    Ian Jacobs; et al. Cascading Style Sheets, level 2 (CSS2) Specification. 11 April 2008. W3C Recommendation. URL: http://www.w3.org/TR/2008/REC-CSS2-20080411 
[CSS21]
    Bert Bos; et al. Cascading Style Sheets Level 2 Revision 1 (CSS 2.1) Specification. 7 June 2011. W3C Recommendation. URL: http://www.w3.org/TR/2011/REC-CSS2-20110607 
[RFC2119]
    S. Bradner. Key words for use in RFCs to Indicate Requirement Levels. RFC 2119. URL: http://www.ietf.org/rfc/rfc2119.txt 
[SSML]
    Daniel C. Burnett; 双志伟 (Zhi Wei Shuang). Speech Synthesis Markup Language (SSML) Version 1.1. 7 September 2010. W3C Recommendation. URL: http://www.w3.org/TR/2010/REC-speech-synthesis11-20100907/ 
[XML11]
    Eve Maler; et al. Extensible Markup Language (XML) 1.1 (Second Edition). 16 August 2006. W3C Recommendation. URL: http://www.w3.org/TR/2006/REC-xml11-20060816 

●●ref_informative

[CSS-CONTENT-3]
    Elika J. Etemad / fantasai; Dave Cramer. CSS Generated Content Module Level 3. 2 June 2016. W3C Working Draft. (Work in progress.) URL: http://www.w3.org/TR/2016/WD-css-content-3-20160602/ 
[CSS3LIST]
    Tab Atkins. CSS Lists and Counters Module Level 3. 20 March 2014. W3C Working Draft. (Work in progress.) URL: http://www.w3.org/TR/2014/WD-css-lists-3-20140320/ 
[PRONUNCIATION-LEXICON]
    Paolo Baggia. Pronunciation Lexicon Specification (PLS) Version 1.0. 14 October 2008. W3C Recommendation. URL: http://www.w3.org/TR/2008/REC-pronunciation-lexicon-20081014/ 
[SSML-SAYAS]
    Daniel C. Burnett; et al. SSML 1.0 say-as attribute values. 26 May 2005. W3C Working Group Note. URL: http://www.w3.org/TR/2005/NOTE-ssml-sayas-20050526 

●●trans_metadata
<p>
~THIS_PAGEは、~W3Cにより編集者草案として公開された
<a href="~SPEC_URL">CSS Speech Module</a>
を日本語に翻訳したものです。
~PUB
</p>

●●spec_metadata

最新発行バージョン
    https://www.w3.org/TR/css3-speech/

編集者草案
    https://drafts.csswg.org/css3-speech/

以前のバージョン
    https://www.w3.org/TR/2012/CR-css3-speech-20120320/
    https://www.w3.org/TR/2011/WD-css3-speech-20110818/

フィードバック
	<a href="mailto:www-style@w3.org?subject=%5Bcss-speech%5D%20feedback">www-style@w3.org</a> with subject line “<kbd>[css-speech] <var>… message topic …</var></kbd>” (<a href="http://lists.w3.org/Archives/Public/www-style/" rel="discussion">archives</a>)

編集
	<a href="mailto:dweck@daisy.org">Daniel Weck</a> (<a href="http://www.daisy.org">DAISY Consortium</a>)

前任編集者
	<a href="mailto:dsr@w3.org">Dave Raggett</a> (<a href="http://www.w3.org/">W3C</a>/<a href="http://www.canon.com/">Canon</a>)
	<a href="mailto:daniel@glazman.org">Daniel Glazman</a> (<a href="http://www.disruptive-innovations.com/">Disruptive Innovations</a>)
	<a href="mailto:csant@opera.com">Claudio Santambrogio</a> (<a href="http://www.opera.com/">Opera Software</a>)

public mailing list
	<a href="mailto:www-style@w3.org?Subject=%5Bcss3-speech%5D%20PUT%20SUBJECT%20HERE">www-style@w3.org</a> (<a href="http://lists.w3.org/Archives/Public/www-style/">archived</a>)

</script>

</head>


<body>

<header>
	<hgroup>
<h1 id="top">CSS Speech Module</h1>
	</hgroup>
</header>


<div id="MAIN" style="display:none;">

	<section id="abstract">
<h2 title="Abstract">要約</h2>

<div class="p">
<p>
Speech ~moduleは、いくつかの~CSS聴覚~propを定義する
— それらにより，作者は、発話~合成を通して, および~optionの音声指示を利用して，文書の音声化（ rendering ）を宣言的に制御できるようになる。
この標準は、
<a href="https://www.w3.org/Voice/">Voice Browser Activity</a>
との協同で開発された。
</p>

~CSSisaLANG

◎
CSS (Cascading Style Sheets) is a language that describes the rendering of markup documents (e.g. HTML, XML) on various supports, such as screen, paper, speech, etc. The Speech module defines aural CSS properties that enable authors to declaratively control the rendering of documents via speech synthesis, and using optional audio cues. Note that this standard was developed in cooperation with the Voice Browser Activity.
</div>

<p class="trans-note">【
この仕様が Working Group Note にされた理由は、
`speech^v 媒体~型を~supportする~UAが存在しないことによると見受けられる
— 詳細は
<a href="~MQ4#valdef-media-speech">`speech^v</a> ／
<a href="~CSSissue/1751">issue#1751</a>
に。
】</p>

	</section>
	<section id="status">
<h2 title="Status of this document">この文書の位置付け</h2>

<p>
この節では、発行時点における…
<!-- 
これは編集者草案の公開の複製です…
 -->
【以下，この節の他の内容は <a href="css-common-ja.html#status">CSS 日本語訳 共通ページ</a>に委譲。】
</p>


<p>
この文書は、
<a href="https://www.w3.org/TR/2011/WD-css3-speech-20110818/">Last Call Working Draft (18 August 2011)</a>
に基づくものであり，
<a href="https://wiki.csswg.org/spec/css3-speech">disposition of comments</a>
からの結論が反映された変更点が含められています。
◎
This document is based on the Last Call Working Draft (18 August 2011) and includes changes that reflect the outcome of the disposition of comments.
</p>

<div class="p">
<p id="at-risk">
次の特色機能は~risk下にあり、実装側からの十分な関心が得られなかった場合，勧告候補の期間内に取り下げられる可能性があります：
</p>
<ul ><li>`voice-balance$p
</li><li>`voice-duration$p
</li><li>`voice-pitch$p
</li><li>`voice-range$p
</li><li>`voice-stress$p
</li></ul>


◎
The following features are at-risk and may be dropped at the end of the Candidate Recommendation period if there has not been enough interest from implementers: ‘voice-balance’, ‘voice-duration’, ‘voice-pitch’, ‘voice-range’, and ‘voice-stress’.
</div>


	</section>

<main id="MAIN0">

	<section id="_translation-of-terms_">
<h2>【用語の対訳】</h2>

<p>
この仕様で特に用いられている主な語彙の対訳を以下に示す。
一部の語は原語そのままにしている。
これらは，主に、他の（特に視覚的な）~CSS関連の仕様には見られない語であって, かつ
この仕様が定義する語ではなく, かつ
原語が自明でないと考えられる語†として挙げている
<small>（†
次に挙げるような理由で
—
一般に目にする機会が少ない／
定訳がない／
定訳はあるが他の語の対訳としてもあり得る／
定訳と異なる対訳を用いている／
外来語として記される方が多い ／
等々）</small>：
</p>

<table><thead><tr><th style="min-width:7em">対訳
</th><th style="min-width:10em">原語
</th><th>備考
</th></tr></thead>

<tbody><tr><td>~voice
</td><td>voice
</td><td>“声”。視覚~媒体における~fontに相当する。

</td></tr><tr><td>音声
</td><td>audio
</td><td>

</td></tr><tr><td>音声化する／音声化（体言）／〜による音声化1
</td><td>render, rendered aurally ／ rendering, aural rendering ／ rendition
</td><td>

</td></tr><tr><td>発話する／発話（体言）
</td><td>speak／speech
</td><td>
“読み上げ” と対訳される方が多いと思われるが，語義／語幹の観点から “話” を入れた語を利用する。
（ “読み上げ” は “read out” などの対訳にも利用されている。）

</td></tr><tr><td>発話速度
</td><td>speaking rate
</td><td>

</td></tr><tr><td>発話~合成
</td><td>speech synthesis
</td><td>“合成的~発話” は “synthetic speech”

</td></tr><tr><td>発話~合成器
</td><td>speech synthesizer
</td><td>

</td></tr><tr><td>~TTS
</td><td>text-to-speech
</td><td>発話~合成の技術／~system

</td></tr><tr><td>出力音量
</td><td>volume 
</td><td>聴感音量（ loudness ）と区別

</td></tr><tr><td>聴感音量
</td><td>loudness 
</td><td>出力音量（ volume ）と区別

</td></tr><tr><td>聴覚
</td><td>aural
</td><td>

</td></tr><tr><td>聴感~icon／聴感~環境
</td><td>auditory icon／auditory environment
</td><td>

</td></tr><tr><td>聴取／聴取者
</td><td>listening／listener
</td><td>

</td></tr><tr><td>`指示音$／`音声指示$
</td><td>cue／audio cue
</td><td>

</td></tr><tr><td>`~rest$
</td><td>rest
</td><td>“休止”。`~pause$と似るが，`聴覚~box~model$の中での位置, および連接-時の挙動が異なる

</td></tr><tr><td>`~pause$
</td><td>pause
</td><td>“静止”。

</td></tr><tr><td>韻律
</td><td>prosodic
</td><td>【<a href="https://ja.wikipedia.org/wiki/%E9%9F%BB%E5%BE%8B_%28%E8%A8%80%E8%AA%9E%E5%AD%A6%29">参考</a>】

</td></tr><tr><td>韻律~境界
</td><td>prosodic boundary
</td><td>特定の持続時間を伴う無音

</td></tr><tr><td>分断
</td><td>break
</td><td>~restや~pauseなどにより生じる間（ま）

</td></tr><tr><td>連接
</td><td>adjoining
</td><td>境界を共有する隣接

</td></tr><tr><td>音響, 音
</td><td>sound
</td><td>

</td></tr><tr><td>無音
</td><td>silence, silent
</td><td>音は出ないが時間は消費する

</td></tr><tr><td>半音
</td><td>semitone
</td><td>

</td></tr><tr><td>音高
</td><td>pitch
</td><td>

</td></tr><tr><td>音階
</td><td>scale
</td><td>

</td></tr><tr><td>音素
</td><td>phoneme
</td><td>

</td></tr><tr><td>発声する
</td><td>announce
</td><td>

</td></tr><tr><td>発音
</td><td>pronunciation
</td><td>

</td></tr><tr><td>音標
</td><td>phonetic
</td><td>発音表記に用いられる記法／文字

</td></tr><tr><td>再生する／再生（体言）
</td><td>play ／ playback
</td><td>

</td></tr><tr><td>自然言語
</td><td>language
</td><td>人工言語と区別

</td></tr><tr><td>相殺
</td><td>collapsing
</td><td>`視覚~box~model$における~margin相殺の概念に相当する。

</td></tr></tbody></table>
<!-- 
<tr><td>振幅
<td>amplitude
<td>

<tr><td>波形
<td>waveform
<td>
-->
	</section>
	<section id="intro">
<h2 title="Introduction, design goals">1. 序論, 設計~目標</h2>

~INFORMATIVE

<p>
聴覚~情報の呈示は、低視力者から, あるいは印字不能な~~状況で共通的に利用される。
例えば， “~screen-reader（画面読み取り器）” は、視覚的~interfaceの下で，利用者たちが, 彼らにとり他の仕方では~access不能な情報を対話-可能にする。
また、個人の身体的な情報~access能とは関係なく，内容の （<em>読み取り</em> とは対照的に） <em>聴取</em> が選好されたり，ときには要求される状況もある。
具体例として：
電子本の再生-時 ,
車の運転時,
工業用／医療用 機器の操作方法の習得,
在宅鑑賞~systemとの対話,
年少者~用の読み方の指導,
等々。
◎
The aural presentation of information is commonly used by people who are blind, visually-impaired or otherwise print-disabled. For instance, "screen readers" allow users to interact with visual interfaces that would otherwise be inaccessible to them. There are also circumstances in which listening to content (as opposed to reading) is preferred, or sometimes even required, irrespective of a person's physical ability to access information. For instance: playing an e-book whilst driving a vehicle, learning how to manipulate industrial and medical devices, interacting with home entertainment systems, teaching young children how to read.
</p>

<p>
CSS Speech ~module
— 以下，単に “この~module” —
にて定義される~CSS~propにより、作者は，`聴覚~次元$の下での文書の呈示を宣言的に制御できるようになる。
文書の音声化は、［
発話~合成（ “~TTS” — Text to Speech の頭字語 — としても知られている）, および
聴感~icon（この仕様の中では， “音声指示” と称される）
］の組合わせになる。
CSS Speech
— 以下，単に “この仕様” —
~propは、［
発話の［ 音高や速度 ］, 音についての各種~level,~TTS~voice，その他
］を制御する能を供する。
これらの~stylesheet~propは、視覚的~propと併用したり（混成~媒体），視覚的~呈示に対する聴覚による完全な代替にもなり得る。
◎
The CSS properties defined in the Speech module enable authors to declaratively control the presentation of a document in the aural dimension. The aural rendering of a document combines speech synthesis (also known as "TTS", the acronym for "Text to Speech") and auditory icons (which are referred-to as "audio cues" in this specification). The CSS Speech properties provide the ability to control speech pitch and rate, sound levels, TTS voices, etc. These stylesheet properties can be used together with visual properties (mixed media), or as a complete aural alternative to a visual presentation.
</p>

	</section>
	<section id="background">
<h2 title="Background information, CSS 2.1">2. 背景~情報, CSS 2.1</h2>

~INFORMATIVE

<p>
この~moduleは、 CSS 2.1 の Aural 参考~付録の作り直しである。
その仕様には，媒体~型として "aural" が述べられていたが，（ "speech" （発話）媒体~型への支持を受けて）非推奨にされている。
`CSS21$r 仕様は 媒体~型 `speech^v を予約してはいるが、実際には，対応する~propを定義していない。
この~moduleは `speech^v 媒体~型に適用できる~CSS~propについて述べ、特に`聴覚~次元$用の，新たな “~box” ~modelを定義する。
◎
The CSS Speech module is a re-work of the informative CSS2.1 Aural appendix, within which the "aural" media type was described, but also deprecated (in favor of the "speech" media type). Although the [CSS21] specification reserves the "speech" media type, it doesn't actually define the corresponding properties. The Speech module describes the CSS properties that apply to the "speech" media type, and defines a new "box" model specifically for the aural dimension.
</p>

<p>
内容~作成者は、［
`link^e 要素の `media^a 属性を通して, あるいは
`media^at at-規則により, あるいは `import^at 文の中で
］ `speech^v 媒体~型を指定することにより、［
~TTS合成を備える~UA
］に専用の~CSS~propを，条件付きで含ませられる。
その種の条文の視野の中で著作された~styleは、この~moduleを~supportしない~UAからは無視される。
◎
Content creators can conditionally include CSS properties dedicated to user agents with text to speech synthesis capabilities, by specifying the "speech" media type via the media attribute of the link element, or with the @media at-rule, or within an @import statement. When styles are authored within the scope of such conditional statements, they are ignored by user agents that do not support the Speech module.
</p>

	</section>
	<section id="ssml-rel">
<h2 title="Relationship with SSML">3.~SSMLとの関係性</h2>

~INFORMATIVE

<p>
この仕様の中の一部の特色機能は、~SSML
— Speech Synthesis Markup Language 1.1 `SSML$r —
に述べられる機能性に概念的に類似する。
しかしながら，~CSS~modelの特殊性から、~SSMLの構文や意味論との互換性は，部分的な範囲に限られる。
この~moduleの各種~propの定義には、~SSMLの類似する機能性との関係性を明確化するため，必要に応じて参考~情報が含められている。
◎
Some of the features in this specification are conceptually similar to functionality described in the Speech Synthesis Markup Language (SSML) Version 1.1 [SSML]. However, the specificities of the CSS model mean that compatibility with SSML in terms of syntax and/or semantics is only partially achievable. The definition of each property in the Speech module includes informative statements, wherever necessary, to clarify their relationship with similar functionality from SSML.
</p>

	</section>
	<section id="css-values">
<h2 title="CSS values">4. ~CSS値</h2>

<p class="trans-note">【
この節の内容は
<a href="css-common-ja.html#values">CSS 日本語訳 共通ページ</a>
に委譲
】</p>

	</section>
	<section id="example">
<h2 title="Example">5. 例</h2>

  <div class="example">
<p>
下の例は、<!-- 作者が -->
~HTMLの見出しを， `paul^v と称される~voiceにより，（ `normal^v より強い）
`moderate^v 強勢を利用して，発話~合成器に発話させる方法、および
各 見出しに対し~TTS音声化を開始する前に，音声指示（与えられた~URLに在る録音-済みの音声~clip）を挿入する方法を示すものである。
~stereo音響~systemにおいては、~CSS~class `heidi^css が付与された段落（
`p^e 要素
）が左~音声~channelに（および，女性~voice, その他により）音声化され，
~class `peter^css
のものが右~channelに（および，男性~voice, その他により）音声化される。
~class `special^css
が付与された `span^e 要素では、~textの出力音量~levelが 通常より低くされた上で、それが発話された後に強い~pauseが導入されることにより，韻律~境界が作成される（
~HTMLの `span^e はその親の段落から `voice-family$p を継承することに注意）。
◎
This example shows how authors can tell the speech synthesizer to speak HTML headings with a voice called "paul", using "moderate" emphasis (which is more than normal) and how to insert an audio cue (pre-recorded audio clip located at the given URL) before the start of TTS rendering for each heading. In a stereo-capable sound system, paragraphs marked with the CSS class "heidi" are rendered on the left audio channel (and with a female voice, etc.), whilst the class "peter" corresponds to the right channel (and to a male voice, etc.). The volume level of text spans marked with the class "special" is lower than normal, and a prosodic boundary is created by introducing a strong pause after it is spoken (note how the span inherits the voice-family from its parent paragraph).
</p>

<pre class="lang-css">
h1, h2, h3, h4, h5, h6 {
  `voice-family$p: 太郎;        /* <span class="comment">特定の~voice名</span> */
  `voice-stress$p: moderate;    /* <span class="comment">強勢するときの度合い</span> */
  `cue-before$p: url(../audio/ping.wav); /* <span class="comment">音声指示</span> */
  `voice-volume$p: medium 6dB;  /* <span class="comment">聴感音量＋出力音量の補正量</span> */
}
p.花子 {
  `voice-family$p: female;      /* <span class="comment">女性~voice</span> */
  `voice-balance$p: left;       /* <span class="comment">左~channel</span> */
  `voice-pitch$p: high;         /* <span class="comment">高めの音高</span> */
  `voice-volume$p: -6dB;        /* <span class="comment">出力音量の補正量</span> */
}
p.一郎 {
  `voice-family$p: male;        /* <span class="comment">男性~voice</span> */
  `voice-balance$p: right;      /* <span class="comment">右~channel</span> */
  `voice-rate$p: fast;          /* <span class="comment">速い発話</span> */
}
span.special {
  `voice-volume$p: soft;        /* <span class="comment">控えめな聴感音量</span> */
  `pause-after$p: strong;       /* <span class="comment">強い~pause</span> */
}
</pre>
…
<pre class="lang-ml">&lt;h1&gt;太郎です。見出しの読み上げを担当します。&lt;/h1&gt;
&lt;p class="花子"&gt;こんにちは、私は花子。&lt;/p&gt;
&lt;p class="一郎"&gt;
  &lt;span class="special"&gt;聴こえますか？&lt;/span&gt;
  僕は一郎。
&lt;/p&gt;
</pre>

<!-- 
I am Paul, and I speak headings.
Hello, I am Heidi.
Can you hear me ?
  I am Peter.

 -->
</div>



	</section>
	<section id="aural-model">
<h2 title="The aural formatting model">6. 聴覚~整形~model</h2>

<p>
聴覚~媒体~用の~CSS整形~modelは、
`視覚~box~model$
に類似するような，入子にされた文脈の中で生じる［
音と無音
］の並びに基づいている。
ここでは それを，
<dfn id="aural-box-model">聴覚 “~box” ~model</dfn>
と称することにする。
聴覚 “~canvas” は、
`聴覚~次元@
— ［
合成的~発話と音声指示
］が共存し得るような，［
2 個の~channelが成す（~stereo）空間, および
時間的な次元
］
— からなる。
<em>被選択~要素</em>†
は、（内側から外側にかけて）順に［
`rest$p, `cue$p, `pause$p
］~propで囲まれる。
これらは それぞれ，聴覚において［
`padding$p, `border$p, `margin$p
］~propに等価なものと捉えられる。
［
`before^pe ／ `after^pe
］疑似要素
`CSS21$r
が利用されたときは，要素の内容と `rest$p の狭間に挿入される。
◎
The CSS formatting model for aural media is based on a sequence of sounds and silences that occur within a nested context similar to the visual box model, which we name the aural "box" model. The aural "canvas" consists of a two-channel (stereo) space and of a temporal dimension, within which synthetic speech and audio cues coexist. The selected element is surrounded by ‘rest’, ‘cue’ and ‘pause’ properties (from the innermost to the outermost position). These can be seen as aural equivalents to ‘padding’, ‘border’ and ‘margin’, respectively. When used, the ‘:before’ and ‘:after’ pseudo-elements [CSS21] get inserted between the element's contents and the ‘rest’.
</p>

<p class="trans-note">【†
“~CSS選択子により選択されている要素”
— すなわち，論の対象にされている~propが適用される要素。
この仕様を通して，この意味で用いられる。
“被選択~内容”
という語も現れるが、
“被選択~要素の内容”
と考えればよいであろう。
】</p>

<p>
次の図式に、被選択~要素（図中の "要素" ）に適用される，
`視覚~box~model$ ／ `聴覚~box~model$
の~propの間の等価性を示す：
◎
The following diagram illustrates the equivalence between properties of the visual and aural box models, applied to the selected &lt;element&gt;:
</p>

<figure>

<ol id="aural-box">

	<li style="top:1em; bottom:1em; left:2em;">
`pause-before^p
<div style="height:9em;"></div>
<div style="height:9em;"></div>
`margin-top^p
</li>
	<li style="top:2.5em; bottom:2.5em; left:3em;">
`cue-before^p
<div style="height:7.5em;"></div>
<div style="height:7.5em;"></div>
`border-top^p
</li>
	<li style="top:4em; bottom:4em; left:4em;">
`rest-before^p
<div style="height:6em;"></div>
<div style="height:6em;"></div>
`padding-top^p
</li>

	<li style="top:10em; left:0; border: solid black 0.1em; width:25em; height:0;">
<div style="top:-0.5em; left: 6em; padding:0 0.5em; width:auto; background: white; border: none;">要素</div>
<div style="left: 25em; top:-0.3em; border:solid transparent 0.3em; border-left: solid black 1.5em;"><!-- 矢先 --></div>
</li>

	<li style="top:5.5em; bottom:5.5em; left:12em;">
`rest-after^p
<div style="height:4.5em;"></div>
<div style="height:4.5em;"></div>
`padding-bottom^p
</li>
	<li style="top:7em; bottom:7em; left:13em;">
`cue-after^p
<div style="height:3em;"></div>
<div style="height:3em;"></div>
`border-bottom^p
</li>
	<li style="top:8.5em; bottom:8.5em; left:14em;">
`pause-after^p
<div style="height:1.5em;"></div>
<div style="height:1.5em;"></div>
`margin-bottom^p
</li>
</ol>

<!-- 
<img id="aural-box" src="css-speech/aural-box.png">
 -->
<figcaption>
<!-- alt caption -->
図式による聴覚 “~box” ~model：
中央に被選択~要素が位置し，その
左側には（内側から外側にかけて）［
`rest-before$p, `cue-before$p, `pause-before$p
］が並び,
右側には（内側から外側にかけて）［
`rest-after$p, `cue-after$p, `pause-after$p
］が並ぶ。
ここで、［
`rest-*^p は `padding-*^p ／
`cue-*^p は `border-*^p ／
`pause-*^p は `margin-*^p
］に，概念的に類似する。
◎
The aural 'box' model, illustrated by a diagram: the selected element is positioned in the center, on its left side are (from innermost to outermost) rest-before, cue-before, pause-before, on its right side are (from innermost to outermost) rest-after, cue-after, pause-after, where rest is conceptually similar to padding, cue is similar to border, pause is similar to margin.
</figcaption>

</figure>


	</section>
	<section id="mixing-props">
<h2 title="Mixing properties">7.~mixing~prop</h2>

		<section id="mixing-props-voice-volume">
<h3 title="The ‘voice-volume’ property">7.1. `voice-volume^p ~prop</h3>

`voice-volume^vv

◎名 `voice-volume@p
◎値
`silent$p
| [[`x-soft$v
| `soft$v
| `medium$v
| `loud$v
| `x-loud$v]
|| `decibel$t]
◎初 `medium$v
◎適 すべての要素
◎継 される
◎百 受容しない
◎算
`silent$v, または［
それ以外の~keyword値と, 非 0 の~decibel差分（~option）
］の組
◎
‘silent’, or a keyword value and optionally also a decibel offset (if not zero)
◎表終

<p>
`voice-volume$p ~propは、発話~合成器から生成される音声~波形の振幅を，作者が制御できるようにする。
また、`聴覚~box~model$の中での，被選択~要素の`音声指示$の相対的な出力音量~levelの調整-時にも利用される。
◎
The ‘voice-volume’ property allows authors to control the amplitude of the audio waveform generated by the speech synthesiser, and is also used to adjust the relative volume level of audio cues within the aural box model of the selected element.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `prosody$sS 要素の `volume^a 属性に類似するが、留意すべき不一致があることに注意。
例えば，この~propに対する［
~keyword値,
`decibel$t 値
］は、被選択~要素に値が継承され, 組合わされる法があることに因り，排他的でない。
◎
Note that although the functionality provided by this property is similar to the volume attribute of the prosody element from the SSML markup language [SSML], there are notable discrepancies. For example, CSS Speech volume keywords and decibels units are not mutually-exclusive, due to how values are inherited and combined for selected elements.
</p>


<dl class="value-defs">
<!-- dt><strong>normal</strong></dt>
      <dd>
        <p> Corresponds to +0.0dB, which means that there is no modification of volume level. This
          value overrides the inherited value.</p>
      </dd -->


	<dt>`silent@v</dt>
	<dd>
（大きさのある）音は生成されない（~textは “無音に” 読まれる）ことを指定する。
◎
Specifies that no sound is generated (the text is read "silently").
</dd>
	<dd class="note">
これは、負の無限~decibelの利用と同じ効果になることに注意。
また、
`voice-volume$p ~propの値が
`silent$v にされた要素と,
`speak$p ~propの値が
`none^v にされた要素との間には，相違があることにも注意。
前者では、被選択~要素は，要素の前後の~pauseも含め，それが発話されたかのように同じ時間を占めつつ, 大きさのある音は生成されない（ただし，被選択~要素の`聴覚~box~model$の中の子孫は `voice-volume$p 値を上書きできるので、音声~出力を生成し得る）。
一方で後者では、被選択~要素は`聴覚~次元$の中に音声化されず，再生~用の時間も割り当てられられない（ただし，被選択~要素の`聴覚~box~model$の中の子孫は
`speak$p 値を上書きできるので、音声~出力を生成し得る）。
◎
Note that this has the same effect as using negative infinity decibels. Also note that there is a difference between an element whose ‘voice-volume’ property has a value of ‘silent’, and an element whose ‘speak’ property has the value ‘none’. With the former, the selected element takes up the same time as if it was spoken, including any pause before and after the element, but no sound is generated (descendants within the aural box model of the selected element can override the ‘voice-volume’ value, and may therefore generate audio output). With the latter, the selected element is not rendered in the aural dimension and no time is allocated for playback (descendants within the aural box model of the selected element can override the ‘speak’ value, and may therefore generate audio output).
</dd>

	<dt>`x-soft@v</dt>
	<dt>`soft@v</dt>
	<dt>`medium@v</dt>
	<dt>`loud@v</dt>
	<dt>`x-loud@v</dt>
	<dd>
これらの~keywordは、それぞれが，［
知覚される聴感音量（ loudness ）についての聴取者の要件を満たすような 実装に依存する値
］に対応付けられる出力音量~levelに 対応する。
後に挙げたものほど，大きくなる（厳密には，より小さくない）。
<!-- non-decreasing -->
これらの音声~levelは，概して、利用者が聴感~環境に則って 音についての~optionを調節できるような，選好の仕組みを通して供される。
各種~keyword：
`x-soft^v は
利用者が <em>聴取れる最小の</em> 出力音量~levelに,
`x-loud^v は
利用者が <em>容認し得る最大の</em> 出力音量~levelに,
`medium^v は
利用者が <em>選好する</em> 出力音量~levelに, 
`soft^v と `loud^v
は それらの中間の値に，対応付けられる。
◎
This sequence of keywords corresponds to monotonically non-decreasing volume levels, mapped to implementation-dependent values that meet the listener's requirements with regards to perceived loudness. These audio levels are typically provided via a preference mechanism that allow users to calibrate sound options according to their auditory environment. The keyword ‘x-soft’ maps to the user's minimum audible volume level, ‘x-loud’ maps to the user's maximum tolerable volume level, ‘medium’ maps to the user's preferred volume level, ‘soft’ and ‘loud’ map to intermediary values.
</dd>

	<dt>`decibel@t</dt>
	<dd>
<p>
［
`実数$,
"`dB^u" （~decibel単位）
］の並びで与えられ、次の値に相対的な（正負の）変化を表現する：
◎
A number immediately followed by "dB" (decibel unit).＼
</p>

		<ol>
			<li>
（上に列挙された）~keyword値も与えられていれば それ。
◎
This represents a change (positive or negative) relative to the given keyword value (see enumeration above),＼
</li>
			<li>
他の場合，根~要素に対しては既定~値
【すなわち，初期値】。
◎
or to the default value for the root element,＼
</li>
			<li>
<p>
他の場合，継承される出力音量~level（それ自身，~keyword値と~decibel差分の組合わせをとり得る — この場合の~decibel値は加法的に組合わされ得る）。
◎
or otherwise to the inherited volume level (which may itself be a combination of a keyword value and of a decibel offset, in which case the decibel values are combined additively).＼
</p>

<p>
この場合、継承された出力音量~levelが
`silent$v であるならば、この 
`voice-volume$p も，指定された `decibel$t 値に関係なく
`silent$v に解決される。
◎
When the inherited volume level is ‘silent’, this ‘voice-volume’ resolves to ‘silent’ too, regardless of the specified &lt;decibel&gt; value.＼
</p>
			</li>
		</ol>
	</dd>
	<dd>
<p>
~decibelは，次の対数による等式に従う，新たな信号~振幅（ %a1 ）と現在の振幅（ %a0 ）の比率の二乗を表現する：
</p>

<pre>
出力音量（ dB ） = 20 × log<sub>10</sub> ( %a1 ÷ %a0 )
</pre>

<p class="note">
−6.0dB は 音声~信号の振幅において およそ半分,
+6.0dB は およそ 2 倍になる。
◎
Note that -6.0dB is approximately half the amplitude of the audio signal, and +6.0dB is approximately twice the amplitude.
</p>
◎
Decibels represent the ratio of the squares of the new signal amplitude (a1) and the current amplitude (a0), as per the following logarithmic equation: volume(dB) = 20 log10 (a1 / a0)
</dd>
</dl>

<p class="note">
知覚される聴感音量は、利用者の聴取~環境, 選好, 身体能力など，様々な要因に依存することに注意。
`x-soft$v から `x-loud$v
までの有効な出力音量の変動範囲は、音声~出力の（聴感音量~上の）~dynamic-rangeを表現する。
この範囲は概して，騒がしい環境下では圧縮されることになる
— すなわち、 `x-soft$v に対応する 知覚される聴感音量は，静かな環境下のときより実質的に `x-loud$v に近付くことになるであろう。
また、思慮分別が~~求められる聴取~環境など（図書館や夜中の読書など），
`x-soft$v, `x-loud$v
ともに低い出力音量~levelに対応付けられる状況もあるだろう。
◎
Note that perceived loudness depends on various factors, such as the listening environment, user preferences or physical abilities. The effective volume variation between ‘x-soft’ and ‘x-loud’ represents the dynamic range (in terms of loudness) of the audio output. Typically, this range would be compressed in a noisy context, i.e. the perceived loudness corresponding to ‘x-soft’ would effectively be closer to ‘x-loud’ than it would be in a quiet environment. There may also be situations where both ‘x-soft’ and ‘x-loud’ would map to low volume levels, such as in listening environments requiring discretion (e.g. library, night-reading).
</p>

		</section>
		<section id="mixing-props-voice-balance">
<h3 title="The ‘voice-balance’ property">7.2. `voice-balance^p ~prop</h3>

`voice-balance^vv

◎名 `voice-balance@p
◎値
`number$t
| `left$v
| `center$v
| `right$v
| `leftwards$v
| `rightwards$v
◎初 `center$v
◎適 すべての要素
◎継 される
◎百 受容しない
◎算
−100 〜 100 の範囲の
`number$t に解決される指定値。
◎
the specified value resolved to a &lt;number&gt; between ‘-100’ and ‘100’ (inclusive)
◎表終

<p>
`voice-balance$p ~propは、音響~stageの，側面方向にまたがる 音声~出力の空間的な分布を制御する：
聴取者から見て，一方の端は左手側, 他方の端は右手側に。
作者は、左右端の中間~段階を指定して，結果における 左右軸に沿う音声~分離を表現できる。
◎
The ‘voice-balance’ property controls the spatial distribution of audio output across a lateral sound stage: one extremity is on the left, the other extremity is on the right hand side, relative to the listener's position. Authors can specify intermediary steps between left and right extremities, to represent the audio separation along the resulting left-right axis.
</p>

<p class="note">
`~SSML$には、この~propにより供される機能性に該当するものがないことに注意。
◎
Note that the functionality provided by this property has no match in the SSML markup language [SSML].
</p>

<dl class="value-defs">

	<dt>`number@t</dt>
	<dd>
−100 〜 100 の範囲の`実数$。
範囲~外の値は範囲~内に切詰められる。
負数は左側を表現し, 正数は右側を表現する。
`0^v は、左右の音声~分離を聴き分け得ない，中央~点を表現する（~stereo音響~systemの下では、これは，左右~speakerへの音声~信号の分布が等しいことに対応する）。
◎
A number between ‘-100’ and ‘100’ (inclusive). Values smaller than ‘-100’ are clamped to ‘-100’. Values greater than ‘100’ are clamped to ‘100’. The value ‘-100’ represents the left side, and the value ‘100’ represents the right side. The value ‘0’ represents the center point whereby there is no discernible audio separation between left and right sides (in a stereo sound system, this corresponds to equal distribution of audio signals between left and right speakers).
</dd>

	<dt>`left@v</dt>
	<dd>
`-100^v と同じ。
◎
Same as ‘-100’.
</dd>

	<dt>`center@v</dt>
	<dd>
`0^v と同じ。
◎
Same as ‘0’.
</dd>

	<dt>`right@v</dt>
	<dd>
`100^v と同じ。
◎
Same as ‘100’.
</dd>

	<dt>`leftwards@v</dt>
	<dd>
音を左へ移動させる
— `voice-balance$p の継承値から 20 を減算した上で −100 に切上げて得られる数により。
◎
Moves the sound to the left, by subtracting 20 from the inherited ‘voice-balance’ value, and by clamping the resulting number to ‘-100’.
</dd>

	<dt>`rightwards@v</dt>
	<dd>
音を右へ移動させる
— `voice-balance$p の継承値に 20 を加算した上で 100 に切下げて得られる数により。
◎
Moves the sound to the right, by adding 20 to the inherited ‘voice-balance’ value, and by clamping the resulting number to ‘100’.
</dd>
</dl>

<p>
~UAに接続される音響~systemに備わる音声~mixingには、その特色機能として種々のものがあり得る。
［
~mono, ~stereo, ~surround
］の音響~systemに予期される挙動は、それぞれ，次に従って定義される：
◎
user agents may be connected to different kinds of sound systems, featuring varying audio mixing capabilities. The expected behavior for mono, stereo, and surround sound systems is defined as follows:
</p>

<ul>
	<li>
~UAが~mono-aural （すなわち，単独の~speakerからなる）音響~systemを通して音声を生産する下では、
`voice-balance$p
~propの効果はない。
◎
When user agents produce audio via a mono-aural sound system (i.e. single-speaker setup), the ‘voice-balance’ property has no effect.
</li>
	<li>
~UAが~stereo音響~system（例えば，~headphoneや 2 個の~speaker）を通して音声を生産する下では、音声~信号の左右間の分布は，
`voice-balance$p ~prop用に著作された値に 精確に合致し得る。
◎
When user agents produce audio through a stereo sound system (e.g. two speakers, a pair of headphones), the left-right distribution of audio signals can precisely match the authored values for the ‘voice-balance’ property.
</li>
	<li>
~UAが多~channel（例えば 専用の中央~channelも備える 5 個の~speakerからなる~surround音響~system）を通した音声~信号の~mixingも可能な下では、
`voice-balance$p ~propの適用による結果の 音声~信号の物理的な分布は、聴取者からは，基本的な~stereo~layoutから音が鳴らされているかのように知覚されるべきである。
例えば， `center$v 値の挙動を模倣するために，中央~channelも左/右~speakerと併用されてもよい。
◎
When user agents are capable of mixing audio signals through more than 2 channels (e.g. 5-speakers surround sound system, including a dedicated center channel), the physical distribution of audio signals resulting from the application of the ‘voice-balance’ property should be performed so that the listener perceives sound as if it was coming from a basic stereo layout. For example, the center channel as well as the left/right speakers may be used altogether in order to emulate the behavior of the ‘center’ value.
</li></ul>

<p>
この~moduleの将来の改訂には、作者が実質的に “方位角” と “仰角” の値を指定できるような，三次元の音声~用の~supportも含められ得る。
従って、将来的には，現在の仕様を利用して著作された内容は、［
この仕様の~versionのうち，三次元の音声を~supportするもの
］に準拠する~UAからも消費され得る。
この可能性に備えるため、現在の 
`voice-balance$p
~propに可能化されている値は， “方位角” による角度との互換性が維持されるように設計されている。
より精確には、現在の左右間の音声~軸（側面方向の音響~stage）と，聴取者から見た周囲 360 度 平面との対応付けが、次に従って定義される：
◎
Future revisions of the CSS Speech module may include support for three-dimensional audio, which would effectively enable authors to specify "azimuth" and "elevation" values. In the future, content authored using the current specification may therefore be consumed by user agents which are compliant with the version of CSS Speech that supports three-dimensional audio. In order to prepare for this possibility, the values enabled by the current ‘voice-balance’ property are designed to remain compatible with "azimuth" angles. More precisely, the mapping between the current left-right audio axis (lateral sound stage) and the envisioned 360 degrees plane around the listener's position is defined as follows:
</p>

<ul>
	<li>
値 `0^v は、 0 度（ `center$v ）に対応付けられる。
これは、聴取者の  “背後から” ではなく， “正面から” になる。
◎
The value ‘0’ maps to zero degrees (‘center’). This is in "front" of the listener, not from "behind".
</li>
	<li>
値 `-100^v は， −40 度（ `left$v ）に対応付けられる。
負の角度は，（音声~stageを真上から眺めて）反時計回りの方向を表す。
◎
The value ‘-100’ maps to -40 degrees (‘left’). Negative angles are in the counter-clockwise direction (the audio stage is seen from the top).
</li>
	<li>
値 `100^v は， 40 度（ `right$v ）に対応付けられる。
正の角度は，（音声~stageを真上から眺めて）時計回りの方向を表す。
◎
The value ‘100’ maps to 40 degrees (‘right’). Positive angles are in the clockwise direction (the audio stage is seen from the top).
</li>
	<li>
−100 〜 100 の尺度による値は、数値的に線形に比例するように，
−40 〜 40 度の範囲の角度に対応付けられる。
例えば， −50 は −20 度に対応付けられる。
◎
Intermediary values on the scale from ‘-100’ to ‘100’ map to the angles between -40 and 40 degrees in a numerically linearly-proportional manner. For example, ‘-50’ maps to -20 degrees.
</li></ul>

<p class="note">
利用者は 音響~systemを環境設定することもあるので、文書~作者により指定される左右間の音声~分布は，それに干渉され得ることに注意。
概して、現代的な音響~systemは，（基本的な~stereo ~speaker~systemも含め）種々の “~surround” ~modeを備えており、知覚される 音声~信号の空間的な~layoutが大きく改められる傾向にある。
三次元の音響~stageによる錯覚効果は、しばしば，［
位相変位, ~digital遅延, 出力音量 制御（~channel~mixing）, その他の技法
］の組合わせを利用して得られる。
一部の利用者は、自身の~systemを，音声化される音を単独の~mono~channelに “~downgrade” することすらある
— この場合，
`voice-balance$p
~propの効果は明らかに知覚し得なくなる。
従って、著作された内容の音声化における忠実さは，利用者による その種の~custom化に依存する。
`voice-balance$p
~propは，単に欲される最終結果を指定するものに過ぎない。
◎
Note that sound systems may be configured by users in such a way that it would interfere with the left-right audio distribution specified by document authors. Typically, the various "surround" modes available in modern sound systems (including systems based on basic stereo speakers) tend to greatly alter the perceived spatial arrangement of audio signals. The illusion of a three-dimensional sound stage is often achieved using a combination of phase shifting, digital delay, volume control (channel mixing), and other techniques. Some users may even configure their system to "downgrade" any rendered sound to a single mono channel, in which case the effect of the ‘voice-balance’ property would obviously not be perceivable at all. The rendering fidelity of authored content is therefore dependent on such user customizations, and the ‘voice-balance’ property merely specifies the desired end-result.
</p>

<p class="note">
多くの発話~合成器は、~mono音しか生成しないので，
`voice-balance$p ~propを内在的に~supportしないことに注意。
そのため、左右軸に沿う音の分布は，合成の後処理~段（発話が可能化されている~UAが，文書~内に著作された種々の音声~sourceを混合する段）で生じる。
◎
Note that many speech synthesizers only generate mono sound, and therefore do not intrinsically support the ‘voice-balance’ property. The sound distribution along the left-right axis consequently occurs at post-synthesis stage (when the speech-enabled user agent mixes the various audio sources authored within the document)
</p>

		</section>
	</section>
	<section id="speaking-props">
<h2 title="Speaking properties">8. 発話用~prop</h2>

		<section id="speaking-props-speak">
<h3 title="The ‘speak’ property">8.1. `speak^p ~prop</h3>

`speak^vv

◎名 `speak@p
◎値
`auto$v
| `never$v
| `always$v
◎初 `auto$v
◎適 すべての要素
◎継 される
◎百 受容しない
◎算 指定値
◎表終

<p>
`speak$p ~propは、~textを音声化するかどうかを決定する。
◎
The ‘speak’ property determines whether or not to render text aurally.
</p>

<p class="note">
`~SSML$には、この~propにより供される機能性に該当するものがないことに注意。
◎
Note that the functionality provided by this property has no match in the SSML markup language [SSML].
</p>

<dl class="value-defs">

	<dt>`auto@v</dt>
	<dd>
算出値は、 `display$p に応じて［
`none^v にされているときは `never$v ／
~ELSE_ `auto$v
］に解決される。
使用値は、 `visibility$p に応じて［
`visible^v にされているときは  `always$v ／
~ELSE_  `never$v
］に等価になる。
◎
Resolves to a computed value of ‘never’ when ‘display’ is ‘none’, otherwise resolves to a computed value of ‘auto’. The used value is then equivalent to ‘always’ if ‘visibility’ is ‘visible’ and to ‘never’ otherwise.

 which yields a used value of ‘always’.
</dd>
	<dd class="note">
`display$p ~propの `none^v 値は，被選択~要素の子孫からは上書きされ得ない一方で、 `speak$p の `auto$v 値は， `never$v や `always$v 利用して上書きできることに注意。
◎
Note that the ‘none’ value of the ‘display’ property cannot be overridden by descendants of the selected element, but the ‘auto’ value of ‘speak’ can however be overridden using either of ‘never’ or ‘always’.
</dd>

	<dt>`never@v</dt>
	<dd>
この値は、（~pause, 指示音, ~rest, 実際の内容も含め）要素が音声化されないようにする（すなわち，要素は`聴覚~次元$の下では効果を持たなくなる）。
◎
This value causes an element (including pauses, cues, rests and actual content) to not be rendered (i.e., the element has no effect in the aural dimension).
</dd>
	<dd class="note">
影響される要素の子孫では，この値の上書きが許容されるので、この~levelで `display$p に `none^v を利用していたとしても，子孫は実際に音声化の一部を成し得ることに注意。
しかしながら、先祖~要素の［
~pause, 指示音, ~rest
］は，`聴覚~次元$の下では “作動中でない” ままにされるため、`~pauseの相殺$や［
連接する~restにおける加法的な挙動
］には，寄与しない。
◎
Note that any of the descendants of the affected element are allowed to override this value, so descendants can actually take part in the aural rendering despite using ‘display: none’ at this level. However, the pauses, cues, and rests of the ancestor element remain "deactivated" in the aural dimension, and therefore do not contribute to the collapsing of pauses or additive behavior of adjoining rests.
</dd>

	<dt>`always@v</dt>
	<dd>
要素は音声化される（要素の
`display$p 値や先祖の［
`display$p ／ `speak$p
］値に関わらず）。
◎
The element is rendered aurally (regardless of its ‘display’ value, or the ‘display’ or ‘speak’ values of its ancestors).
</dd>
	<dd class="note">
この値の利用により、要素は，視覚的~canvasには描画されなくても，`聴覚~次元$の下では音声化されるようになることに注意。
◎
Note that using this value can result in the element being rendered in the aural dimension even though it would not be rendered on the visual canvas.
</dd>
</dl>



		</section>
		<section id="speaking-props-speak-as">
<h3 title="The ‘speak-as’ property">8.2. `speak-as^p ~prop</h3>

`speak-as^vv

◎名 `speak-as@p
◎値
`normal$v
| `spell-out$v
|| `digits$v
|| [ `literal-punctuation$v
| `no-punctuation$v ]
◎初 `normal$v
◎適 すべての要素
◎継 される
◎百 受容しない
◎算 指定値
◎表終

<p>
`speak-as$p ~propは、定義-済みの~~選択肢に基づいて，~textがどの方式で音声化されるかを決定する。
◎
The ‘speak-as’ property determines in what manner text gets rendered aurally, based upon a predefined list of possibilities.
</p>

<p class="note">
この~propにより供される機能性は、`~SSML$の `say-as$sS 要素に概念的に類似することに注意。
（可能な値は W3C Note `SSML-SAYAS$r にて述べられている）。
設計~目標は似ていても、~CSS~modelでは，発音~規則の基本的な集合に制限される。
◎
Note that the functionality provided by this property is conceptually similar to the say-as element from the SSML markup language [SSML] (whose possible values are described in the [SSML-SAYAS] W3C Note). Although the design goals are similar, the CSS model is limited to a basic set of pronunciation rules.
</p>

<dl class="value-defs">

	<dt>`normal@v</dt>
	<dd>
要素の内容の音声化に，自然言語に依存する発音~規則を利用する。
例えば約物はそのままの形では発話されず，
代わりに，適切な~pauseとして “自然に” 音声化される。
◎
Uses language-dependent pronunciation rules for rendering the element's content. For example, punctuation is not spoken as-is, but instead rendered naturally as appropriate pauses.
</dd>

	<dt>`spell-out@v</dt>
	<dd>
~textを一字ごとに読み綴る（頭字語や略語に有用になる）。
~accent付き文字が稀な自然言語の下では、~accentなしの綴りによる代替も許可される。
例として，~Englishでは単語 "rôle" を "role" とも記せるので、適合~実装は， "rôle" を “R O L E” と読み綴ることになる。
◎
Spells the text one letter at a time (useful for acronyms and abbreviations). In languages where accented characters are rare, it is permitted to drop accents in favor of alternative unaccented spellings. As as example, in English, the word "rôle" can also be written as "role". A conforming implementation would thus be able to spell-out "rôle" as "R O L E".
</dd>

	<dt>`digits@v</dt>
	<dd>
数を， 1 個の数字ごとに発話する。
具体例として、
"twelve" は “one two” と,
"31" は “three one” と発話されることになるであろう。
<span class="trans-note">【
おそらく，被選択~要素の自然言語が~Englishに設定されている下では。
前者については意外／違和感も — その様な発話が想定されているのなら，通常は 10 進~記数法で記されるだろうし、そのような発話を避けるために "twelve" と記されることも考えられる — この辺りは，利用者~側の設定に委ねるのが適当にも思われる。
日本語の下での "十二", "31" はそれぞれ
“いち, に”, “さん, いち”
と発話されることになるが、 "twelve" が “いち, に” と発話されるべきなのかどうかは，よくわからない。
】</span>
◎
Speak numbers one digit at a time, for instance, "twelve" would be spoken as "one two", and "31" as "three one".
</dd>
	<dd class="note">
発話~合成器は <em>数</em> についての知識を持ち得る。
`speak-as$p ~propは、~UAによる数の音声化に対する ある程度の制御を可能化し，
~textを実際の発話~合成器に渡す前の前処理~段として実装し得る。
◎
Speech synthesizers are knowledgeable about what a number is. The ‘speak-as’ property enables some level of control on how user agents render numbers, and may be implemented as a preprocessing step before passing the text to the actual speech synthesizer.
</dd>

	<dt>`literal-punctuation@v</dt>
	<dd>
~semicolon, 括弧類, 等々の約物は、適切な~pauseとして “自然に” 音声化される代わりに，その名前が~~声に出される（すなわち、逐語的に発話される）。
◎
Punctuation such as semicolons, braces, and so on is named aloud (i.e. spoken literally) rather than rendered naturally as appropriate pauses.
</dd>

	<dt>`no-punctuation@v</dt>
	<dd>
約物は音声化されない：
発話されず，また~pauseとしても音声化されない。
◎
Punctuation is not rendered: neither spoken nor rendered as pauses.
</dd>
</dl>

		</section>
	</section>
	<section id="pause-props">
<h2 title="Pause properties">9. ~pause~prop</h2>


		<section id="pause-props-pause-before-after">
<h3 title="The ‘pause-before’ and ‘pause-after’ properties">9.1. `pause-before^p, `pause-after^p ~prop</h3>

`pause^vv

◎名 `pause-before@p
◎値
`time$t
| `none$v
| `x-weak$v
| `weak$v
| `medium$v
| `strong$v
| `x-strong$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終


◎名 `pause-after@p
◎値
`time$t
| `none$v
| `x-weak$v
| `weak$v
| `medium$v
| `strong$v
| `x-strong$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終

<p>
［
`pause-before$p ／ `pause-after$p
］~propは、`聴覚~box~model$の中で，被選択~要素の発話~合成による音声化1の［
前／後
］に生じるような，韻律~境界（特定の持続時間を伴う無音）を指定する
— これは、［
`cue-before$p ／ `cue-after$p
］が指定されている場合には，それによる指示音より［
前／後
］に生じるとする。
◎
The ‘pause-before’ and ‘pause-after’ properties specify a prosodic boundary (silence with a specific duration) that occurs before (or after) the speech synthesis rendition of the selected element, or if any ‘cue-before’ (or ‘cue-after’) is specified, before (or after) the cue within the aural box model.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `break$sS 要素に類似するが、`聴覚~box~model$の中での `pause$p 韻律~境界の適用には，特別な配慮を要する（例えば`~pauseの相殺$）。
◎
Note that although the functionality provided by this property is similar to the break element from the SSML markup language [SSML], the application of ‘pause’ prosodic boundaries within the aural box model of CSS Speech requires special considerations (e.g. "collapsed" pauses).
</p>

<dl class="value-defs">

	<dt>`time@t</dt>
	<dd>
~pauseを絶対的な`時間$単位（秒やミリ秒
— 例えば `+3s^v, `250ms^v
）で表す。
非負の値のみ許容される。
◎
Expresses the pause in absolute time units (seconds and milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed.
</dd>

	<dt>`none@v</dt>
	<dd>
`0ms^v に等価（発話~処理器からは韻律~分断は生産されない）。
◎
Equivalent to 0ms (no prosodic break is produced by the speech processor).
</dd>

	<dt>`x-weak@v</dt>
	<dt>`weak@v</dt>
	<dt>`medium@v</dt>
	<dt>`strong@v</dt>
	<dt>`x-strong@v</dt>
	<dd>
要素の狭間の~pauseを発話~出力における韻律~分断の強度で表す。
正確な時間は実装に依存する。
後に挙げたものほど，強くなる（厳密には，より弱くない）。
<!-- non-decreasing (conceptually increasing) -->
◎
Expresses the pause by the strength of the prosodic break in speech output. The exact time is implementation-dependent. The values indicate monotonically non-decreasing (conceptually increasing) break strength between elements.
</dd>
</dl>

<p class="note">
より強い内容~境界には，概して~pauseも付帯することに注意。
例えば，段落と段落の間の分断は、概して，文の中の単語と単語の間の分断よりも ずっと重みがある。
◎
Note that stronger content boundaries are typically accompanied by pauses. For example, the breaks between paragraphs are typically much more substantial than the breaks between words within a sentence.
</p>

<div class="example">
<p>
次の例に、（~UA~stylesheetにて定義される）特定の要素に対する 韻律~分断の既定の強度を，著作された~styleにより上書きする方法を示す：
◎
This example illustrates how the default strengths of prosodic breaks for specific elements (which are defined by the user agent stylesheet) can be overridden by authored styles.
</p>

<pre class="lang-css">
p { pause: none } /* <span class="comment">
`pause-before: none; pause-after: none^css
</span> */
</pre>
</div>

		</section>
		<section id="pause-props-pause">
<h3 title="The ‘pause’ shorthand property">9.2. `pause^p 略式~prop</h3>

◎名 `pause@p
◎値
`pause-before$tp `pause-after$tp?
◎初 個々の~propを見よ
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 個々の~propを見よ
◎表終

<p>
`pause$p ~propは、［
`pause-before$p, `pause-after$p
］用の略式~propである。
2 個の値は、順に，これらの~propの値を与える。
値が 1 個だけ与えられた場合、それが 2 個目の値も与える。
◎
The ‘pause’ property is a shorthand property for ‘pause-before’ and ‘pause-after’. If two values are given, the first value is ‘pause-before’ and the second is ‘pause-after’. If only one value is given, it applies to both properties.
</p>

<div class="example">
<p>
~prop値の例：
◎
Examples of property values:
</p>

<pre class="lang-css">
h1 { pause: 20ms; } /* pause-before: 20ms; pause-after: 20ms */
h2 { pause: 30ms 40ms; } /* pause-before: 30ms; pause-after: 40ms */
h3 { pause-after: 10ms; } /* pause-before: <i title="unspecified">未指定</i>; pause-after: 10ms */
</pre>
</div>


		</section>
		<section id="collapsed-pauses">
<h3 title="Collapsing pauses">9.3. ~pauseの相殺</h3>

<p>
この節に現れる “~box” は、すべて，`聴覚~box~model$の中のそれを表すとする。
</p>

<p>
~pauseは、~boxから その前／後の~boxまでの，最小の距離を定義する。
連接する~pauseは、それらの中から
最も強い~keywordによる分断と, 最も長い絶対的な時区間が選定されることにより，併合される。
例えば、
`strong$v と `weak$v
の比較-時には
`strong$v が選択され，
`1s^v と `250ms^v
の比較-時には
`1s^v が選択され，
`strong$v と `250ms^v
の比較-時には それらの効果が合算される。
◎
The pause defines the minimum distance of the aural "box" to the aural "boxes" before and after it. Adjoining pauses are merged by selecting the strongest named break and the longest absolute time interval. For example, "strong" is selected when comparing "strong" and "weak", "1s" is selected when comparing "1s" and "250ms", and "strong" and "250ms" take effect additively when comparing "strong" and "250ms".
</p>

<p>
次の各 項にて挙げる 2 つの~pauseは、互いに連接するとされる：
◎
The following pauses are adjoining:
</p>

<ol>
	<li>
~boxの `pause-after$p と,
~boxの最後の子の `pause-after$p
—
ただし，~boxが
`rest-after$p も `cue-after$p
も持たない場合に限る。
◎
The ‘pause-after’ of an aural "box" and the ‘pause-after’ of its last child, provided the former has no ‘rest-after’ and no ‘cue-after’.
</li>
	<li>
~boxの `pause-before$p と,
~boxの最初の子の `rest-before$p
—
ただし，~boxが
`rest-before$p も `cue-before$p
も持たない場合に限る。
◎
The ‘pause-before’ of an aural "box" and the ‘pause-before’ of its first child, provided the former has no ‘rest-before’ and no ‘cue-before’.
</li>
	<li>
~boxの `pause-after$p と,
~boxの次の同胞の `pause-before$p 。
◎
The ‘pause-after’ of an aural "box" and the ‘pause-before’ of its next sibling.
</li>
	<li>
<p>
~boxの `pause-before$p と,
~boxの `pause-after$p
—
ただし，~box内に音声化される内容が全くない場合（ `speak$p を見よ）, または
~boxは次をすべて満たしている場合に限る：
</p>

<ul><li>`voice-duration$p は `0ms^v にされている
</li><li>`rest-before$p も `rest-after$p も持たない
</li><li>`cue-before$p も `cue-after$p も持たない
</li></ul>

◎
The ‘pause-before’ and ‘pause-after’ of an aural "box", if the the "box" has a ‘voice-duration’ of "0ms" and no ‘rest-before’ or ‘rest-after’ and no ‘cue-before’ or ‘cue-after’, or if the the "box" has no rendered content at all (see ‘speak’).
</li>
</ol>

<p>
相殺された~pauseの並びは，そのいずれかの~pause成分が 別の~pauseに連接する場合、その別の~pauseにも連接するものと見なされる。
◎
A collapsed pause is considered adjoining to another pause if any of its component pauses is adjoining to that pause.
</p>

<p class="note">
`pause$p
は、要素の内容と
`cue$p
との狭間から，
`cue$p
の外側へ移動されたことに注意。
これは CSS 2.1 の Aural 参考~付録 `CSS21$r
に対し、後方互換でない。
◎
Note that ‘pause’ has been moved from between the element's contents and any ‘cue’ to outside the ‘cue’. This is not backwards compatible with the informative CSS2.1 Aural appendix [CSS21].
</p>

		</section>
	</section>
	<section id="rest-props">
<h2 title="Rest properties">10. ~rest~prop</h2>



		<section id="rest-props-rest-before-after">
<h3 title="The ‘rest-before’ and ‘rest-after’ properties">10.1. `rest-before^p, `rest-after^p ~prop</h3>

`rest^vv

◎名 `rest-before@p
◎値
`time$t
| `none$v
| `x-weak$v
| `weak$v
| `medium$v
| `strong$v
| `x-strong$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終


◎名 `rest-after@p
◎値
`time$t
| `none$v
| `x-weak$v
| `weak$v
| `medium$v
| `strong$v
| `x-strong$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終

<p>
［
`rest-before$p ／ `rest-after$p
］~propは、`聴覚~box~model$の中で，要素の発話~合成による音声化1の［
前／後
］に生じる， 1 個の韻律~境界（特定の持続時間を伴う無音）を指定する。
◎
The ‘rest-before’ and ‘rest-after’ properties specify a prosodic boundary (silence with a specific duration) that occurs before (or after) the speech synthesis rendition of an element within the aural box model.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `break$sS 要素に類似するが、`聴覚~box~model$の中での `rest$p 韻律~境界の適用には，特別な配慮を要する（例えば，点在する音声指示, 隣接する~restの加法的な挙動）。
◎
Note that although the functionality provided by this property is similar to the break element from the SSML markup language [SSML], the application of ‘rest’ prosodic boundaries within the aural box model of CSS Speech requires special considerations (e.g. interspersed audio cues, additive adjacent rests).
</p>

<dl class="value-defs">

	<dt>`time@t</dt>
	<dd>
~restを絶対`時間$単位（秒やミリ秒
— 例えば `+3s^v, `250ms^v
）で表す。
非負の値のみ許容される。
◎
Expresses the rest in absolute time units (seconds and milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed.
</dd>

	<dt>`none@v</dt>
	<dd>
0ms に等価（発話~処理器からは韻律~分断は生産されない）。
◎
Equivalent to 0ms (no prosodic break is produced by the speech processor).
</dd>

	<dt>`x-weak@v</dt>
	<dt>`weak@v</dt>
	<dt>`medium@v</dt>
	<dt>`strong@v</dt>
	<dt>`x-strong@v</dt>
	<dd>
~restを発話~出力における 韻律~分断の強度で表す。
正確な時間は実装に依存する。
後に挙げたものほど，強くなる（厳密には，より弱くない）。
<!-- non-decreasing (conceptually increasing) -->
◎
Expresses the rest by the strength of the prosodic break in speech output. The exact time is implementation-dependent. The values indicate monotonically non-decreasing (conceptually increasing) break strength between elements.
</dd>
</dl>

<p>
<a href="#pause-props">~pause~prop</a>
とは対照的に，
~restは要素の内容と［
`cue-before$p ／ `cue-after$p
］の内容との狭間に挿入される。
連接する~restは加法的に扱われ，相殺されない。
◎
As opposed to pause properties, the rest is inserted between the element's content and any ‘cue-before’ or ‘cue-after’ content. Adjoining rests are treated additively, and do not collapse.
</p>

		</section>
		<section id="rest-props-rest">
<h3 title="The ‘rest’ shorthand property">10.2. `rest^p 略式~prop</h3>

◎名 `rest@p
◎値
`rest-before$tp `rest-after$tp?
◎初 個々の~propを見よ
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 個々の~propを見よ
◎表終

<p>
`rest$p ~propは、［
`rest-before$p,  `rest-after$p
］用の略式~propである。
2 個の値は、順に，これらの~propの値を与える。
値が 1 個だけ与えられた場合、それが 2 個目の値も与える。
◎
The ‘rest’ property is a shorthand for ‘rest-before’ and ‘rest-after’. If two values are given, the first value is ‘rest-before’ and the second is ‘rest-after’. If only one value is given, it applies to both properties.
</p>

		</section>
	</section>
	<section id="cue-props">
<h2 title="Cue properties">11. 指示音~prop</h2>



		<section id="cue-props-cue-before-after">
<h3 title="The ‘cue-before’ and ‘cue-after’ properties">11.1. `cue-before^p, `cue-after^p ~prop</h3>

`cue^vv

◎名 `cue-before@p
◎値
`uri$t
`decibel$t?
| `none$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終


◎名 `cue-after@p
◎値
`uri$t
`decibel$t?
| `none$v
◎初 `none$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終

<p>
［
`cue-before$p ／ `cue-after$p
］~propは、`聴覚~box~model$の中で，被選択~要素の［
前／後
］に再生されることになる，聴感~icon（すなわち，録音-済みの, あるいは生成-済みの音~clip）を指定する。
◎
The ‘cue-before’ and ‘cue-after’ properties specify auditory icons (i.e. pre-recorded / pre-generated sound clips) to be played before (or after) the selected element within the aural box model.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `audio$sS 要素に関係して現れ得るが、事実，大きな不一致があることに注意。
例えば、`聴覚~box~model$により，音声指示は被選択~要素の出力音量~levelに結付けられることになるので、この仕様の聴感~iconが供する機能性は，~SSMLの `audio^e 要素に比べ制限される。
◎
Note that although the functionality provided by this property may appear related to the audio element from the SSML markup language [SSML], there are in fact major discrepancies. For example, the aural box model means that audio cues are associated to the selected element's volume level, and CSS Speech's auditory icons provide limited functionality compared to SSML's audio element.
</p>

<dl class="value-defs">

	<dt>`uri@t</dt>
	<dd>
聴感~icon資源として指名される`~URL$。
~UAが指定された聴感~iconを音声化し得ない場合（例えば，~file資源が見つからない, 未~supportの音声~codecなど）、~bell音などの代替の指示音を生産することが推奨される。
◎
The URI designates an auditory icon resource. When a user agent is not able to render the specified auditory icon (e.g. missing file resource, or unsupported audio codec), it is recommended to produce an alternative cue, such as a bell sound.
</dd>

	<dt>`none@v</dt>
	<dd>
聴感~iconは利用されないことを指定する。
◎
Specifies that no auditory icon is used.
</dd>

	<dt>`decibel@t</dt>
	<dd>
［
`実数$,
"`dB^u" （~decibel単位）
］の並びで与えられる。
これは、`聴覚~box~model$の中での，被選択~要素の `voice-volume$p ~propの算出値に相対的な（正または負の）変化を表現する（その結果、音声指示の出力音量~levelは `voice-volume$p ~propの変化に伴って変化する）。
省略された場合の暗黙の値は
`0dB^v に算出される。
◎
A number immediately followed by "dB" (decibel unit). This represents a change (positive or negative) relative to the computed value of the ‘voice-volume’ property within the aural box model of the selected element (as a result, the volume level of an audio cue changes when the ‘voice-volume’ property changes). When omitted, the implied value computes to 0dB.
</dd>
	<dd>
`voice-volume$p ~propの算出値が
`silent^v （無音）の場合、音声指示も無音にされる（この指定 `decibel$t 値に関わらず）。
他の場合の `voice-volume$p 値は、常に，出力音量~level~keyword（
`voice-volume$p の定義を見よ）に相対的に指定される。
この出力音量~levelは、利用者が “選好する” 設定群に調節された聴感音量の尺度に対応付けられる。
`voice-volume$p の継承値に~decibel差分がすでに含まれている場合、音声指示に特有の dB 差分が加法的に組合わされる。
◎
When the computed value of the ‘voice-volume’ property is ‘silent’, the audio cue is also set to ‘silent’ (regardless of this specified &lt;decibel&gt; value). Otherwise (when not ‘silent’), ‘voice-volume’ values are always specified relatively to the volume level keywords (see the definition of ‘voice-volume’), which map to a user-calibrated scale of "preferred" loudness settings. If the inherited ‘voice-volume’ value already contains a decibel offset, the dB offset specific to the audio cue is combined additively.
</dd>
	<dd>
<p>
~decibelは、次の対数~等式に従う，現在の信号~振幅（ %a0 ）に対する 新たな信号~振幅（ %a1 ）の比率の二乗を表す：
◎
Decibels express the ratio of the squares of the new signal amplitude (a1) and the current amplitude (a0), as per the following logarithmic equation: volume(dB) = 20 log10 (a1 / a0)
</p>

<pre>
出力音量（ dB ） = 20 × log<sub>10</sub> ( %a1 ÷ %a0 )
</pre>

<p class="note">
−6.0dB は 音声~信号の振幅において およそ半分,
+6.0dB は およそ 2 倍になる。
◎
Note that -6.0dB is approximately half the amplitude of the audio signal, and +6.0dB is approximately twice the amplitude.
</p>

	</dd>
	<dd class="note">
`voice-volume$p を通して出力音量が無音にされている 音声指示と,
`none$v 値にされた音声指示には、相違があることに注意。
前者は，再生されつつも, （大きさのある）音が生成されないかのように 同じ時間を占める一方、後者は存在そのものがないものにされる（すなわち，`聴覚~次元$の中で指示音に割り当てられる時間は無い）。
◎
Note that there is a difference between an audio cue whose volume is set to ‘silent’ and one whose value is ‘none’. In the former case, the audio cue takes up the same time as if it had been played, but no sound is generated. In the latter case, the there is no manifestation of the audio cue at all (i.e. no time is allocated for the cue in the aural dimension).
</dd>
</dl>


<div class="example">
<p>
~prop値の例：
◎
Examples of property values:
</p>

<pre class="lang-css">
a {
  cue-before: url(/audio/bell.aiff) -3dB;
  cue-after: url(dong.wav);
}

h1 {
  cue-before: url(../clips-1/pop.au) +6dB;
  cue-after: url(../clips-2/pop.au) 6dB;
}

div.caution { cue-before: url(./audio/caution.wav) +8dB; }
</pre>

</div>



		</section>
		<section id="cue-props-volume">
<h3 title="Relation between audio cues and speech synthesis volume levels">11.2. 音声指示と発話~合成との，出力音量~levelの相関</h3>

~INFORMATIVE

<p>
`聴覚~box~model$の中では、被選択~要素の［
音声指示と発話~合成
］の出力音量~levelは 相関する。
例えば，出力音量~levelが（ `decibel$t 値の指定により）
`+0dB^v に設定されたときの音声指示の効果は、その再生~時に知覚される聴感音量が， `voice-volume$p ~propの算出値から決まる［
被選択~要素の発話~合成による音声化1の聴感音量
］に近くなることが欲される。
`voice-volume$p ~propに対する算出値 `silent^v による結果は，
“強制的” に（すなわち，音声指示に指定されている `decibel$t 値に関わらず）無音にされた音声指示になることに注意。
◎
The volume levels of audio cues and of speech synthesis within the aural box model of a selected element are related. For example, the desired effect of an audio cue whose volume level is set at +0dB (as specified by the &lt;decibel&gt; value) is that its perceived loudness during playback is close to that of the speech synthesis rendition of the selected element, as dictated by the computed value of the ‘voice-volume’ property. Note that a ‘silent’ computed value for the ‘voice-volume’ property results in audio cues being "forcefully" silenced as well (i.e. regardless of the specified audio cue ‘decibel’ value)
</p>

<div>
<p>
`voice-volume$p ~propに対する~keyword値による出力音量は、著作-時には知り得ないような利用者の要求（例えば聴感~環境, 個人的な選好）に合致させるために，利用者から調節される。
したがって，上述したように［
音声指示と発話~合成
］の聴感音量を近似的に揃えるためには、作者は，［
音声指示の（<em>平均の</em> <sup>†1</sup> ）出力音量~level
］が，［［
“代表的な” 聴取~条件 <sup>†2</sup> の下での利用が意図された `voice-family$p
］に基づく，発話~合成による音声化1の出力
］に合致することを確保するべきである。
発話~処理器には，生成される~TTS音声の波形~振幅を直に制御する能力があり、~UAは，音声指示の出力音量を調整できる <sup>†3</sup> ので、これは，利用者により調節される出力音量~level <sup>†4</sup> に相対的な［
聴覚~box~model内の［
~TTSと指示音
］音声~streamの両者の聴感音量
］を 実装が上手く扱えるようにするための，基底線を設定する。
</p>

<ul>
<li>†1 — 音声~streamにおける，抑揚, 瞬時の~~強勢（ stress ）, 等々の変化により、知覚される聴感音量には，ばらつきが生じ得るので。</li>
<li>†2 — すなわち，周波数~spectrumに渡り 中央に均等化された（ equalization ），既定の~system出力音量~level。</li>
<li>†3 — すなわち，~digital化された音~clipの内在的な波形~振幅に基づいて音声~信号を増幅させたり減衰させる。</li>
<li>†4 — `voice-volume$p ~propにて定義される~keywordを見よ。</li>
</ul>

◎
The volume keywords of the ‘voice-volume’ property are user-calibrated to match requirements not known at authoring time (e.g. auditory environment, personal preferences). Therefore, in order to achieve this approximate loudness alignment of audio cues and speech synthesis, authors should ensure that the volume level of audio cues (on average, as there may be discrete variations of perceived loudness due to changes in the audio stream, such as intonation, stress, etc.) matches the output of a speech synthesis rendition based on the ‘voice-family’ intended for use, given "typical" listening conditions (i.e. default system volume levels, centered equalization across the frequency spectrum). As speech processors are capable of directly controlling the waveform amplitude of generated text-to-speech audio, and because user agents are able to adjust the volume output of audio cues (i.e. amplify or attenuate audio signals based on the intrinsic waveform amplitude of digitized sound clips), this sets a baseline that enables implementations to manage the loudness of both TTS and cue audio streams within the aural box model, relative to user-calibrated volume levels (see the keywords defined in the ‘voice-volume’ property).
</div>


<p>
知覚される音声~特性（例えば聴感音量）と［
~digital化された音声~信号に適用される処理（例えば信号~圧縮）
］の間には複雑な関係性があるため、ここでは，減衰が 概して［
0dB（~clipping-thresholdに近い最大の音声~入力） 〜 −60dB （全くの無音）
］の範囲に渡る~decibel単位で指示されるような，単純な局面を想定する。
この文脈の下では、“標準的な” 音声~clipは，これらの値の間を変動することになる。
聴感音量が最大になる~peak~levelは（歪みを避けるために） −3dB 近くにされ，それに伴う音声節の平均（ RMS ）出力音量~levelは なるべく高く（すなわち，増幅の際の背景雑音を避けるために静か過ぎない程度に）される。
これにより，聴取者が体験する音声は、概ね，~TTS出力と継ぎ目無く結合できるように（すなわち、録音-済みの音声と発話~合成とを切り替える際の出力音量~levelの相違が，聴き分けられなくなる程に）なるであろう。
その種の慣行を~supportする業界~標準は存在しないが、種々の~TTS~engineが、利得や減衰が指定されていないときには，比較的~強めの音声~信号を生成する傾向にある。
~voiceや穏やかな音楽 用には、 −15dB RMS が相応の標準になるであろう。
◎
Due to the complex relationship between perceived audio characteristics (e.g. loudness) and the processing applied to the digitized audio signal (e.g. signal compression), we refer to a simple scenario whereby the attenuation is indicated in decibels, typically ranging from 0dB (i.e. maximum audio input, near clipping threshold) to -60dB (i.e. total silence). Given this context, a "standard" audio clip would oscillate between these values, the loudest peak levels would be close to -3dB (to avoid distortion), and the relevant audible passages would have average (RMS) volume levels as high as possible (i.e. not too quiet, to avoid background noise during amplification). This would roughly provide an audio experience that could be seamlessly combined with text-to-speech output (i.e. there would be no discernible difference in volume levels when switching from pre-recorded audio to speech synthesis). Although there exists no industry-wide standard to support such convention, different TTS engines tend to generate comparably-loud audio signals when no gain or attenuation is specified. For voice and soft music, -15dB RMS seems to be pretty standard.
</p>

		</section>
		<section id="cue-props-cue">
<h3 title="The ‘cue’ shorthand property">11.3. `cue^p 略式~prop</h3>

◎名 `cue@p
◎値
`cue-before$tp `cue-after$tp?
◎初 個々の~propを見よ
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 個々の~propを見よ
◎表終

<p>
`cue$p ~propは、［
`cue-before$p, `cue-after$p
］用の略式~propである。
2 個の値は、順に，これらの~propの値を与える。
値が 1 個だけ与えられた場合、それが 2 個目の値も与える。
◎
The ‘cue’ property is a shorthand for ‘cue-before’ and ‘cue-after’. If two values are given the first value is ‘cue-before’ and the second is ‘cue-after’. If only one value is given, it applies to both properties.
</p>

<div class="example">
<p>
略式~記法の例：
◎
Example of shorthand notation:
</p>

<pre class="lang-css">
h1 {
  cue-before: url(pop.au);
  cue-after: url(pop.au);
}
/* <span class="comment">
は、次と等価になる：
◎
...is equivalent to:
</span> */
h1 {
  cue: url(pop.au);
}
</pre>
</div>

		</section>
	</section>
	<section id="voice-char-props">
<h2 title="Voice characteristic properties">12. ~voice特性~prop</h2>



		<section id="voice-props-voice-family">
<h3 title="The ‘voice-family’ property">12.1. `voice-family^p ~prop</h3>

`voice-family^vv

◎名 `voice-family@p
◎値
[[`name$t
| `generic-voice$t],]*
[`name$t
| `generic-voice$t]
| `preserve$p
◎初
実装に依存する
◎
implementation-dependent
◎適 すべての要素
◎継 される
◎百 受容しない
◎算 指定値
◎表終

<p>
`voice-family$p ~propは、いくつかの優先度~付きの代替を指示する，~comma区切りの成分~値からなる~listを指定する（これは，視覚的~stylesheetの `font-family$p に類似する）。
各 成分~値は、合致のための判定基準を指定することにより，発話~合成~voice~instanceになり得るものと指名される（この論題については `~voice選定$ 節を見よ）。
◎
The ‘voice-family’ property specifies a prioritized list of component values that are separated by commas to indicate that they are alternatives (this is analogous to ‘font-family’ in visual style sheets). Each component value potentially designates a speech synthesis voice instance, by specifying match criteria (see the voice selection section on this topic).
</p>

<div class="prod">
`generic-voice@t
= [`age$t? `gender$t `integer$t?]
</div>

<p class="note">
この~propにより供される機能性は，`~SSML$の `voice$sS 要素に類似するが、 この仕様は，~SSMLによる精巧な~voice自然言語~選択に等価なものは供さない。
この技術的な制限は，この~moduleの将来の改訂においては緩和され得る。
◎
Note that although the functionality provided by this property is similar to the voice element from the SSML markup language [SSML], CSS Speech does not provide an equivalent to SSML's sophisticated voice language selection. This technical limitation may be alleviated in a future revision of the Speech module.
</p>

<dl class="value-defs">

	<dt>`name@t</dt>
	<dd>
値は，特定の~voice~instance（例えば：
`Mike^v, `comedian^v, `mary^v, `carlos2^v, `"valley girl"^v, 等々
）。
各~voice名は、［
引用符で括られた~CSS`文字列$
］か, または［
1 個以上の［
引用符で括られていない~CSS`識別子$
］の
【空白~区切りの】
並び
］として，与えられなければならない。
◎
Values are specific voice instances (e.g., Mike, comedian, mary, carlos2, "valley girl"). Voice names must either be given quoted as strings, or unquoted as a sequence of one or more identifiers.
</dd>
	<dd class="note">
その結果，引用符で括られていない~voice名においては、各~tokenの先頭にある ほとんどの約物や数字は，~escapeされなければならないことになる。
◎
Note that as a result, most punctuation characters, or digits at the start of each token, must be escaped in unquoted voice names.
</dd>
	<dd>
1 個の~voice名として
【空白~区切りの】
識別子の並びが与えられた場合、その算出値は，並びの中のすべての識別子を［
1 個の空白で区切って連結した文字列
］に変換して得られる名前になる。
◎
If a sequence of identifiers is given as a voice name, the computed value is the name converted to a string by joining all the identifiers in the sequence by single spaces.
</dd>
	<dd>
~voice名のうち，性別（ `gender$t ）~keyword（
`male^v, `female^v, `neutral^v
）や~keyword
`inherit$v, `preserve$v
とたまたま同じになるものは、これらの~keywordと区別できるように引用符で括られなければならない。
~keyword［
`initial$v, `default^v
］も、将来~利用に予約-済みであり，~voice名として利用される際には引用符で括られなければならない。
◎
Voice names that happen to be the same as the gender keywords (‘male’, ‘female’ and ‘neutral’) or that happen to match the keywords ‘inherit’ or ‘preserve’ must be quoted to disambiguate with these keywords. The keywords ‘initial’ and ‘default’ are reserved for future use and must also be quoted when used as voice names.
</dd>
	<dd class="note">
`SSML$r における一連の~voice名は、空白~区切りで与えられるので，空白を含み得ない。
◎
Note that in [SSML], voice names are space-separated and cannot contain whitespace characters.
</dd>
	<dd>［
空白, 数字, ［
~hyphen以外の約物
］］のいずれかを含んでいる~voice名は、~codeの明確さを向上させるため，引用符で括られていない形が妥当な場合でも, 引用符で括ることが推奨される。
例えば：
<samp class="css">`voice-family^p: `"john doe", "Henry the-8th"^v;</samp>
◎
It is recommended to quote voice names that contain white space, digits, or punctuation characters other than hyphens - even if these voice names are valid in unquoted form - in order to improve code clarity. For example: voice-family: "john doe", "Henry the-8th";
</dd>

	<dt>`age@t</dt>
	<dd>
~keyword［
`child^v,
`young^v,
`old^v
］の いずれかを値にとり，~voice選定において合致が選好される年齢層を指示する。
◎
Possible values are ‘child’, ‘young’ and ‘old’, indicating the preferred age category to match during voice selection.
</dd>
	<dd class="note">
`SSML$r における年齢との対応付けには［
`child^v = 6 歳,
`young^v = 24 歳, 
`old^v = 75 歳<!-- y/o = years old -->
］が推奨されることに注意。
処理器に依存する~voice照合~algoは、より柔軟な年齢~範囲を利用してよい。
◎
Note that a recommended mapping with [SSML] ages is: ‘child’ = 6 y/o, ‘young’ = 24 y/o, ‘old’ = 75 y/o. More flexible age ranges may be used by the processor-dependent voice-matching algorithm.
</dd>

	<dt>`gender@t</dt>
	<dd>
~keyword［
`male^v,
`female^v,
`neutral^v
］の いずれか。
それぞれ［
男性, 女性, 中性
］の~voiceを指定する。
◎
One of the keywords ‘male’, ‘female’, or ‘neutral’, specifying a male, female, or neutral voice, respectively.
</dd>
	<dd class="note">
個人の年齢や性別と, 認識し得る~voiceの種別との関係度の解釈は、実質的にいくつもの判定基準（文化的, 言語的, 生物学的, 等々）に依存するので、現実的には統一的な方式で定義し得ない。
従って，この仕様により供される機能性は、ある程度の誤差と引き換えに，幅広い発話~文脈にほどよく適用し得るような 単純化された~modelを表現する。
この仕様の将来~versionでは、発話~処理器~実装がもっと標準~化されるに伴い，~voice照合~algoはより精緻化され得る。
◎
Note that the interpretation of the relationship between a person's age or gender, and a recognizable type of voice, cannot realistically be defined in a universal manner as it effectively depends on numerous criteria (cultural, linguistic, biological, etc.). The functionality provided by this specification therefore represent a simplified model that can be reasonably applied to a broad variety of speech contexts, albeit at the cost of a certain degree of approximation. Future versions of this specification may refine the level of precision of the voice-matching algorithm, as speech processor implementations become more standardized.
</dd>

	<dt>`integer@t</dt>
	<dd>
選好される変種を指示する`整数$（例えば “男性かつ子供の~voiceのうち <em>2 個目</em> のもの”）。
正~整数のみが許容される。
値 `1^v は，合致するすべての~voiceの中で最初のものを指す。
◎
An integer indicating the preferred variant (e.g. "the second male child voice"). Only positive integers (i.e. excluding zero) are allowed. The value "1" refers to the first of all matching voices.
</dd>

	<dt>`preserve@v</dt>
	<dd>
内容~markupにより生じ得る自然言語の変化に関わり無く，継承による
`voice-family$p 値の利用を指示する（~voice選定と自然言語の取扱いについては下の節を見よ）。
この値が根~要素に適用される際には，
`inherit$v として挙動する。
◎
Indicates that the ‘voice-family’ value gets inherited and used regardless of any potential language change within the content markup (see the section below about voice selection and language handling). This value behaves as ‘inherit’ when applied to the root element.
</dd>
	<dd class="note">
被選択~要素の子孫は、他の 
`voice-family$p
値（例えば
名前（ `name$t ）,
性別（ `gender$t ）,
年齢（ `age$t ）
）により明示的に上書きされない限り，
`preserve$v
値を自動的に継承することに注意。
◎
Note that descendants of the selected element automatically inherit the ‘preserve’ value, unless it is explicitly overridden by other ‘voice-family’ values (e.g. name, gender, age).
</dd>
</dl>

<div class="example">
<p>
無効な宣言の例：
◎
Examples of invalid declarations:
</p>

<pre class="lang-css">
voice-family: john/doe;
    /* <span class="comment">
~forward-slashは~escapeされるべきである
◎
forward slash character should be escaped
</span> */
voice-family: john "doe";
    /* <span class="comment">
一連の識別子は`文字列$を含み得ない
◎
identifier sequence cannot contain strings
</span> */
voice-family: john!;
    /* <span class="comment">
感嘆符は~escapeされるべきである
◎
exclamation mark should be escaped
</span> */
voice-family: john@doe;
    /* <span class="comment">
“at” 文字（ `@^c ）は~escapeされるべきである
◎
"at" character should be escaped
</span> */
voice-family: #john;
    /* <span class="comment">
識別子は~hash文字から開始できない
◎
identifier cannot start with hash character
</span> */
voice-family: john 1st;
    /* <span class="comment">
識別子は数字から開始できない
◎
identifier cannot start with digit
</span> */
</pre>
</div>

			<section id="voice-selection">
<h4 title="Voice selection, content language">12.1.1. ~voice選定と, 内容の自然言語</h4>

<p>
`voice-family$p ~propは、発話~合成~voice~instanceの選択を手引きするために利用される。
発話~能力がある~UAは、この選択~処理の一部に，~markup内容における被選択~要素の自然言語も織り込まなければならない。
`voice-family$p ~prop値が子孫~要素に継承される際に，内容の深層へ伝わる［
名前（ `name$t ）,
性別（ `gender$t ）,
年齢（ `age$t ）,
および選好される “変種” （ `integer$t ~index）
］は、~voice選定~用の~hintである。
内容~構造~内のどこであれ、自然言語は，指定されている~CSS~voice特性より優先される（すなわち，より優先度が高い）。
◎
The ‘voice-family’ property is used to guide the selection of the speech synthesis voice instance. As part of this selection process, speech-capable user agents must also take into account the language of the selected element within the markup content. The "name", "gender", "age", and preferred "variant" (index) are voice selection hints that get carried down the content hierarchy as the ‘voice-family’ property value gets inherited by descendant elements. At any point within the content structure, the language takes precedence (i.e. has a higher priority) over the specified CSS voice characteristics.
</p>

<p>
~voice選定~algoの概要を以下に挙げる（方言による差異を吸収するため、ここでの  “自然言語” の定義は緩められていることに注意）：
◎
The following list outlines the voice selection algorithm (note that the definition of "language" is loose here, in order to cater for dialectic variations):
</p>

<ol>
	<li>
被選択~内容
【 被選択~要素の内容 】
の自然言語に対し，可用な~voice~instanceが 1 個しかない場合、指定された~CSS~voice特性に関わり無く，この~voiceが利用されなければならない。
◎
If only a single voice instance is available for the language of the selected content, then this voice must be used, regardless of the specified CSS voice characteristics.
</li>
	<li>
被選択~内容の自然言語に対し，複数の~voice~instanceが可用な場合、選ばれる~voiceは，
指定された名前, または［
性別, 年齢, ~voiceに選好される変種
］に最も近く合致するものになる。
“最良~合致” の実際の定義は，処理器に依存する。
例えば，大人の男性／女性の~voiceのみが可用な~systemにおいては、
"<samp class="css">`voice-family$p: `young male^v</samp>"
に対しては、音高が高い女性~voiceの方が ほどよく合致するであろう
— その方が調子は少年に近くなるであろうから。
供されているどの `voice-family$p 成分~値にも特性が合致する~voice~instanceが無い場合、（被選択~内容の自然言語に適するものの中で）最初に可用な~voice~instanceが利用されなければならない。
【 “最初” — どの順序で？ 】
◎
If several voice instances are available for the language of the selected content, then the chosen voice is the one that most closely matches the specified name, or gender, age, and preferred voice variant. The actual definition of "best match" is processor-dependent. For example, in a system that only has male and female adult voices available, a reasonable match for "voice-family: young male" may well be a higher-pitched female voice, as this tone of voice would be close to that of a young boy. If no voice instance matches the characteristics provided by any of the ‘voice-family’ component values, the first available voice instance (amongst those suitable for the language of the selected content) must be used.
</li>
	<li>
被選択~内容の自然言語に利用し得る~voiceが無い場合、
~UAには，適切な~TTS~voiceが無いことを利用者に知らせることが推奨される。
◎
If no voice is available for the language of the selected content, it is recommended that user agents let the user know about the lack of appropriate TTS voice.
</li></ol>

<p>
内容~flowの中で~CSS~voice特性が変化するようなどの場所でも、
発話~合成器~voiceは，再~評価されなければならない（すなわち，選択~処理が再び行われなければならない）。
`preserve$v ~keyword（これは、被選択~内容の自然言語~用に設計されたものではない~voiceを利用して，埋込みの外国語~textを発話させたいときに有用になり得る — 下に例示される様に）が利用されていない限り、内容の自然言語が変化する度に，~voiceも再~計算されなければならない。
◎
The speech synthesizer voice must be re-evaluated (i.e. the selection process must take place once again) whenever any of the CSS voice characteristics change within the content flow. The voice must also be re-calculated whenever the content language changes, unless the ‘preserve’ keyword is used (this may be useful in cases where embedded foreign language text can be spoken using a voice not designed for this language, as demonstrated by the example below).
</p>

<p class="note">
~voiceの動的な算出は，不慮の~lagをもたらし得るので、
~UAは再生を開始する前に，文書~木の中の具体的な~voice~instanceの解決を試みるべきである。
◎
Note that dynamically computing a voice may lead to unexpected lag, so user agents should try to resolve concrete voice instances in the document tree before the playback starts.
</p>

<div class="example">
<p>
~prop値の例：
◎
Examples of property values:
</p>

<pre class="lang-css">
h1 { voice-family: announcer, old male; }
p.romeo  { voice-family: romeo, young male; }
p.juliet { voice-family: juliet, young female; }
p.mercutio { voice-family: young male; }
p.tybalt { voice-family: young male; }
p.nurse { voice-family: amelie; }
</pre>
…
<pre class="lang-ml">
&lt;p class="romeo" xml:lang="en-US"&gt;

<span class="comment">
次の~French~textは~Englishの~voiceで発話されることになる：
◎
The French text below will be spoken with an English voice:
</span>
  &lt;span style="voice-family: preserve;" xml:lang="fr-FR"
  &gt;Bonjour monsieur !&lt;/span&gt;

<span class="comment">
次の英文~textは，（親の `p^e 要素から継承されるもの）~class "`romeo^v" に対応する~voiceとは異なる~voiceで発話される：
◎
The English text below will be spoken with a voice different than that corresponding to the class "romeo" (which is inherited from the "p" parent element):
</span>
  &lt;span style="voice-family: female;"&gt;Hello sir!&lt;/span&gt;
&lt;/p&gt;
</pre>
</div>



			</section>
		</section>
		<section id="voice-props-voice-rate">
<h3 title="The ‘voice-rate’ property">12.2. `voice-rate^p ~prop</h3>

`voice-rate^vv

◎名 `voice-rate@p
◎値
[`normal$v
| `x-slow$v
| `slow$v
| `medium$v
| `fast$v
| `x-fast$v]
|| `percentage$t
◎初 `normal$v
◎適 すべての要素
◎継 される
◎百
既定~値に相対的
◎
refer to default value
◎算
［
~keyword値と, ~keywordに相対的な 100% でない百分率（~option）
］の組
◎
a keyword value, and optionally also a percentage relative to the keyword (if not 100%)
◎表終

<p>
`voice-rate$p ~propは、毎分あたりの語数により，生成される合成的~発話の速度を操作する。
◎
The ‘voice-rate’ property manipulates the rate of generated synthetic speech in terms of words per minute.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `prosody$sS 要素の `rate^a 属性に類似するが，留意すべき不一致があることに注意。
例えば，この~propに対する［
速度~keyword値,
百分率~値による修飾
］は、被選択~要素に値が継承され, 組合わされる法があることに因り，排他的でない。
◎
Note that although the functionality provided by this property is similar to the rate attribute of the prosody element from the SSML markup language [SSML], there are notable discrepancies. For example, CSS Speech rate keywords and percentage modifiers are not mutually-exclusive, due to how values are inherited and combined for selected elements.
</p>

<dl class="value-defs">

	<dt>`normal@v</dt>
	<dd>
発話~合成器が現在~作動中の~voiceを生産するときの，既定の速度を表現する。
これは、処理器ごとに特有であり，自然言語, 方言, ［
~voiceの “個性”
］に依存する。
◎
Represents the default rate produced by the speech synthesizer for the currently active voice. This is processor-specific and depends on the language, dialect and on the "personality" of the voice.
</dd>

	<dt>`x-slow@v</dt>
	<dt>`slow@v</dt>
	<dt>`medium@v</dt>
	<dt>`fast@v</dt>
	<dt>`x-fast@v</dt>
	<dd>
これらは 実装／~voiceごとに特有の発話速度であり、後に挙げたものほど，速くなる（厳密には，より遅くない）。
<!-- non-decreasing -->
例えば，~English用の代表的な値は（毎分あたりの語数で）［
`x-slow^v = 80 語,
`slow^v = 120 語,
`medium^v = 180 語 〜 200 語,
`fast^v = 500 語
］になる。
◎
A sequence of monotonically non-decreasing speaking rates that are implementation and voice -specific. For example, typical values for the English language are (in words per minute) x-slow = 80, slow = 120, medium = between 180 and 200, fast = 500.
</dd>

	<dt>`percentage@t</dt>
	<dd>
<p>
負でない`百分率$値のみ許容され、次の値に相対的な変化を表現する：
</p>

		<ol>
			<li>
（上に列挙された）~keyword値も与えられていれば それ。
</li>
			<li>
他の場合，根~要素に対しては既定~値
【すなわち，初期値】。
</li>
			<li>
他の場合，継承されている発話速度（それ自身も~keyword値と百分率の組合わせになり得る — この場合の<!-- 百分 -->率は，累積される）。
</li>
		</ol>

<p>
例えば 50% は、 発話速度が 0.5 倍されることを意味する。
100% を上回る百分率においては，発話速度が（基底の~keywordに比して）より速くなり、
100% を下回る百分率においては，よりゆっくりになる。
</p>

◎
Only non-negative percentage values are allowed. This represents a change relative to the given keyword value (see enumeration above), or to the default value for the root element, or otherwise to the inherited speaking rate (which may itself be a combination of a keyword value and of a percentage, in which case percentages are combined multiplicatively). For example, 50% means that the speaking rate gets multiplied by 0.5 (half the value). Percentages above 100% result in faster speaking rates (relative to the base keyword), whereas percentages below 100% result in slower speaking rates.
</dd>
</dl>

<div class="example">
<p>
継承値の例：
◎
Examples of inherited values:
</p>

<pre class="lang-ml">
&lt;body&gt;
  &lt;e1&gt;
    &lt;e2&gt;
      &lt;e3&gt;
        …
      &lt;/e3&gt;
    &lt;/e2&gt;
  &lt;/e1&gt;
&lt;/body&gt;
</pre>
…
<pre class="lang-css">
body { voice-rate: inherit; }
    /* <span class="comment">
初期値は `normal$v （実際の発話速度の値は作動中の~voiceに依存する）
◎
the initial value is 'normal' (the actual speaking rate value depends on the active voice)
</span> */

e1 { voice-rate: +50%; }
    /* <span class="comment">
算出値は［
`normal$v と `50%^v
］の組。
これは， `normal$v の 0.5 倍（発話速度の半分）に対応する速度に解決されることになる。
◎
the computed value is ['normal' and 50%], which will resolve to the rate corresponding to 'normal' multiplied by 0.5 (half the speaking rate)
</span> */

e2 { voice-rate: fast 120%; }
    /* <span class="comment">
算出値は［
`fast$v と `120%^v
］の組。
これは， `fast$v の 1.2 倍に対応する速度に解決されることになる。
◎
the computed value is ['fast' and 120%], which will resolve to the rate corresponding to 'fast' multiplied by 1.2
</span> */

e3 {
    voice-rate: normal;
    /* <span class="comment">
発話速度を内在的な~voice値に “再設定-” する。
算出値は `normal$v になる（実際の値については，次の~commentを見よ）。
◎
"resets" the speaking rate to the intrinsic voice value, the computed value is 'normal' (see comment below for actual value)
</span> */

    voice-family: "another-voice";
    /* <span class="comment">
~voiceが別のものにされているので、計算される発話速度は， `body^e のそれに比して（ `voice-rate$p の算出値が同じであっても）変わり得る。
◎
because the voice is different, the calculated speaking rate may vary compared to "body" (even though the computed 'voice-rate' value is the same)
</span> */
}
</pre>
</div>



		</section>
		<section id="voice-props-voice-pitch">
<h3 title="The ‘voice-pitch’ property">12.3. `voice-pitch^p ~prop</h3>

`voice-pitch^vv

◎名 `voice-pitch@p
◎値
`frequency$t
&amp;&amp; `absolute$v
| [[`x-low$v
| `low$v
| `medium$v
| `high$v
| `x-high$v]
|| [`frequency$t
| `semitones$t
| `percentage$t]]
◎初 `medium$v
◎適 すべての要素
◎継 される
◎百
継承値に相対的
◎
refer to inherited value
◎算  <p>
定義-済みの音高~keywordのみが指定されている場合はその~keyword。
他の場合、~keyword値（もし指定されていれば）を［
現在の `voice-family$p を基に，相対~差分が指定されていれば それも適用した上で，固定~周波数に変換する
］ことにより計算される，絶対的な周波数。
◎
one of the predefined pitch keywords if only the keyword is specified by itself, otherwise an absolute frequency calculated by converting the keyword value (if any) to a fixed frequency based on the current voice-family and by applying the specified relative offset (if any)
</p>
◎表終

<p>
`voice-pitch$p ~propは、生成される発話~出力の “基底線” とされる音高を指定する。
これは、使用される `voice-family$p ~instanceに依存し，発話~合成~処理器ごとに変わり得る（およそ，出力の平均~音高に対応する）。
例えば、男性~voiceに共通的な音高は 120Hz 周辺になる一方，女性~voiceでは 210Hz 周辺になる。
◎
The ‘voice-pitch’ property specifies the "baseline" pitch of the generated speech output, which depends on the used ‘voice-family’ instance, and varies across speech synthesis processors (it approximately corresponds to the average pitch of the output). For example, the common pitch for a male voice is around 120Hz, whereas it is around 210Hz for a female voice.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の `prosody$sS 要素の `pitch^a 属性に類似するが、留意すべき不一致があることに注意。
例えば，この~propに対する［
音高~keyword値,
相対~変化~値（周波数, 半音単位, 百分率）
］は、被選択~要素に値が継承され, 組合わされる法があることに因り，排他的でない。
◎
Note that although the functionality provided by this property is similar to the pitch attribute of the prosody element from the SSML markup language [SSML], there are notable discrepancies. For example, CSS Speech pitch keywords and relative changes (frequency, semitone or percentage) are not mutually-exclusive, due to how values are inherited and combined for selected elements.
</p>

<dl class="value-defs">

	<dt>`frequency@t</dt>
	<dd>
`周波数$単位（~Hertzまたは~kiloHertz）による値（例えば
`100Hz^v や
`+2kHz^v
）。
ただし，
`absolute$v ~keywordが指定された下での値は、正数に制約される。
他の場合の［
負／正
］の値はそれぞれ，継承値に相対的な［
減分／増分
］を表現する。
例えば
"`2kHz^v"
は，正の差分（
"`+2kHz^v"
と厳密に等価）になり、
"`+2kHz absolute^v"
は，絶対~周波数（
"`2kHz absolute^v"
と厳密に等価）になる。
◎
A value in frequency units (Hertz or kiloHertz, e.g. "100Hz", "+2kHz"). Values are restricted to positive numbers when the ‘absolute’ keyword is specified. Otherwise (when the ‘absolute’ keyword is not specified), a negative value represents a decrement, and a positive value represents an increment, relative to the inherited value. For example, "2kHz" is a positive offset (strictly equivalent to "+2kHz"), and "+2kHz absolute" is an absolute frequency (strictly equivalent to "2kHz absolute").
</dd>

	<dt>`absolute@v</dt>
	<dd>
指定された場合、この~keywordは，指定された周波数が 絶対的な値を表現することを指示する。
負の周波数が指定された場合に算出される周波数は 0 になる。
◎
If specified, this keyword indicates that the specified frequency represents an absolute value. If a negative frequency is specified, the computed frequency will be zero.
</dd>

	<dt>`semitones@t</dt>
	<dd>
継承値に相対的な，変化（減分または増分）を指定する。
許容される値の構文は［
`number$t,
"`st^u" （半音 単位~識別子）
］の並びである。
半音~区間は，半音による等分平均律の各 音階（音符と次の音符の間）に対応する。
従って，半音は、そのような音階の下で隣り合う 2 個の音高の周波数の相違として量られる。
1 個の半音で隔てられた 2 つの周波数の比率は，
2 の 12 乗根（約 ( 11011 ÷ 10393 ), あるいは 1.0594631 に（この桁数の精度で）等しい）。
すなわち、半音による差分に対応する~Hertz単位の値は，その差分が適用される初期~周波数に相対的になる（言い換えれば、半音は，固定的な~Hertz単位の数値に対応しない）。
◎
Specifies a relative change (decrement or increment) to the inherited value. The syntax of allowed values is a &lt;number&gt; followed immediately by "st" (semitones). A semitone interval corresponds to the step between each note on an equal temperament chromatic scale. A semitone can therefore be quantified as the difference between two consecutive pitch frequencies on such scale. The ratio between two consecutive frequencies separated by exactly one semitone is the twelfth root of two (approximately 11011/10393, which equals exactly 1.0594631). As a result, the value in Hertz corresponding to a semitone offset is relative to the initial frequency the offset is applied to (in other words, a semitone doesn't correspond to a fixed numerical value in Hertz).
</dd>

	<dt>`percentage@t</dt>
	<dd>
`百分率$には［
正／負
］の値が許容され、それぞれ 継承値に相対的な［
増分／減分
］を表現する。
その算出値は、継承値の指定された割合分を，継承値に 加算-／減算-することにより計算される。
例えば，継承値が `200Hz^v のとき、
`50%^v（ `+50%^v に等価）による結果は
200 + ( 200 × 0.5 ) = `300Hz^v
になり，
`-50%^v による結果は
200 − ( 200 × 0.5 ) = `100Hz^v
になる。
◎
Positive and negative percentage values are allowed, to represent an increment or decrement (respectively) relative to the inherited value. Computed values are calculated by adding (or subtracting) the specified fraction of the inherited value, to (from) the inherited value. For example, 50% (which is equivalent to +50%) with a inherited value of 200Hz results in 200 + (200*0.5) = 300Hz. Conversely, -50% results in 200-(200*0.5) = 100Hz.
</dd>

	<dt>`x-low@v</dt>
	<dt>`low@v</dt>
	<dt>`medium@v</dt>
	<dt>`high@v</dt>
	<dt>`x-high@v</dt>
	<dd>
これらは，実装／~voiceごとに特有の音高~levelを表し、後に挙げたものほど，高くなる（厳密には，より低くない）。
<!-- non-decreasing -->
与えられた要素に対する算出値が~keywordのみの場合（すなわち，相対~差分が指定されていない）、対応する絶対~周波数は，~voiceが変化する度に再~評価されることになる。
逆に，相対~差分の適用は、［
相対~差分が指定された地点における現在の~voice
］に基づく周波数の計算を要するので、［
~styleの~cascadeにより ~voice変化が深層へ伝わる
］のに関わらず，絶対的に算出される周波数が継承されることになる。
従って，作者は、~voice変化に応じて［
~keywordから具体的な, ~voiceに依存する周波数への変換の再~評価
］を誘発させたいときは、~keyword値を利用するべきである。
◎
A sequence of monotonically non-decreasing pitch levels that are implementation and voice specific. When the computed value for a given element is only a keyword (i.e. no relative offset is specified), then the corresponding absolute frequency will be re-evaluated on a voice change. Conversely, the application of a relative offset requires the calculation of the resulting frequency based on the current voice at the point at which the relative offset is specified, so the computed frequency will inherit absolutely regardless of any voice change further down the style cascade. Authors should therefore only use keyword values in cases where they wish that voice changes trigger the re-evaluation of the conversion from a keyword to a concrete, voice-dependent frequency.
</dd>
</dl>

<p>
算出された絶対~周波数が負の場合は 0 ~Hertz以上に切上げられる。
発話~能力がある~UAは，おそらく、周波数の計算から得られ得る全~数値~範囲ではなく，特定の範囲の値を~supportすることになるであろう。
従って，~UAにおける実際の値は、実装に依存する下限／上限に切詰められ得る。
例えば，周波数
`0Hz^v
は合法的に計算され得るが、発話~合成器の文脈の下では，より有意義な値に切詰められるであろう。
◎
Computed absolute frequencies that are negative are clamped to zero Hertz. Speech-capable user agents are likely to support a specific range of values rather than the full range of possible calculated numerical values for frequencies. The actual values in user agents may therefore be clamped to implementation-dependent minimum and maximum boundaries. For example: although the 0Hz frequency can be legitimately calculated, it may be clamped to a more meaningful value in the context of the speech synthesizer.
</p>

<div class="example">
<p>
~prop値の例：
◎
Examples of property values:
</p>

<pre class="lang-css">
h1 { voice-pitch: 250Hz; }
    /* <span class="comment">
継承される絶対~周波数に相対的な正の差分
◎
positive offset relative to the inherited absolute frequency
</span> */
h1 { voice-pitch: +250Hz; }
    /* <span class="comment">
前の行と同じになる
◎
identical to the line above
</span> */
h2 { voice-pitch: +30Hz absolute; }
    /* <span class="comment">
増分ではない
◎
not an increment
</span> */
h2 { voice-pitch: absolute 30Hz; }
    /* <span class="comment">
前の行と同じになる
◎
identical to the line above
</span> */
h3 { voice-pitch: -20Hz; }
    /* <span class="comment">
継承される絶対~周波数に相対的な負の差分（減分）
◎
negative offset (decrement) relative to the inherited absolute frequency
</span> */
h4 { voice-pitch: -20Hz absolute; }
    /* <span class="comment">
違法な構文。
値は無視される（ `absolute$v ~keywordは，負の周波数には許容されない）
◎
illegal syntax =&gt; value ignored ("absolute" keyword not allowed with negative frequency)
</span> */
h5 { voice-pitch: -3.5st; }
    /* <span class="comment">
半音単位, 負の差分
◎
semitones, negative offset
</span> */
h6 { voice-pitch: 25%; }
    /* <span class="comment">
これは “継承値の 4 分の 1 を継承値に加える” ことを意味する
◎
this means "add a quarter of the inherited value, to the inherited value"
</span> */
h6 { voice-pitch: +25%; }
    /* <span class="comment">
前の行と同じになる
◎
identical to the line above
</span> */
</pre>
</div>



		</section>
		<section id="voice-props-voice-range">
<h3 title="The ‘voice-range’ property">12.4. `voice-range^p ~prop</h3>

<!-- 
`voice-range^vv
 -->

◎名 `voice-range@p
◎値
`frequency$t
&amp;&amp; `absolute$v
| [[`x-low$v
| `low$v
| `medium$v
| `high$v
| `x-high$v]
|| [`frequency$t
| `semitones$t
| `percentage$t]]
◎初 `medium$v
◎適 すべての要素
◎継 される
◎百 <!-- copy -->
継承値に相対的
◎
refer to inherited value
◎算 <!-- copy -->
定義-済みの音高~keywordのみが指定されている場合はその~keyword。
他の場合、~keyword値（もし指定されていれば）を［
現在の `voice-family$p を基に，相対~差分が指定されていれば それも適用した上で，固定~周波数に変換する
］ことにより計算される，絶対的な周波数。
◎
one of the predefined pitch keywords if only the keyword is specified by itself, otherwise an absolute frequency calculated by converting the keyword value (if any) to a fixed frequency based on the current voice-family and by applying the specified relative offset (if any)
◎表終

<p>
`voice-range$p ~propは、 “基底線” 音高の可変度
— すなわち，基本周波数
【<a href="https://en.wikipedia.org/wiki/Fundamental_frequency">fundamental frequency</a>】
が発話~出力の平均~音高からどの程度 外れられるか —
を指定する。
生成される発話の動的な音高~範囲は、高度に活発な~voiceにおいては，一般に拡大する。
例えば，発話における意味や強勢の~~伝達に，屈折
【<a href="https://en.wikipedia.org/wiki/Inflection">inflection</a>, <a href="https://ja.wikipedia.org/wiki/%E8%AA%9E%E5%BD%A2%E5%A4%89%E5%8C%96">~~屈折</a>】
が利用されるときなど。
概して、範囲が狭い場合は平坦で単調な~voiceを生産する一方，範囲が広い場合は活発な~voiceを生産する。
◎
The ‘voice-range’ property specifies the variability in the "baseline" pitch, i.e. how much the fundamental frequency may deviate from the average pitch of the speech output. The dynamic pitch range of the generated speech generally increases for a highly animated voice, for example when variations in inflection are used to convey meaning and emphasis in speech. Typically, a low range produces a flat, monotonic voice, whereas a high range produces an animated voice.
</p>

<p class="note">
この~propにより供される機能性は，`~SSML$の
`prosody$sS 要素の `range^a 属性に類似するが、留意すべき不一致があることに注意。
例えば，この~propに対する［
音高~範囲~keyword値,
相対~変化~値（周波数, 半音単位, 百分率など）
］は、被選択~要素に値が継承され, 組合わされる法があることに因り，排他的でない。
◎
Note that although the functionality provided by this property is similar to the range attribute of the prosody element from the SSML markup language [SSML], there are notable discrepancies. For example, CSS Speech pitch range keywords and relative changes (frequency, semitone or percentage) are not mutually-exclusive, due to how values are inherited and combined for selected elements.
</p>

<div>
<p class="trans-note">【
各種 成分~値の定義と付帯する注釈は `voice-pitch$p のそれと同一なので，和訳は省略する。
】</p>

	<div lang="en">
<dl><!-- copy -->
	<dt>&lt;frequency&gt;</dt>
	<dd>
A value in frequency units (Hertz or kiloHertz, e.g. "100Hz", "+2kHz"). Values are restricted to positive numbers when the ‘absolute’ keyword is specified. Otherwise (when the ‘absolute’ keyword is not specified), a negative value represents a decrement, and a positive value represents an increment, relative to the inherited value. For example, "2kHz" is a positive offset (strictly equivalent to "+2kHz"), and "+2kHz absolute" is an absolute frequency (strictly equivalent to "2kHz absolute").
</dd>

	<dt>absolute</dt>
	<dd>
If specified, this keyword indicates that the specified frequency represents an absolute value. If a negative frequency is specified, the computed frequency will be zero.
</dd>

	<dt>&lt;semitones&gt;</dt>
	<dd>
Specifies a relative change (decrement or increment) to the inherited value. The syntax of allowed values is a &lt;number&gt; followed immediately by "st" (semitones). A semitone interval corresponds to the step between each note on an equal temperament chromatic scale. A semitone can therefore be quantified as the difference between two consecutive pitch frequencies on such scale. The ratio between two consecutive frequencies separated by exactly one semitone is the twelfth root of two (approximately 11011/10393, which equals exactly 1.0594631). As a result, the value in Hertz corresponding to a semitone offset is relative to the initial frequency the offset is applied to (in other words, a semitone doesn't correspond to a fixed numerical value in Hertz).
</dd>

	<dt>&lt;percentage&gt;</dt>
	<dd>
Positive and negative percentage values are allowed, to represent an increment or decrement (respectively) relative to the inherited value. Computed values are calculated by adding (or subtracting) the specified fraction of the inherited value, to (from) the inherited value. For example, 50% (which is equivalent to +50%) with a inherited value of 200Hz results in 200 + (200*0.5) = 300Hz. Conversely, -50% results in 200-(200*0.5) = 100Hz.
</dd>

	<dt>x-low</dt>
	<dt>low</dt>
	<dt>medium</dt>
	<dt>high</dt>
	<dt>x-high</dt>
	<dd>
A sequence of monotonically non-decreasing pitch levels that are implementation and voice specific. When the computed value for a given element is only a keyword (i.e. no relative offset is specified), then the corresponding absolute frequency will be re-evaluated on a voice change. Conversely, the application of a relative offset requires the calculation of the resulting frequency based on the current voice at the point at which the relative offset is specified, so the computed frequency will inherit absolutely regardless of any voice change further down the style cascade. Authors should therefore only use keyword values in cases where they wish that voice changes trigger the re-evaluation of the conversion from a keyword to a concrete, voice-dependent frequency.
	</dd>
</dl>

<p>
Computed absolute frequencies that are negative are clamped to zero Hertz. Speech-capable user agents are likely to support a specific range of values rather than the full range of possible calculated numerical values for frequencies. The actual values in user agents may therefore be clamped to implementation-dependent minimum and maximum boundaries. For example: although the 0Hz frequency can be legitimately calculated, it may be clamped to a more meaningful value in the context of the speech synthesizer.
</p>
	</div>
</div>


<div class="example">
<p>
継承値の例：
◎
Examples of inherited values:
</p>

<pre class="lang-ml">
&lt;body&gt;
  &lt;e1&gt;
    &lt;e2&gt;
      &lt;e3&gt;
        &lt;e4&gt;
          &lt;e5&gt;
            &lt;e6&gt;
            …
            &lt;/e6&gt;
          &lt;/e5&gt;
        &lt;/e4&gt;
      &lt;/e3&gt;
    &lt;/e2&gt;
  &lt;/e1&gt;
&lt;/body&gt;
</pre>
…
<pre class="lang-css">
body { voice-range: inherit; }
    /* <span class="comment">
初期値は `medium$v （実際の周波数の値は現在の~voiceに依存する)
◎
the initial value is 'medium' (the actual frequency value depends on the current voice)
</span> */

e1 { voice-range: +25%; }
    /* <span class="comment">
算出値は［
`medium$v + `25%^v
］であり，
( `medium$v に対応する周波数 ) + 0.25 × ( `medium$v に対応する周波数 )
に解決される
◎
the computed value is ['medium' + 25%] which resolves to the frequency corresponding to 'medium' plus 0.25 times the frequency corresponding to 'medium'
</span> */

e2 { voice-range: +10Hz; }
    /* <span class="comment">
算出値は ( %FREQ + 10Hz ) 。
ここで %FREQ は，上の "`e1^css" 規則にて計算される絶対~周波数。
◎
the computed value is [FREQ + 10Hz] where "FREQ" is the absolute frequency calculated in the "e1" rule above.
</span> */

e3 {
    voice-range: inherit;
    /* <span class="comment">
これは省略し得るが，明確さのために明示的に指定されている
◎
this could be omitted, but we explicitly specify it for clarity purposes
</span> */

    voice-family: "another-voice";
    /* <span class="comment">
この~voice変化により， `body^e 要素から継承された初期値の `medium$v ~keywordは再~評価される（すなわち，~voiceに依存する~keyword値から具体的な絶対~周波数に変換される）ことになるが、相対~差分は~styleの~cascadeにより深層へ伝わるので， `voice-range$p の実際の継承値は 上の "`e2^css" 規則にて計算される周波数になる。
◎
this voice change would have resulted in the re-evaluation of the initial 'medium' keyword inherited by the "body" element (i.e. conversion from a voice-dependent keyword value to a concrete, absolute frequency), but because relative offsets were applied down the style cascade, the inherited value is actually the frequency calculated at the "e2" rule above.
</span> */
}

e4 { voice-range: 200Hz absolute; }
    /* <span class="comment">
現在の~voiceに依存しない絶対~周波数で上書きする
◎
override with an absolute frequency which doesn't depend on the current voice
</span> */

e5 { voice-range: 2st; }
    /* <span class="comment">
算出値は、［
200Hz + 2 個の半音
］の計算から得られる，絶対~周波数（実際の周波数は，それを適用する基底~値に依存する半音に対応することに留意）
◎
the computed value is an absolute frequency, which is the result of the calculation: 200Hz + two semitones (reminder: the actual frequency corresponding to a semitone depends on the base value to which it applies)
</span> */

e6 {
    voice-range: inherit;
    /* <span class="comment">
これは省略し得るが，明確さのために明示的に指定されている
◎
this could be omitted, but we explicitly specify it for clarity purposes
</span> */

    voice-family: "yet-another-voice";
    /* <span class="comment">
~voice変化にかかわらず，
`voice-range$p の算出値は "`e5^css" に対するもの（すなわち、現在の~voiceから独立な，絶対~周波数による値）と同じになる
◎
despite the voice change, the computed value is the same as for "e5" (i.e. an absolute frequency value, independent from the current voice)
</span> */
}
</pre>

</div>


		</section>
		<section id="voice-props-voice-stress">
<h3 title="The ‘voice-stress’ property">12.5. `voice-stress^p ~prop</h3>

`voice-stress^vv

◎名 `voice-stress@p
◎値
`normal$v
| `strong$v
| `moderate$v
| `none$v
| `reduced$v
◎初 `normal$v
◎適 すべての要素
◎継 される
◎百 受容しない
◎算 指定値
◎表終

<p>
`voice-stress$p ~propは、［
音高の変化, ~timing変化, 聴感音量, 他の聴感上の相違
］の組合わせを利用して，通常時に適用される強勢の強度を操作する。
従って，これらの値の精確な意味は、発話されている自然言語に依存する。
◎
The ‘voice-stress’ property manipulates the strength of emphasis, which is normally applied using a combination of pitch change, timing changes, loudness and other acoustic differences. The precise meaning of the values therefore depend on the language being spoken.
</p>

<p class="note">
この~propにより供される機能性は、`~SSML$の`emphasis$sS 要素に類似することに注意。
◎
Note that the functionality provided by this property is similar to the emphasis element from the SSML markup language [SSML].
</p>

<dl class="value-defs">

	<dt>`normal@v</dt>
	<dd>
発話~合成器により生産される既定の強勢を表現する。
◎
Represents the default emphasis produced by the speech synthesizer.
</dd>

	<dt>`none@v</dt>
	<dd>
合成器が通常時には強勢する~textを，強勢させないようにする
◎
Prevents the synthesizer from emphasizing text it would normally emphasize.
</dd>

	<dt>`moderate@v</dt>
	<dt>`strong@v</dt>
	<dd>
これらの値は強度を表す。
後に挙げたものほど，強くなる（厳密には，より弱くない）。
<!-- non-decreasing -->
これらの適用の結果、発話~合成器が通常時に生産する強勢（すなわち，
`normal$v
に対応する値）は，より強められる。
◎
These values are monotonically non-decreasing in strength. Their application results in more emphasis than what the speech synthesizer would normally produce (i.e. more than the value corresponding to ‘normal’).
</dd>

	<dt>`reduced@v</dt>
	<dd>
<!-- 実質的には -->
上とは逆に，単語の強勢を抑制する。
◎
Effectively the opposite of emphasizing a word.
</dd>
</dl>

  <div class="example">
<p>
~HTML見本を伴う~prop値の例：
◎
Examples of property values, with HTML sample:
</p>

<pre class="lang-css">
.default-emphasis { voice-stress: normal; }
.lowered-emphasis { voice-stress: reduced; }
.removed-emphasis { voice-stress: none; }
.normal-emphasis { voice-stress: moderate; }
.huge-emphasis { voice-stress: strong; }
</pre>
…
<pre class="lang-ml">
&lt;p&gt;これは&lt;em&gt;ばかでかい&lt;/em&gt;車だ。&lt;/p&gt;
&lt;!-- <span class="comment">前の行†による発話~出力は，次の行と同じになる：

◎
The speech output from the line above is identical to the line below:
</span> --&gt;
&lt;p&gt;これは&lt;em class="default-emphasis"&gt;ばかでかい&lt;/em&gt;車だ。&lt;/p&gt;

&lt;p&gt;この車は&lt;em class="lowered-emphasis"&gt;ゴツい&lt;/em&gt;！&lt;/p&gt;
&lt;!-- <span class="comment">前の行の強勢は抑制されるのみである一方，次の "`em^e" は全く強勢されない：
◎
The "em" below is totally de-emphasized, whereas the emphasis in the line above is only reduced:
</span> --&gt;
&lt;p&gt;この車は&lt;em class="removed-emphasis"&gt;ゴツい&lt;/em&gt;！&lt;/p&gt;

&lt;!-- <span class="comment">下の 2 行は強勢~levelの増大を例示する：
◎
The lines below demonstrate increasing levels of emphasis:
</span> --&gt;
&lt;p&gt;これは&lt;em class="normal-emphasis"&gt;ばかでかい&lt;/em&gt;車だ！&lt;/p&gt;
&lt;p&gt;これは&lt;em class="huge-emphasis"&gt;ばかでかい&lt;/em&gt;車だ！！&lt;/p&gt;
</pre>

<p class="trans-note">【
† 原文は `em^e ~markup記述が明らかに抜け落ちていたと見られるので補完。
】</p>

</div>
<!-- 
This is a big car.
This car is massive!
 -->


		</section>
	</section>
	<section id="duration-props">
<h2 title="Voice duration property">13. ~voice持続時間~prop</h2>



		<section id="mixing-props-voice-duration">
<h3 title="The ‘voice-duration’ property">13.1. `voice-duration^p ~prop</h3>

`voice-duration^vv

◎名 `voice-duration@p
◎値
`auto$v
| `time$t
◎初 `auto$v
◎適 すべての要素
◎継 されない
◎百 受容しない
◎算 指定値
◎表終

<p>
`voice-duration$p ~propは、被選択~要素の内容が音声化される際に費やすべき時間を指定する（
`音声指示$, `~pause$, `~rest$
の時間は含まれない）。
値に `auto$v が指定されていない限り、この~propは `voice-rate$p ~propより優先され，~voiceに適した発話速度の決定に利用されるべきである。
`voice-duration$p ~propの値が `auto$v でない要素の，子孫に指定されている［
`voice-duration$p, `voice-rate$p
］~propは、無視されなければならない。
すなわち，被選択~要素~上の
`voice-duration$p に指定された `time$t は、要素の部分木~全体に適用される（子はこの~propを上書きできない）。
◎
The ‘voice-duration’ property specifies how long it should take to render the selected element's content (not including audio cues, pauses and rests ). Unless the value ‘auto’ is specified, this property takes precedence over the ‘voice-rate’ property, and should be used to determine a suitable speaking rate for the voice. An element for which the ‘voice-duration’ property value is not ‘auto’ may have descendants for which the ‘voice-duration’ and ‘voice-rate’ properties are specified, but these must be ignored. In other words, when a ‘time’ is specified for the ‘voice-duration’ of a selected element, it applies to the entire element subtree (children cannot override the property).
</p>

<p class="note">
この~propにより供される機能性は、`~SSML$の `prosody$sS 要素の `duration^a 属性に類似することに注意。
◎
Note that the functionality provided by this property is similar to the duration attribute of the prosody element from the SSML markup language [SSML].
</p>

<dl class="value-defs">
	<dt>`auto@v</dt>
	<dd>
継承される `voice-rate$p を利用している場合は、発話~合成の持続時間に対応する使用値に解決される。
◎
Resolves to a used value corresponding to the duration of the speech synthesis when using the inherited ‘voice-rate’.
</dd>

	<dt>`time@t</dt>
	<dd>
`時間$単位（秒／ミリ秒）による絶対的な値を指定する（例えば
`+3s^v, `250ms^v
）。
非負の値のみ許容される。
◎
Specifies a value in absolute time units (seconds and milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed.
</dd>
</dl>



		</section>
	</section>
	<section id="lists">
<h2 title="List items and counters styles">14. ~list~itemと~counter~style</h2>

<p>
`CSS21$r の `list-style-type$p ~propは、［
~glyph, 付番~system, ~alphabet式~system
］の， 3 種いずれかによる~list~item~markerを指定する。
この~propに許容される値は、 `content$p ~propにおける `counter^f 関数にも利用される。
この~moduleは、これらの~styleが`聴覚~次元$において発話~合成を利用してどの様に音声化されるかを定義する。
`CSS21$r の `list-style-image$p ~propは無視され，代わりに `list-style-type$p が利用される。
◎
The ‘ list-style-type’ property of [CSS21] specifies three types of list item markers: glyphs, numbering systems, and alphabetic systems. The values allowed for this property are also used for the counter() function of the ‘content’ property. The CSS Speech module defines how to render these styles in the aural dimension, using speech synthesis. The ‘list-style-image’ property of [CSS21] is ignored, and instead the ‘list-style-type’ is used.
</p>

<p class="note">
CSS Lists and Counters Module Level 3
`CSS3LIST$r
による新たな特色機能に対する発話~音声化は、この~levelのこの仕様の対象外にあるが，将来の仕様にて定義され得ることに注意。
【CSS Counter Style ~moduleにて
<a href="css-counter-styles-ja.html#counter-style-speak-as">定義されている</a>。】
◎
Note that the speech rendering of new features from the CSS Lists and Counters Module Level 3 [CSS3LIST] is not covered in this level of CSS Speech, but may be defined in a future specification.
</p>

<dl>
	<dt>`disc^v</dt>
	<dt>`circle^v</dt>
	<dt>`square^v</dt>
	<dd>
これらの~list~item~styleに対しては、~UAが［
どの等価な~phraseが発話されるか, あるいは
どの音声指示が再生されるか
］を定義する（場合によっては、利用者の選好に基づいて）。
従って，~graphic的な~bullet（箇条書き記号）を伴う~list~itemは、実装に依存する方式で適切に発声される。
◎
For these list item styles, the user agent defines (possibly based on user preferences) what equivalent phrase is spoken or what audio cue is played. List items with graphical bullets are therefore announced appropriately in an implementation-dependent manner.
</dd>

	<dt>`decimal^v</dt>
	<dt>`decimal-leading-zero^v</dt>
	<dt>`lower-roman^v</dt>
	<dt>`upper-roman^v</dt>
	<dt>`georgian^v</dt>
	<dt>`armenian^v</dt>
	<dd>
これらの~list~item~styleに対しては、対応する数がそのままの形で 発話~合成器により，発話される。
また、~list~itemの~~存在を指示するために，追加の［
音声指示または［
文書の自然言語による（すなわち，~list~itemの内容を発話するものと同じ~TTS~voiceによる）発話~phrase
］］も補われ得る。
例えば，~Englishが利用されているときは、各~list~item~counterの前に単語 `Item^en が補われる結果，~list~itemは
`Item one^en, `Item two^en,
等々と発声されることになるであろう。
◎
For these list item styles, corresponding numbers are spoken as-is by the speech synthesizer, and may be complemented with additional audio cues or speech phrases in the document's language (i.e. with the same TTS voice used to speak the list item content) in order to indicate the presence of list items. For example, when using the English language, the list item counter could be prefixed with the word "Item", which would result in list items being announced with "Item one", "Item two", etc.
</dd>

	<dt>`lower-latin^v</dt>
	<dt>`lower-alpha^v</dt>
	<dt>`upper-latin^v</dt>
	<dt>`upper-alpha^v</dt>
	<dt>`lower-greek^v</dt>
	<dd>
これらの~list~item~styleは、文書の自然言語の下で（すなわち，~list~itemの内容を発話するものと同じ~TTS~voiceを利用して），発話~合成器により 一字ごとに読み綴られる。
例えば，~Englishの下での `lower-greek^v は、［
`alpha^en, `beta^en, `gamma^en, 等々
］と読上げられるであろう。
対して、~Frenchの下での `upper-latin^v は，音標による記法で［
<samp>/a/</samp>, <samp>/be/</samp>, <samp>/se/</samp>, 等々
］と読上げられるであろう。
◎
These list item styles are spelled out letter-by-letter by the speech synthesizer, in the document language (i.e. with the same TTS voice used to speak the list item content). For example, ‘lower-greek’ in English would be read out as "alpha", "beta", "gamma", etc. Conversely, ‘upper-latin’ in French would be read out as /a/, /be/, /se/, etc. (phonetic notation)
</dd>
</dl>

<p class="note">
~screen-readerなどの~UAでは、~list~itemが入子にされた深さを発声したり、より一般には，複雑な階層的~内容に伴われる構造的~情報を追加で指示することが共通的に行われている。
この種の追加の［
音声指示や発話~出力
］の詳細度合いは、通例的には利用者により制御され，利便性に寄与する。
この種の~navi援助は実装に依存するが，
この~moduleを~supportする~UAには、この種の音声指示や発話~出力に際し，［［
冗長さが生成される／一貫性が損なわれる
］ことはないことを確保する
］ことが推奨される（例えば、同じ~listの~itemたちに複数の付番方式が~~適用されないようにするなど）。
◎
Note that it is common for user agents such as screen readers to announce the nesting depth of list items, or more generally, to indicate additional structural information pertaining to complex hierarchical content. The verbosity of these additional audio cues and/or speech output can usually be controlled by users, and contribute to increasing usability. These navigation aids are implementation-dependent, but it is recommended that user agents supporting the CSS Speech module ensure that these additional audio cues and speech output don't generate redundancies or create inconsistencies (for example: duplicated or different list item numbering scheme).
</p>

	</section>
	<section id="content">
<h2 title="Inserted and replaced content">15. 挿入される内容と置換される内容</h2>

~INFORMATIVE

<p>
定例の発音~規則の適用に先立ち，~source~textから別の文字列への対応付けを指定したいと，作者から求められることもある。
これは、共通的な略語や頭字語ではない，合成器からは認識されそうにないものに利用され得る。
`content$p ~propは、文字列を別の文字列に置換するために利用できる。
この~propにより供される機能性は、`~SSML$の `sub$sS 要素の `alias^a 属性に類似することに注意。
◎
Sometimes, authors will want to specify a mapping from the source text into another string prior to the application of the regular pronunciation rules. This may be used for uncommon abbreviations or acronyms which are unlikely to be recognized by the synthesizer. The ‘content’ property can be used to replace one string by another. The functionality provided by this property is similar to the alias attribute of the sub element from the SSML markup language [SSML].
</p>

<div class="example">
<p>
次の例では、略語の音声化に際し，要素の内容の代わりに `title^a 属性の内容が利用される。
◎
In this example, the abbreviation is rendered using the content of the title attribute instead of the element's content.
</p>

<pre class="lang-css">
    /* <span class="comment">
これは、被選択~要素の内容を 文字列 "World Wide Web Consortium" に置き換える。
◎
This replaces the content of the selected element by the string "World Wide Web Consortium".
</span> */
abbr { content: attr(title); }
</pre>
…
<pre class="lang-ml">
&lt;abbr title="World Wide Web Consortium"&gt;W3C&lt;/abbr&gt;
</pre>

</div>

<p>
同様の仕方で、文書~内の~text文字列も，予め録音-済みの~versionに置換できる。
◎
In a similar way, text strings in a document can be replaced by a previously recorded version.
</p>

<div class="example">
<p>
次の例では、 `Sir John Gielgud^en による著名な~monologueの朗読の録音が再生される。
ここでは、［
その形式は~supportされていて, かつ
~fileは可用であり, かつ
~UAはそうするよう環境設定されている
］とする
— 他の場合，~UAは、合成された発話により~textを音声化するよう~fall-backすることになる。
◎
In this example - assuming the format is supported, the file is available and the UA is configured to do so - a recording of Sir John Gielgud's declamation of the famous monologue is played. Otherwise the UA falls back to render the text using synthesized speech.
</p>

<pre class="lang-css">
.hamlet { content: url(./audio/gielgud.wav); }
</pre>
…
<pre class="lang-ml">
&lt;div class="hamlet"&gt;
To be, or not to be: that is the question:
&lt;/div&gt;
</pre>

</div>

<p>
更に，作者（または利用者~stylesheetを用いる利用者）は、文書との非~視覚的な対話において 構造を理解し易くするための，何らかの情報を追加してもよい。
それらは［
`before^pe ／ `after^pe
］疑似要素を利用して追加できる。
複数の~stylesheetを利用すれば、~screen-readerから発話される追加の情報の詳細度合いを複数~level定義できることに注意。
◎
Furthermore, authors (or users via a user stylesheet) may add some information to ease the understanding of structures during non-visual interaction with the document. They can do so by using the ‘::before’ and ‘::after’ pseudo-elements. Note that different stylesheets can be used to define the level of verbosity for additional information spoken by screen readers.
</p>

<div class="example">
<p>
この例では、~listの前に文字列
"箇条書き~~開始。"
を挿入し,
各~list~itemの内容の前に文字列
"一つ、"
を挿入する。
同様に、~listの後には，利用者に~listの発話~出力を終えたことを伝えるための文字列
"箇条書き~~終了。"
が挿入される。
◎
This example inserts the string "Start list: " before a list and the string "List item: " before the content of each list item. Likewise, the string "List end: " gets inserted after the list to inform the user that the list speech output is over.
</p>

<pre class="lang-css">
ul::before { content: "箇条書き~~開始。"; }
ul::after  { content: "一つ、"; }
li::before { content: "箇条書き~~終了。"; }
</pre>

<!-- 
ul::before { content: "Start list: "; }
ul::after  { content: "List end. "; }
li::before { content: "List item: "; }
 -->
</div>

<p>
より詳細な情報は
`CSS 3 Generated and Replaced Content ~module^en
`CSS-CONTENT-3$r
にて見られる。
◎
Detailed information can be found in the CSS3 Generated and Replaced Content module [CSS-CONTENT-3].
</p>

	</section>
	<section id="pronunciation">
<h2 title="Pronunciation, phonemes">16. 発音と音素</h2>

~INFORMATIVE

<p>
~CSSは、~markup文書~内の特定0の~text片の発音（きちんと定義された音標~alphabetで表される）については，それを定義する方法を指定しない。
この仕様の以前の草案では， “音素” （ `phonemes^en ）~propについて述べられていたが、内容と呈示の分離の原則に抵触するとして，異論が提起された（聴覚~CSS~stylesheet内に著作された “音素” は、~markup文書~内の~textが変更される度に更新される必要がある）。
従って， “音素” の機能性は、~CSS（呈示~層）の視野~外にあると見なされており，~markup層／内容~層において取組まれるべきである。
◎
CSS does not specify how to define the pronunciation (expressed using a well-defined phonetic alphabet) of a particular piece of text within the markup document. A "phonemes" property was described in earlier drafts of this specification, but objections were raised due to breaking the principle of separation between content and presentation (the "phonemes" authored within aural CSS stylesheets would have needed to be updated each time text changed within the markup document). The "phonemes" functionality is therefore considered out-of-scope in CSS (the presentation layer) and should be addressed in the markup / content layer.
</p>

<p>
`rel^a 値に
<a href="http://microformats.org/wiki/rel-pronunciation">"`pronunciation^v"</a>
を伴う
`link^e 要素を利用すれば（~CSS~stylesheetを含めるときと同様の方法で）， ~HTML文書に発音~lexiconを取り込めるようになる。
W3C PLS （ `Pronunciation Lexicon Specification^en ）
`PRONUNCIATION-LEXICON$r
は、その種の~lexiconを記述するために利用できる形式の一つである。
◎
The "pronunciation" rel value allows importing pronunciation lexicons in HTML documents using the link element (similar to how CSS stylesheets can be included). The W3C PLS (Pronunciation Lexicon Specification) [PRONUNCIATION-LEXICON] is one format that can be used to describe such a lexicon.
</p>

<p>
加えて，~markup内では、~textと発音の結び付けの著作に，属性に基づく仕組みを利用できる。
その種の仕組みは、この仕様が書かれた時点では， W3C ~HTML標準では公式的に定義されていない。
しかしながら，
<a href="http://idpf.org/epub/30">EPUB 3.0 仕様</a>
では、 `SSML$r 仕様から導出された［
~textを特定0の音標~alphabetに基づいて発音する方法
］を記述する属性を，~HTML文書に含ませることが許容されている。
◎
Additionally, an attribute-based mechanism can be used within the markup to author text-pronunciation associations. At the time of writing, such mechanism isn't formally defined in the W3C HTML standard(s). However, the EPUB 3.0 specification allows (x)HTML5 documents to contain attributes derived from the [SSML] specification, that describe how to pronounce text based on a particular phonetic alphabet.
</p>


<!-- p> 
One avenue to explore is the use CSS to "bind" HTML text with a 
phoneme (also declared in the HTML document). This would maintain a 
clear separation between content and presentation, and it would allow 
authors to define different pronunciations for one given text token 
(Media Queries could drive the switch of stylesheet to import). This 
possibility has been mentioned several times by Working Group members 
as well as people from the public mailing-list, so it cannot be 
ignored. However, there are architectural considerations (e.g. 
collision between CSS versus HTML -defined phonemes) which make this a 
lot trickier to standardize than it sounds. The 
whole "speech synthesis" issue should be tackled globally at the level 
of the W3C ecosystem. For example, there are many cross-cutting 
concerns with the work done by the HTML-Audio and HTML-Speech 
Incubator Groups.
      </p -->


	</section>
	<section id="ack">
<h2 title="Acknowledgements">謝辞</h2>

<p>
この仕様の策定に援助された
W3C Voice Browser ／ Cascading Style Sheets 
ワーキンググループのメンバに感謝する。
詳細な~commentを寄せられた, Ellen Eide 氏（ IBM ）と，入念に検討された Elika Etemad 氏（ Fantasai ）に特に感謝する。
◎
The editors would like to thank the members of the W3C Voice Browser and Cascading Style Sheets working groups for their assistance in preparing this specification. Special thanks to Ellen Eide (IBM) for her detailed comments, and to Elika Etemad (Fantasai) for her thorough reviews.
</p>

	</section>
	<section id="changes">
<h2 title="Changes from previous draft">以前の草案からの変更点</h2>

<p>
<a href="https://www.w3.org/TR/2012/CR-css3-speech-20120320/">2012 年 勧告候補</a>
からの変更点は：
◎
The following changes have been made since the 2012 Candidate Recommendation:
</p>

<ul>
	<li>
明確さのため、 `speak$p ~propの
`none^v,
`normal^v
値を，順に
`never^v,
`always^v
に改称した。
◎
Renamed the ‘none’ and ‘normal’ values of ‘speak’ to ‘never’ and ‘always’ for clarity. 
</li>
	<li>
`speak$p に対する `auto^v 値は、
`visibility$p に呼応するようにされた。
<a href="~CSSissue/511">Issue 511</a>
を見よ。
◎
Made the ‘auto’ value of ‘speak’ respond to ‘visibility’. See Issue 511.
</li>

</ul>


	</section>

</main></div>
