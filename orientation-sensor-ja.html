<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8" />
<title>Orientation Sensor（日本語訳）</title>

<link rel="stylesheet" href="common.css" type="text/css" />
<link rel="stylesheet" href="common-w3c.css" type="text/css" />


<style>

</style>

<script src="common0.js" ></script>
<script src="common1.js" async></script>

<script>

Util.ready = function(){
	const source_data = {
		toc_main: 'MAIN0',
		collectParts: Util.collectParts,
		generate: expand
	};
	Util.switchWordsInit(source_data);
}

function expand(){
	const class_map = this.class_map;
	const tag_map = this.tag_map;
	const link_map = this.link_map;

	return this.html.replace(
		/%[\w\-~一-鿆あ-ん]+|`(.+?)([$@\^])(\w*)/g,
		create_html
	);

	function create_html(match, key, indicator, klass){

if(!key) {//%
	return `<var>${match.slice(1)}</var>`;
}

let text = key;
let href = '';

switch(klass){
case 'r':
	text = `[${key}]`;
	href = `#biblio-${key.toLowerCase()}`;
	break;
case 'l':
	text = `"<code class="literal">${text}</code>"`;
	break;
case 'm':
	const n = text.indexOf('(');
	if(n > 0){
		key = text.slice(0, n);
		text = key + text.slice(n).replace(/\w+/g, '<var>$&</var>');
	}
	break;
case 'mc':
	text = 'constructor';
	klass = 'm';
	break;
case 'dgm':
	return `<a id="_dgm-${key}">＊</a>`;
	break;
case 'en':
	return `<span lang="en-x-a0">${key}</span>`;
	break;
}

let tag = tag_map[klass];
if(tag) {
	let classname = class_map[klass];
	classname = classname ? ` class="${classname}"` : '';
	text = `<${tag}${classname}>${text}</${tag}>`;
}

if(indicator !== '^'){
	href = link_map[ klass ? `${klass}.${key}` : key ] || href;
	if(!href){
		console.log(match); // check error
		return match;
	}

	switch(indicator){
	case '$':
		text = `<a href="${href}">${text}</a>`;
		break;
	case '@':
		text = `<dfn id="${href.slice(1)}">${text}</dfn>`;
		break;
	}
}

return text;


	}
}

</script>


<script type="text/plain" id="_source_data">


●●options

spec_title:Orientation Sensor
spec_date:2019-12-12
trans_update:2019-09-26
source_checked:190809
spec_status:CR
original_url:https://www.w3.org/TR/orientation-sensor/
	https://w3c.github.io/orientation-sensor/
	abbr_url:ORIENTATION-SENSOR
ref_id_prefix:biblio-
ref_id_lowercase:true
page_state_key:SENSORS
site_nav:sensors
ref_id_lowercase:true
copyright:2019,permissive
trans_1st_pub:2019-08-23
conformance:w3c

●●class_map
E:error
et:event-type
e:element
a:attr
hm:method
op:op

●●tag_map
I:code
E:code
m:code
c:code
mb:code
cite:cite
et:code
a:code
e:code
i:i
hm:code
em:em
op:span

●●original_id_map

●●mdn_urls
absoluteorientationsensor:API/AbsoluteOrientationSensor
orientationsensor:API/OrientationSensor
relativeorientationsensor:API/RelativeOrientationSensor
	dictdef-absoluteorientationreadingvalues:API/AbsoluteOrientationReadingValues
	dictdef-orientationsensoroptions:API/OrientationSensorOptions
	dictdef-relativeorientationreadingvalues:API/RelativeOrientationReadingValues
	enumdef-orientationsensorlocalcoordinatesystem:API/OrientationSensorLocalCoordinateSystem
	typedefdef-rotationmatrixtype:API/RotationMatrixType

●●link_map

	●IDL

Exposed:~WEBIDL#Exposed
SecureContext:~WEBIDL#SecureContext

Float32Array:~WEBIDL#idl-Float32Array
Float64Array:~WEBIDL#idl-Float64Array
I.Float32Array:~WEBIDL#idl-Float32Array
I.Float64Array:~WEBIDL#idl-Float64Array
FrozenArray:~WEBIDL#idl-frozen-array
double:~WEBIDL#idl-double

E.NotReadableError:~WEBIDL#notreadableerror
E.SecurityError:~WEBIDL#securityerror
E.TypeError:~WEBIDL#exceptiondef-typeerror
	I.DOMException:~WEBIDL#idl-DOMException
I.AbsoluteOrientationReadingValues:#dictdef-absoluteorientationreadingvalues
I.AbsoluteOrientationSensor:#absoluteorientationsensor
I.Accelerometer:~ACCELEROMETER#accelerometer
I.DOMMatrix:~GEOMETRY#dommatrix
I.DeviceOrientationEvent:~DEVICEORIENTATION#deviceorientationevent
	https://www.w3.org/TR/2016/CR-orientation-event-20160818/#deviceorientation_event
I.Gyroscope:~GYROSCOPE#gyroscope
I.Magnetometer:~MAGNETOMETER#magnetometer
I.OrientationSensor:#orientationsensor
I.OrientationSensorLocalCoordinateSystem:#enumdef-orientationsensorlocalcoordinatesystem
I.OrientationSensorOptions:#dictdef-orientationsensoroptions
I.RelativeOrientationReadingValues:#dictdef-relativeorientationreadingvalues
I.RelativeOrientationSensor:#relativeorientationsensor
I.RotationMatrixType:#typedefdef-rotationmatrixtype
I.Sensor:~SENSORS#sensor
I.SensorOptions:~SENSORS#dictdef-sensoroptions


l.absolute-orientation:~SENSORS#dom-mocksensortype-absolute-orientation
l.relative-orientation:~SENSORS#dom-mocksensortype-relative-orientation
	l.accelerometer:~SENSORS#dom-mocksensortype-accelerometer
	l.gyroscope:~SENSORS#dom-mocksensortype-gyroscope
	l.magnetometer:~SENSORS#dom-mocksensortype-magnetometer

l.device:#dom-orientationsensorlocalcoordinatesystem-device
l.screen:#dom-orientationsensorlocalcoordinatesystem-screen


m.onerror:~SENSORS#dom-sensor-onerror
m.populateMatrix:#dom-orientationsensor-populatematrix
m.quaternion:#dom-orientationsensor-quaternion
mb.quaternion:#dom-absoluteorientationreadingvalues-quaternion
m.referenceFrame:#dom-orientationsensoroptions-referenceframe
m.start:~SENSORS#dom-sensor-start

m.AbsoluteOrientationSensor:#dom-absoluteorientationsensor-absoluteorientationsensor
m.RelativeOrientationSensor:#dom-relativeorientationsensor-relativeorientationsensor

	%sensorOptions:#dom-absoluteorientationsensor-absoluteorientationsensor-sensoroptions-sensoroptions
	%sensorOptions:#dom-relativeorientationsensor-relativeorientationsensor-sensoroptions-sensoroptions
	%targetMatrix:#dom-orientationsensor-populatematrix-targetmatrix-targetmatrix

	●用語
i.方位~sensor:#orientation-sensor
方位~sensor~objを構築する:#construct-an-orientation-sensor-object
~stationary基準~座標系:#stationary-reference-coordinate-system
回転~行列を拡充する:#populate-rotation-matrix
地球の基準~座標系:#earths-reference-coordinate-system

	●用語（sensor

~sensor型:~SENSORS#sensor-type
~sensor融合:~SENSORS#sensor-fusion
~supportする~sensor~options:~SENSORS#supported-sensor-options
~sensor~hub:~SENSORS#sensor-hubs
低level:~SENSORS#low-level
局所~座標系:~SENSORS#local-coordinate-system
最新な読取り~map:~SENSORS#latest-reading

~sensor~accessを要請する:~SENSORS#request-sensor-access
~sensor~objを初期化する:~SENSORS#initialize-a-sensor-object
~sensor施策により制御される特能を検査する:~SENSORS#check-sensor-policy-controlled-features
最新な読取り~mapから値を取得する:~SENSORS#get-value-from-latest-reading

模擬~sensor型:~SENSORS#mock-sensor-type
模擬~sensor読取り値たち:~SENSORS#mock-sensor-reading-values

	~SENSORS#equivalent
	~SENSORS#automation

相対~方位~sensor:~MOTION-SENSORS#relative-orientation-sensor
絶対~方位~sensor:~MOTION-SENSORS#absolute-orientation-sensor
	相対~方位~sensor:~MOTION-SENSORS#relative-orientation
	絶対~方位~sensor:~MOTION-SENSORS#absolute-orientation

	●用語（外部
継承した~interfaceたち:~WEBIDL#dfn-inherited-interfaces
識別子:~WEBIDL#dfn-identifier
~interface:~WEBIDL#dfn-interface
凍結d配列:~WEBIDL#dfn-frozen-array-type


~list:~INFRA#list
map.~entry:~INFRA#map-entry
map.~key:~INFRA#map-key
map.値:~INFRA#map-value
	~THROW:~WEBIDL#dfn-throw

~screen座標系:~ACCELEROMETER#screen-coordinate-system
~device座標系:~ACCELEROMETER#device-coordinate-system
~event~handler:~WAPI#event-handlers
cite.Motion Sensors Explainer:~MOTION-SENSORS#usecases-and-requirements


●●words_table1

DEVICEORIENTATION:deviceorientation-ja.html
MOTION-SENSORS:motion-sensors-ja.html
ACCELEROMETER:accelerometer-ja.html
MAGNETOMETER:magnetometer-ja.html
GYROSCOPE:gyroscope-ja.html


theta:<var>θ</var>

●●words_table

	●幾何
motion::::モーション
方位:orientation::~
gyroscope::::ジャイロスコープ
磁場:magnetic field::~
hub::::ハブ
地球:Earth:~
Cartesian:::直交
座標系:coordinate system::~
垂直:perpendicular::~
磁北:magnetic north::~
四元数:quaternion::~
回転:rotation::~
地面:ground::~
天:sky::~
平坦:flat::~
	平坦~化:flatten
平面:plane::~
慣性-:inertial::~
東:east::~
基準:reference::~
次元な:dimensional::次元の
vector-product:vector product:::クロス積
stationary:
vector::::ベクター
drift:
drifting:
真北:true north::~
w:
x:
y:
z:
角度:angle::~
列主導順:column-major order:~
	周り:about
整列-:align::~
行列:matrix::~
	~z位置:z-position
	接して:tangential
	へ向かって:toward
	指す:point／points towards

	●sensor／計測
device:
hub:
sensor::::センサ
低level:low-level:低 level::低レベル
scalar::::スカラー
単位:unit:~
融合:fusion::~
読取り:reading::読み取り
最新な:latest:~
具体:concrete::~
模擬:mock::~

	次第にずれる:drift／:drift over time

	●仕様
自動化:automation:~
WebGL:
framework::::フレームワーク
	汎用~sensor~API／^en:Generic Sensor API
	方位~sensor~API／^en:Orientation Sensor API

	来る:go
	~~未然に~~防ぐ:obviating
	との関係で:in relation to
	-:according to
	満たす:satisfy
	図:figure

	●未分類
偏り:bias:~
監視-:monitor:~
凍結d:frozen::~
安定的:stable:~
描く:drawする:~
	~~登録:subscribe
compass::::コンパス

	模擬する:mocking
	環境設定-可能:configurable
	表:table
	-:in other words
	含む:includeする

	●指示語
	大部分:most
	16:sixteen
	3 :three
	4 個の:four
	非:non
	部分:part

	●変数
	%V*:V*
	%q*
	%方位~interface:orientation_interface
	%M:targetMatrix

●●ref_normative

[ACCELEROMETER]
    Anssi Kostiainen. Accelerometer. 7 March 2019. WD. URL: https://www.w3.org/TR/accelerometer/ 
[GENERIC-SENSOR]
    Mikhail Pozdnyakov; Alexander Shalamov; Tobie Langel. Generic Sensor API. 7 March 2019. WD. URL: https://www.w3.org/TR/generic-sensor/ 
[GEOMETRY-1]
    Simon Pieters; Chris Harrelson. Geometry Interfaces Module Level 1. 4 December 2018. CR. URL: https://www.w3.org/TR/geometry-1/ 
[GYROSCOPE]
    Anssi Kostiainen. Gyroscope. 7 March 2019. WD. URL: https://www.w3.org/TR/gyroscope/ 
[INFRA]
    Anne van Kesteren; Domenic Denicola. Infra Standard. Living Standard. URL: https://infra.spec.whatwg.org/ 
[MAGNETOMETER]
    Anssi Kostiainen; Rijubrata Bhaumik. Magnetometer. 7 March 2019. WD. URL: https://www.w3.org/TR/magnetometer/ 
[RFC2119]
    S. Bradner. Key words for use in RFCs to Indicate Requirement Levels. March 1997. Best Current Practice. URL: https://tools.ietf.org/html/rfc2119 
[WEBIDL]
    Boris Zbarsky. Web IDL. 15 December 2016. ED. URL: https://heycam.github.io/webidl/ 

●●ref_informative

[HTML]
    Anne van Kesteren; et al. HTML Standard. Living Standard. URL: https://html.spec.whatwg.org/multipage/ 
[QUATCONV]
    Watt, Alan H., and Mark Watt.. Advanced animation and rendering techniques., page 362. 1992. Informational. URL: http://www.cs.cmu.edu/afs/cs/academic/class/15462-s14/www/lec_slides/3DRotationNotes.pdf 
[QUATERNIONS]
    Kuipers, Jack B. Quaternions and rotation sequences. Vol. 66.. 1999. Informational. URL: http://www.emis.ams.org/proceedings/Varna/vol1/GEOM09.pdf 
[SI]
    SI Brochure: The International System of Units (SI), 8th edition. 2014. URL: http://www.bipm.org/en/publications/si-brochure/ 

●●trans_metadata
<p>
~THIS_PAGEは、~W3Cにより
勧告候補として公開された
<a href="~SPEC_URL">Orientation Sensor</a>
を日本語に翻訳したものです。
~PUB

●●spec_metadata

このバージョン
	https://www.w3.org/TR/2019/CR-orientation-sensor-20191212/
最新発行バージョン
	https://www.w3.org/TR/orientation-sensor/
以前のバージョン
	https://www.w3.org/TR/2019/WD-orientation-sensor-20190307/
編集者草案
	https://w3c.github.io/orientation-sensor/
バージョン履歴
	https://github.com/w3c/orientation-sensor/commits/master/index.bs
フィードバック
	<a href="mailto:public-device-apis@w3.org?subject=%5Borientation-sensor%5D%20YOUR%20TOPIC%20HERE">public-device-apis@w3.org</a> with subject line “<kbd>[orientation-sensor] <i>… message topic …</i></kbd>” (<a href="https://lists.w3.org/Archives/Public/public-device-apis/" rel="discussion">archives</a>)
最新の課題
	<a href="https://github.com/w3c/orientation-sensor/issues/">GitHub</a>
編集
	<a href="https://intel.com/">Kenneth Rohde Christiansen</a> (Intel Corporation)
	<a href="https://intel.com/">Anssi Kostiainen</a> (Intel Corporation)
前任編集者
	<a href="https://intel.com/">Mikhail Pozdnyakov</a> (Intel Corporation)
	<a href="https://intel.com/">Alexander Shalamov</a> (Intel Corporation)
バグ報告
	<a href="https://www.github.com/w3c/orientation-sensor/issues/new">via the w3c/orientation-sensor repository on GitHub</a>
テスト一式
	<a href="https://github.com/web-platform-tests/wpt/tree/master/orientation-sensor">web-platform-tests on GitHub</a>
mailing list
	<a href="mailto:public-device-apis@w3.org?Subject=%5Borientation-sensor%5D%20PUT%20SUBJECT%20HERE">public-device-apis@w3.org</a> (<a href="mailto:public-device-apis-request@w3.org?subject=subscribe">subscribe</a>, <a href="https://lists.w3.org/Archives/Public/public-device-apis/">archives</a>)
発行者
	<a href="https://www.w3.org/das/">Devices and Sensors Working Group</a>
</script>
</head>
<body>
<!--%resource pool -->
<div id="_persisted_parts" hidden>
<img
	id="_dgm-absolute_orientation_sensor_coordinate_system"
	alt="AbsoluteOrientationSensor coordinate system."
	src="orientation-sensor/absolute_orientation_sensor_coordinate_system.png"
	style="width:375px; height:375px;"
>
<img
	id="_dgm-quaternion_to_rotation_matrix"
	alt="Converting quaternion to rotation matrix."
	src="orientation-sensor/quaternion_to_rotation_matrix.png"
	style="width: 397px; height: 102px;"
>

</div>

<header>
	<hgroup>
<h1>方位センサ — Orientation Sensor</h1>
	</hgroup>
</header>

<div id="MAIN" hidden>

	<section id="abstract">
~ABSTRACT

<p>
この仕様は、［
~deviceの物理的な方位を~stationary【定常／静止】な 3 次元な~Cartesian座標系との関係で監視する
］ための，基底~方位~sensor~interface,
および各種~具体~sensor下位classを定義する。
◎
This specification defines a base orientation sensor interface and concrete sensor subclasses to monitor the device’s physical orientation in relation to a stationary three dimensional Cartesian coordinate system.
</p>

	</section>
	<section id="status">
~STATUSofTHIS

<p>
この節では、発行時点における…
【以下、この節の他の内容は <a href="w3c-common-ja.html#status" >W3C 日本語訳 共通ページ</a>／冒頭の仕様~metadataに委譲。】
</p>

	</section>

<main id="MAIN0">

	<section id="_conventions">
<h2 class="trans-note">【この訳に固有の表記規約】</h2>

<p>
この訳の，~algoや定義の記述に利用されている各種記号（ ~LET, ~EQ, ~IN, ~IF, ~THROW, 等々）の意味や定義の詳細は、~SYMBOL_DEF_REFを~~参照されたし。
</p>
	</section>
	<section id="intro">
<h2 title="Introduction">1. 序論</h2>

<p>
方位~sensor~API （ `Orientation Sensor API^en ）は、［
~deviceの物理的~方位を
3 次元な~Cartesian座標系との関係で述べる汎用~情報
］を供するため，
汎用~sensor~API（ `Generic Sensor API^en ） `GENERIC-SENSOR$r を拡張する。
◎
The Orientation Sensor API extends the Generic Sensor API [GENERIC-SENSOR] to provide generic information describing the device’s physical orientation in relation to a three dimensional Cartesian coordinate system.
</p>

<p>
`AbsoluteOrientationSensor$I ~classは、
`OrientationSensor$I ~interfaceを継承し，
~deviceの物理的~方位を`地球の基準~座標系$との関係で述べる。
◎
The AbsoluteOrientationSensor class inherits from the OrientationSensor interface and describes the device’s physical orientation in relation to the Earth’s reference coordinate system.
</p>

<p>
他の下位classは、［
真北【北極】や非~stationary方向などの，他の~stationary方向
］との関係で方位を述べる
— ~deviceの自前の~z位置との関係で，最新な最も安定的な~z位置へ向かって次第にずれる（ `drift^en ）様な。【？】
◎
Other subclasses describe the orientation in relation to other stationary directions, such as true north, or non stationary directions, like in relation to a devices own z-position, drifting towards its latest most stable z-position.
</p>

<p>
`OrientationSensor$I 下位classが供する~dataは、
`DeviceOrientationEvent$I からの~dataに類似するが，
方位~sensor~APIには，次に挙げる有意な相違点がある
— `OrientationSensor$I 下位classは：
◎
The data provided by the OrientationSensor subclasses are similar to data from DeviceOrientationEvent, but the Orientation Sensor API has the following significant differences:
</p>
<ol>
	<li>
~WebGLに互換な形式（四元数（ `quaternion^en ）, 回転~行列）で方位~dataを表現する。
◎
The Orientation Sensor API represents orientation data in WebGL-compatible formats (quaternion, rotation matrix).
</li>
	<li>
より厳密な待時間~要件を満たす。
◎
The Orientation Sensor API satisfies stricter latency requirements.
</li>
	<li>
方位~dataを得るときに，どの`低level$な~motion~sensorを利用するかを明示的に定義する
— したがって，アリな相互運用能の課題を~~未然に~~防ぐ。
◎
Unlike DeviceOrientationEvent, the OrientationSensor subclasses explicitly define which low-level motion sensors are used to obtain the orientation data, thus obviating possible interoperability issues.
</li>
	<li>
その各~instanceは、
`SensorOptions$I 構築子~parameterを介して環境設定-可能である。
◎
Instances of OrientationSensor subclasses are configurable via SensorOptions constructor parameter.
</li>
</ol>

	</section>
	<section id="usecases-requirements">
<h2 title="Use Cases and Requirements">2. 利用事例と要件</h2>

<p>
利用事例と要件は、
`Motion Sensors Explainer$cite
文書にて論じられている。
◎
The use cases and requirements are discussed in the Motion Sensors Explainer document.
</p>

	</section>
	<section id="examples">
<h2 title="Examples">3. 例</h2>

<div class="example">

<pre>
const %sensor = new AbsoluteOrientationSensor();
const %mat4 = new Float32Array(16);
%sensor.start();
%sensor.onerror = %event =&gt; console.log(%event.error.name, %event.error.message);

%sensor.onreading = () =&gt; {
  %sensor.populateMatrix(%mat4);
};
</pre>
</div>

<div class="example">

<pre>
const %sensor = new AbsoluteOrientationSensor({ frequency: 60 });
const %mat4 = new Float32Array(16);
%sensor.start();
%sensor.onerror = %event =&gt; console.log(%event.error.name, %event.error.message);

function draw(%timestamp) {
  window.requestAnimationFrame(draw);
  try {
    %sensor.populateMatrix(%mat4);
  } catch(%e) {
    /* <span class="comment">
%mat4 は更新されなかった
◎
mat4 has not been updated.
</span> */
  }
    /* <span class="comment">
何か描く…
◎
Drawing...
</span> */
}

window.requestAnimationFrame(draw);
</pre>
</div>

	</section>
	<section id="security-and-privacy">
<h2 title="Security and Privacy Considerations">4. ~securityと~privacyの考慮点</h2>

<p>
汎用~sensor~API `GENERIC-SENSOR$r に述べられたものを超える，特有な~security／~privacyの考慮点は無い。
◎
There are no specific security and privacy considerations beyond those described in the Generic Sensor API [GENERIC-SENSOR].
</p>

	</section>
	<section id="model">
<h2 title="Model">5. ~model</h2>

<p>
`OrientationSensor$I ~classは、
`Sensor$I ~classを拡張し，~device方位~dataを表現している汎用~interfaceを供する。
◎
The OrientationSensor class extends the Sensor class and provides generic interface representing device orientation data.
</p>

<p>
`~sensor型$
`方位~sensor@i
（ `Orientation Sensor^en ）の`最新な読取り~map$に~accessするためには、~UAは
各，具体~方位~sensorが利用する`低level$な~sensorに対し
`~sensor~accessを要請する$ 抽象-演算を呼出すモノトスル。
下の表に、具体~方位~sensorと，`低level$な~sensorにより定義される許可~tokenたちとの間の対応付けを述べる。
◎
To access the Orientation Sensor sensor type’s latest reading, the user agent must invoke request sensor access abstract operation for each of the low-level sensors used by the concrete orientation sensor. The table below describes mapping between concrete orientation sensors and permission tokens defined by low-level sensors.
</p>

<table><thead>

<tr><th>`OrientationSensor^I 下位class
</th><th>許可~token【<a href="~PERMISSIONS#permission-registry">参照</a>】
</th></tr></thead>

<tbody>

<tr><td>`AbsoluteOrientationSensor$I
</td><td>`accelerometer^l, `gyroscope^l, `magnetometer^l
</td></tr>
<tr><td>`RelativeOrientationSensor$I
</td><td>`accelerometer^l, `gyroscope^l
</td></tr></tbody></table>

<div class="p">
<p>
`~sensor型$ `方位~sensor$i の `Sensor$I 用の`最新な読取り~map$は、次のような`~entry$mapを含む：
</p>

<ul>
	<li>
`~key$map ~EQ `quaternion^l
</li>
	<li>
<p>
`値$mapは、単位~四元数 `QUATERNIONS$r を成す 4 個の成分からなり，順に次で与えられる
⇒＃
%Vx ~MUL `sin^op(~theta ~DIV 2),
%Vy ~MUL `sin^op(~theta ~DIV 2),
%Vz ~MUL `sin^op(~theta ~DIV 2),
`cos^op(~theta ~DIV 2)
</p>
<p>
ここで
⇒＃
[ %Vx, %Vy, %Vz ]  は 回転の軸を表現している単位~vector。
~theta は この軸~周りの回転~角度。
</p>
</li>
</ul>

◎
A latest reading for a Sensor of Orientation Sensor sensor type includes an entry whose key is "quaternion" and whose value contains a four element list. The elements of the list are equal to components of a unit quaternion [QUATERNIONS] [Vx * sin(θ/2), Vy * sin(θ/2), Vz * sin(θ/2), cos(θ/2)] where V is the unit vector (whose elements are Vx, Vy, and Vz) representing the axis of rotation, and θ is the rotation angle about the axis defined by the unit vector V.
</div>

<p class="note">注記：
この`~list$においては、四元数~成分 `QUATERNIONS$r は
[ %q1, %q2, %q3, %q0 ]
として配列される。
すなわち，四元数の~vectorを成す部分を表現する成分たちが，~scalar成分 `cos^op(~theta ~DIV 2）より前に来る。
この順序が利用されているのは，既存の~WebGL~frameworkを成す大部分との互換性をより良く得るためであるが、他の~libraryには
—  [ %q0, %q1, %q2, %q3 ] のように —
異なる順序を利用する配列として四元数を公開するものもある。
◎
Note: The quaternion components are arranged in the list as [q1, q2, q3, q0] [QUATERNIONS], i.e. the components representing the vector part of the quaternion go first and the scalar part component which is equal to cos(θ/2) goes after. This order is used for better compatibility with the most of the existing WebGL frameworks, however other libraries could use a different order when exposing quaternion as an array, e.g. [q0, q1, q2, q3].
</p>

<p>
具体 `OrientationSensor$I 下位classのうち［
`低level$な~motion~sensorたちが成す`~sensor融合$を通して作成されるもの
］は、次の表に呈示される：
◎
The concrete OrientationSensor subclasses that are created through sensor-fusion of the low-level motion sensors are presented in the table below:
</p>

<table class="def">

<thead><tr><th>`OrientationSensor^I 下位class
</th><th>`低level$な~motion~sensorたち
</th></tr></thead>

<tbody><tr><td>`AbsoluteOrientationSensor$I
</td><td>`Accelerometer$I, `Gyroscope$I, `Magnetometer$I
</td></tr>
<tr><td>`RelativeOrientationSensor$I
</td><td>`Accelerometer$I, `Gyroscope$I
</td></tr></tbody></table>

<p class="note">注記：
`低level$な~sensor［
`Accelerometer$I ／ `Gyroscope$I ／ `Magnetometer$I
］は［
`ACCELEROMETER$r ／ `GYROSCOPE$r ／ `MAGNETOMETER$r
］仕様に定義される。
`~sensor融合$は，~platformに特有であり、~software内でも，~hardware（すなわち，`~sensor~hub$）内でも起こり得る。
◎
Note: Accelerometer, Gyroscope and Magnetometer low-level sensors are defined in [ACCELEROMETER], [GYROSCOPE], and [MAGNETOMETER] specifications respectively. The sensor fusion is platform specific and can happen in software or hardware, i.e. on a sensor hub.
</p>

<div class="example">

<p>
この例の~codeは、
`start()$m を~callする前に，
`AbsoluteOrientationSensor$I 用の許可を明示的に~queryする。
◎
This example code explicitly queries permissions for AbsoluteOrientationSensor before calling start().
</p>

<pre>
const %sensor = new AbsoluteOrientationSensor();
Promise.all(
  [navigator.permissions.query({ name: "accelerometer" }),
        navigator.permissions.query({ name: "magnetometer" }),
        navigator.permissions.query({ name: "gyroscope" })])
  .then(%results =&gt; {
        if (%results.every(%result =&gt; %result.state === "granted")) {
          %sensor.start();
          ...
        } else {
          console.log("AbsoluteOrientationSensor の利用は許可されませんでした。");
        }
  });
</pre>
<!-- No permissions to use AbsoluteOrientationSensor -->

<p>
単純に
`start()$m を~callして `onerror$m `~event~handler$を~~登録する，別の~approachもある。
◎
Another approach is to simply call start() and subscribe to onerror event handler.
</p>

<pre>
const %sensor = new AbsoluteOrientationSensor();
%sensor.start();
%sensor.onerror = %event =&gt; {
  if (%event.error.name === 'SecurityError')
    console.log("No permissions to use AbsoluteOrientationSensor.");
};
</pre>
</div>

		<section id="absoluteorientationsensor-model">
<h3 title="The AbsoluteOrientationSensor Model">5.1. `AbsoluteOrientationSensor^I の~model</h3>

<p>
`AbsoluteOrientationSensor$I ~classは、
`OrientationSensor$I の下位classであり，`絶対~方位~sensor$を表現する。
◎
The AbsoluteOrientationSensor class is a subclass of OrientationSensor which represents the Absolute Orientation Sensor.
</p>

<p>
絶対~方位~sensor用の`最新な読取り~map$[ `quaternion^l ] の値は、
3 次元な~Cartesian座標系として定義される
`地球の基準~座標系@
との関係で，~deviceの`局所~座標系$の回転を表現する
— ここで、地球の基準~座標系の：
◎
For the absolute orientation sensor the value of latest reading["quaternion"] represents the rotation of a device’s local coordinate system in relation to the Earth’s reference coordinate system defined as a three dimensional Cartesian coordinate system (x, y, z), where:
</p>

<ul>
	<li>
~x軸は、 ~y, ~z の~vector-productであり、地面に接していて東を指す。
◎
x-axis is a vector product of y.z that is tangential to the ground and points east,
</li>
	<li>
~y軸は、地面に接していて磁北（ `magnetic north^en 【~compassの針が指す向き】）を指す。
◎
y-axis is tangential to the ground and points towards magnetic north, and
</li>
	<li>
~z軸は、~x軸, ~y軸が成す平面に垂直であり，天を指す。
◎
z-axis points towards the sky and is perpendicular to the plane made up of x and y axes.
</li>
</ul>

<p>
~deviceの`局所~座標系$は、`低level$~motion~sensor用に定義されるそれと同じである。
それは、`~device座標系$にも`~screen座標系$にもなり得る。
◎
The device’s local coordinate system is the same as defined for the low-level motion sensors. It can be either the device coordinate system or the screen coordinate system.
</p>

<p class="note">注記：
下の図は、~deviceの`局所~座標系$と`地球の基準~座標系$が整列される事例を表現する
— したがって，方位~sensorの`最新な読取り~map$は、各~軸~周りに 0 rad `SI$r の回転を表現することになる。
◎
Note: Figure below represents the case where device’s local coordinate system and the Earth’s reference coordinate system are aligned, therefore, orientation sensor’s latest reading would represent 0 (rad) [SI] rotation about each axis.
</p>

`absolute_orientation_sensor_coordinate_system^dgm

		</section>
		<section id="relativeorientationsensor-model">
<h3 title="The RelativeOrientationSensor Model">5.2. `RelativeOrientationSensor^I ~model</h3>

<p>
`RelativeOrientationSensor$I ~classは、
`OrientationSensor$I の下位classであり，`相対~方位~sensor$を表現する。
◎
The RelativeOrientationSensor class is a subclass of OrientationSensor which represents the Relative Orientation Sensor.
</p>

<p>
相対~方位~sensor用の`最新な読取り~map$[ `quaternion^l ] の値は、`~stationary基準~座標系$との関係で，~deviceの`局所~座標系$の回転を表現する。
`~stationary基準~座標系$は、~gyroscope~sensorが導入する偏りに因り，次第にずれ得る
— その結果、~sensorが供する回転~値も次第にずれ得る。
◎
For the relative orientation sensor the value of latest reading["quaternion"] represents the rotation of a device’s local coordinate system in relation to a stationary reference coordinate system. The stationary reference coordinate system may drift due to the bias introduced by the gyroscope sensor, thus, the rotation value provided by the sensor, may drift over time.
</p>

<p>
`~stationary基準~座標系@
は、［
~sensorを~hostしている~deviceが環境の中で移動しても，~stationaryであり続ける
］ような， 3 次元な~Cartesian慣性-座標系として定義される。
◎
The stationary reference coordinate system is defined as an inertial three dimensional Cartesian coordinate system that remains stationary as the device hosting the sensor moves through the environment.
</p>

<p>
~deviceの`局所~座標系$は、`低level$な~motion~sensor用に定義されるそれと同じであり，`~device座標系$にも`~screen座標系$にもなり得る。
◎
The device’s local coordinate system is the same as defined for the low-level motion sensors. It can be either the device coordinate system or the screen coordinate system.
</p>

<p class="note">注記：
相対~方位~sensor~dataは、絶対~方位~sensorが供するものより正確aになることもある
— ~sensorは，磁場により影響されないので。
◎
Note: The relative orientation sensor data could be more accurate than the one provided by absolute orientation sensor, as the sensor is not affected by magnetic fields.
</p>

		</section>
	</section>
	<section id="api">
<h2 title="API">6. ~API</h2>

		<section id="orientationsensor-interface">
<h3 title="The OrientationSensor Interface">6.1. `OrientationSensor^I ~interface</h3>

<pre class="idl">
typedef (`Float32Array$ or `Float64Array$ or `DOMMatrix$I) `RotationMatrixType@I;

[`SecureContext$, `Exposed$=Window]
interface `OrientationSensor@I : `Sensor$I {
  readonly attribute FrozenArray&lt;`double$&gt;? `quaternion@m;
  void `populateMatrix@m(`RotationMatrixType$I %targetMatrix);
};

enum `OrientationSensorLocalCoordinateSystem@I { `device@l, `screen@l };

dictionary `OrientationSensorOptions@I : `SensorOptions$I {
  `OrientationSensorLocalCoordinateSystem$I `referenceFrame@m = "device";
};
</pre>


<dl class="idl-def">
	<dt id="orientationsensor-quaternion">`quaternion@m</dt>
	<dd>
~device方位を表現している単位~四元数を成す 4 個の成分からなる`凍結d配列$を返す。
◎
6.1.1. OrientationSensor.quaternion
◎
Returns a four-element FrozenArray whose elements contain the components of the unit quaternion representing the device orientation.＼
</dd>
	<dd>
取得子は、次の結果を返すモノトスル
⇒
`最新な読取り~mapから値を取得する$( 此れ, `quaternion^l )
◎
In other words, this attribute returns the result of invoking get value from latest reading with this and "quaternion" as arguments.
</dd>

	<dt id="orientationsensor-populatematrix">`populateMatrix(targetMatrix)@m</dt>
	<dd>
<p>
%targetMatrix を下に示すように［
`最新な読取り~map$[ `quaternion^l ] の値から変換された結果の回転~行列
`QUATCONV$r
］で拡充する：
◎
6.1.2. OrientationSensor.populateMatrix()
◎
The populateMatrix() method populates the given object with rotation matrix which is converted from the value of latest reading["quaternion"] [QUATCONV], as shown below:
</p>

`quaternion_to_rotation_matrix^dgm

<p>
ここで
⇒＃
%W ~EQ `cos^op(~theta/2),
%X ~EQ %Vx ~MUL `sin^op(~theta/2),
%Y ~EQ %Vy ~MUL `sin^op(~theta/2),
%Z ~EQ %Vz ~MUL `sin^op(~theta/2),
◎
where:
• W = cos(θ/2)
• X = Vx * sin(θ/2)
• Y = Vy * sin(θ/2)
• Z = Vz * sin(θ/2)
</p>
	</dd>
	<dd>
回転~行列は、列主導順に %targetMatrix ~obj 内に平坦~化される
— すなわち，被呼出時には、次を走らすモノトスル
⇒
`回転~行列を拡充する$( %targetMatrix, 此れ )
◎
The rotation matrix is flattened in targetMatrix object according to the column-major order, as described in populate rotation matrix algorighm.
</dd>
</dl>

<div class="algorithm">
<p>
`回転~行列を拡充する@
ときは、所与の
( `RotationMatrixType$I %M, `OrientationSensor$I %~sensor )
に対し，次の手続きを走らす：
【！ or ~SENSORS#equivalent → Conformance】
◎
To populate rotation matrix, the populateMatrix() method must run these steps or their equivalent:
</p>

<ol>
	<li>
%種別 ~LET %M に応じて
⇒＃
`Float32Array$I であるならば `配列^i ／
`Float64Array$I であるならば `配列^i ／
`DOMMatrix$I であるならば `行列^i ／
~ELSE_ ε
◎
↓</li>
	<li>
~IF［
%種別 ~EQ ε
］
⇒
~THROW `TypeError$E
◎
If targetMatrix is not of type defined by RotationMatrixType union, throw a "TypeError" exception and abort these steps.
</li>
	<li>
~IF［
%種別 ~EQ `配列^i
］~AND［
%M の~size ~LT 16
］
⇒
~THROW `TypeError$E
◎
If targetMatrix is of type Float32Array or Float64Array with a size less than sixteen, throw a "TypeError" exception and abort these steps.
</li>
	<li>
%四元数 ~LET `最新な読取り~mapから値を取得する$( %~sensor, `quaternion^l )
◎
Let quaternion be the result of invoking get value from latest reading with this and "quaternion" as arguments.
</li>
	<li>
~IF［
%四元数 ~EQ ~NULL
］
⇒
~THROW `NotReadableError$E
◎
If quaternion is null, throw a "NotReadableError" DOMException and abort these steps.
</li>
	<li>
( %x, %y, %z, %w ) ~LET ( %四元数[ 0 ], %四元数[ 1 ], %四元数[ 2 ], %四元数[ 3 ] )
◎
Let x be the value of quaternion[0]
◎
Let y be the value of quaternion[1]
◎
Let z be the value of quaternion[2]
◎
Let w be the value of quaternion[3]
</li>
	<li>
%L ~LET 順に，次の 16 個の~itemからなる新たな`~list$
⇒＃
1 ~MINUS 2 ~MUL %y ~MUL %y ~MINUS 2 ~MUL %z ~MUL %z,
2 ~MUL %x ~MUL %y ~MINUS 2 ~MUL %z ~MUL %w,
2 ~MUL %x ~MUL %z + 2 ~MUL %y ~MUL %w,
0,
2 ~MUL %x ~MUL %y + 2 ~MUL %z ~MUL %w,
1 ~MINUS 2 ~MUL %x ~MUL %x ~MINUS 2 ~MUL %z ~MUL %z,
2 ~MUL %y ~MUL %z ~MINUS 2 ~MUL %x ~MUL %w,
0,
2 ~MUL %x ~MUL %z ~MINUS 2 ~MUL %y ~MUL %w,
2 ~MUL %y ~MUL %z + 2 ~MUL %x ~MUL %w,
1 ~MINUS 2 ~MUL %x ~MUL %x ~MINUS 2 ~MUL %y ~MUL %y,
0,
0,
0,
0,
1
◎
↓</li>
	<li>
~IF［
%種別 ~EQ `配列^i
］
⇒
~EACH( 整数 %i ~IN { 0 〜 15 } )
に対し
⇒
%M[ %i ] ~SET %L[ %i ]
◎
If targetMatrix is of Float32Array or Float64Array type, run these sub-steps:
• Set targetMatrix[0] = 1 - 2 * y * y - 2 * z * z
• Set targetMatrix[1] = 2 * x * y - 2 * z * w
• Set targetMatrix[2] = 2 * x * z + 2 * y * w
• Set targetMatrix[3] = 0
• Set targetMatrix[4] = 2 * x * y + 2 * z * w
• Set targetMatrix[5] = 1 - 2 * x * x - 2 * z * z
• Set targetMatrix[6] = 2 * y * z - 2 * x * w
• Set targetMatrix[7] = 0
• Set targetMatrix[8] = 2 * x * z - 2 * y * w
• Set targetMatrix[9] = 2 * y * z + 2 * x * w
• Set targetMatrix[10] = 1 - 2 * x * x - 2 * y * y
• Set targetMatrix[11] = 0
• Set targetMatrix[12] = 0
• Set targetMatrix[13] = 0
• Set targetMatrix[14] = 0
• Set targetMatrix[15] = 1
</li>
	<li>
~ELSE（ %種別 ~EQ `行列^i ）
⇒＃
%M . m11 ~SET %L[ 0 ]；
%M . m12 ~SET %L[ 1 ]；
%M . m13 ~SET %L[ 2 ]；
%M . m14 ~SET %L[ 3 ]；
%M . m21 ~SET %L[ 4 ]；
%M . m22 ~SET %L[ 5 ]；
%M . m23 ~SET %L[ 6 ]；
%M . m24 ~SET %L[ 7 ]；
%M . m31 ~SET %L[ 8 ]；
%M . m32 ~SET %L[ 9 ]；
%M . m33 ~SET %L[ 10 ]；
%M . m34 ~SET %L[ 11 ]；
%M . m41 ~SET %L[ 12 ]；
%M . m42 ~SET %L[ 13 ]；
%M . m43 ~SET %L[ 14 ]；
%M . m44 ~SET %L[ 15 ]
◎
If targetMatrix is of DOMMatrix type, run these sub-steps:
• Set targetMatrix.m11 = 1 - 2 * y * y - 2 * z * z
• Set targetMatrix.m12 = 2 * x * y - 2 * z * w
• Set targetMatrix.m13 = 2 * x * z + 2 * y * w
• Set targetMatrix.m14 = 0
• Set targetMatrix.m21 = 2 * x * y + 2 * z * w
• Set targetMatrix.m22 = 1 - 2 * x * x - 2 * z * z
• Set targetMatrix.m23 = 2 * y * z - 2 * x * w
• Set targetMatrix.m24 = 0
• Set targetMatrix.m31 = 2 * x * z - 2 * y * w
• Set targetMatrix.m32 = 2 * y * z + 2 * x * w
• Set targetMatrix.m33 = 1 - 2 * x * x - 2 * y * y
• Set targetMatrix.m34 = 0
• Set targetMatrix.m41 = 0
• Set targetMatrix.m42 = 0
• Set targetMatrix.m43 = 0
• Set targetMatrix.m44 = 1
</li>
	</ol>
</div>

		</section>
		<section id="absoluteorientationsensor-interface">
<h3 title="The AbsoluteOrientationSensor Interface">6.2. `AbsoluteOrientationSensor^I ~interface</h3>

<pre class="idl">
[`SecureContext$, `Exposed$=Window]
interface `AbsoluteOrientationSensor@I : `OrientationSensor$I {
  `AbsoluteOrientationSensor@mc(optional `OrientationSensorOptions$I %sensorOptions = {});
};
</pre>

<p>
`AbsoluteOrientationSensor$I ~objを構築するときは、~UAは次を呼出すモノトスル
⇒
`方位~sensor~objを構築する$( `AbsoluteOrientationSensor$I )
◎
To construct an AbsoluteOrientationSensor object the user agent must invoke the construct an orientation sensor object abstract operation for the AbsoluteOrientationSensor interface.
</p>

<p>
`AbsoluteOrientationSensor$I が`~supportする~sensor~options$は
⇒
`frequency^l,
`referenceFrame^l
◎
Supported sensor options for AbsoluteOrientationSensor are "frequency" and "referenceFrame".
</p>

		</section>
		<section id="relativeorientationsensor-interface">
<h3 title="The RelativeOrientationSensor Interface">6.3. `RelativeOrientationSensor^I ~interface</h3>

<pre class="idl">
[`SecureContext$, `Exposed$=Window]
interface `RelativeOrientationSensor@I : `OrientationSensor$I {
  `RelativeOrientationSensor@mc(optional `OrientationSensorOptions$I %sensorOptions = {});
};
</pre>

<p>
`RelativeOrientationSensor$I ~objを構築するときは、~UAは次を呼出すモノトスル
⇒
`方位~sensor~objを構築する$( `RelativeOrientationSensor$I )
◎
To construct a RelativeOrientationSensor object the user agent must invoke the construct an orientation sensor object abstract operation for the RelativeOrientationSensor interface.
</p>

<p>
`RelativeOrientationSensor$I が`~supportする~sensor~options$は
⇒
`frequency^l,
`referenceFrame^l
◎
Supported sensor options for RelativeOrientationSensor are "frequency" and "referenceFrame".
</p>

		</section>
	</section>
	<section id="abstract-operations">
<h2 title="Abstract Operations">7. 抽象-演算</h2>

		<section id="construct-an-orientation-sensor-object">
<h3 title="Construct an Orientation Sensor object">7.1. 方位~sensor~objを構築する</h3>

<div class="algorithm">

<dl>
	<dt>入力-</dt>
	<dd>
%方位~interface
— 次を満たす`~interface$の`識別子$
⇒
`OrientationSensor$I ~IN `継承した~interfaceたち$
◎
orientation_interface, an interface identifier whose inherited interfaces contains OrientationSensor.
</dd>

	<dd>
%~options
— `OrientationSensorOptions$I ~obj。
◎
options, a OrientationSensorOptions object.
</dd>

	<dt>出力</dt>
	<dd>
`OrientationSensor$I ~obj
◎
An OrientationSensor object.
</dd>
</dl>

<ol>
	<li>
%許容される ~LET `~sensor施策により制御される特能を検査する$( %方位~interface により識別され`~interface$ )
◎
Let allowed be the result of invoking check sensor policy-controlled features with the interface identified by orientation_interface.
</li>
	<li>
~IF［
%許容される ~EQ ~F
］
⇒
~THROW `SecurityError$E
◎
If allowed is false, then:
• Throw a SecurityError DOMException.
</li>
	<li>
%方位 ~LET %方位~interface により識別され`~interface$を成す新たな~instance
◎
Let orientation be a new instance of the interface identified by orientation_interface.
</li>
	<li>
`~sensor~objを初期化する$( %方位, %~options )
◎
Invoke initialize a sensor object with orientation and options.
</li>
	<li>
~IF［
%~options . `referenceFrame$m ~EQ `screen^l
］
⇒
%方位 用の`局所~座標系$を`~screen座標系$として定義する
◎
If options.referenceFrame is "screen", then:
• Define local coordinate system for orientation as the screen coordinate system.
</li>
	<li>
~ELSE
⇒
%方位 用の`局所~座標系$を`~device座標系$として定義する
◎
Otherwise, define local coordinate system for orientation as the device coordinate system.
</li>
	<li>
~RET %方位
◎
Return orientation.
</li>
</ol>
</div>

		</section>
	</section>
	<section id="automation">
<h2 title="Automation">8. 自動化</h2>

<p>
この節では、汎用~sensor~API `GENERIC-SENSOR$r に定義される<a href="~SENSORS#automation">自動化</a>を拡張する
— ~UAによる［
`AbsoluteOrientationSensor$I ／ `RelativeOrientationSensor$I
］~APIの実装を~testする目的で，
3 次元な~Cartesian座標系との関係で，~deviceの物理的~方位を模擬する情報を供するための。
◎
This section extends the automation section defined in the Generic Sensor API [GENERIC-SENSOR] to provide mocking information about the device’s physical orientation in relation to a three dimensional Cartesian coordinate system for the purposes of testing a user agent’s implementation of AbsoluteOrientationSensor and RelativeOrientationSensor APIs.
</p>

		<section id="mock-orientation-sensor-type">
<h3 title="Mock Sensor Type">8.1. 模擬~sensor型</h3>

<p>
`AbsoluteOrientationSensor$I ~classに結付けられる`模擬~sensor型$は `absolute-orientation$l であり、その`模擬~sensor読取り値たち$が成す辞書は，次で定義される：
◎
The AbsoluteOrientationSensor class has an associated mock sensor type which is "absolute-orientation", its mock sensor reading values dictionary is defined as follows:
</p>

<pre class="idl">
dictionary `AbsoluteOrientationReadingValues@I {
  required FrozenArray&lt;`double$&gt;? `quaternion@mb;
};
</pre>

<p>
`RelativeOrientationSensor$I ~classに結付けられる`模擬~sensor型$は `relative-orientation$l であり、その`模擬~sensor読取り値たち$が成す辞書は，次で定義される
◎
The RelativeOrientationSensor class has an associated mock sensor type which is "relative-orientation", its mock sensor reading values dictionary is defined as follows:
</p>

<pre class="idl">
dictionary `RelativeOrientationReadingValues@I : `AbsoluteOrientationReadingValues$I {
};
</pre>

		</section>
	</section>
	<section id="acknowledgements">
<h2 title="Acknowledgements">9. 謝辞</h2>

<p>
汎用~sensor~APIの作業を為された `Tobie Langel^en 氏に。
◎
Tobie Langel for the work on Generic Sensor API.
</p>

	</section>
</main></div>
