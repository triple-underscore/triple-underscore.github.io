<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8">
<title>Orientation Sensor（日本語訳）</title>

<link rel="stylesheet" href="common.css" type="text/css">
<link rel="stylesheet" href="common-w3c.css" type="text/css">

<script src="common0.js" ></script>
<script src="common1.js" async></script>

<script>

Util.ready = function(){
	const source_data = {
		toc_main: 'MAIN0',
		generate: expand
	};
	Util.switchWordsInit(source_data);
}

function expand(){
	const class_map = this.class_map;
	const tag_map = this.tag_map;
	const link_map = this.link_map;

	return this.html.replace(
		/%[\w\-~一-鿆あ-ん]+|`(.+?)([$@\^])(\w*)/g,
		create_html
	);

	function create_html(match, key, indicator, klass){

if(!key) {//%
	return `<var>${match.slice(1)}</var>`;
}

let href = '';
let href1 = '';
{
	const n = key.indexOf('＠');
	if(n > 0) {
		href1 = key.slice(n + 1);
		key = key.slice(0, n);
	}
}
let text = key;

switch(klass){
case 'r':
	text = `[${key}]`;
	href = `#biblio-${key.toLowerCase()}`;
	break;
case 'l':
case 'vsT':
	text = `"<code class="literal">${text}</code>"`;
	break;
case 'm':
	const n = text.indexOf('(');
	if(n > 0){
		key = text.slice(0, n);
		text = key + text.slice(n).replace(/\w+/g, '<var>$&</var>');
	}
	break;
case 'mc':
	text = 'constructor';
	klass = 'm';
	key = `new ${key}`;
	break;
case 'en':
	return `<span lang="en">${key}</span>`;
	break;
}

let tag = tag_map[klass];
if(tag) {
	let classname = class_map[klass];
	classname = classname ? ` class="${classname}"` : '';
	text = `<${tag}${classname}>${text}</${tag}>`;
}

if(indicator !== '^'){
	href = href1 || link_map[ klass ? `${klass}.${key}` : key ] || href;
	if(!href){
		console.log(match); // check error
		return match;
	}

	switch(indicator){
	case '$':
		text = `<a href="${href}">${text}</a>`;
		break;
	case '@':
		text = `<dfn id="${href.slice(1)}">${text}</dfn>`;
		break;
	}
}

return text;


	}
}

</script>


<script type="text/plain" id="_source_data">


●●options

spec_title:Orientation Sensor
spec_date:2024-01-10
trans_update:2024-01-12
source_checked:231025
spec_status:ED
original_url:https://w3c.github.io/orientation-sensor/
	abbr_url:ORIENTATION-SENSOR
ref_id_prefix:biblio-
ref_id_lowercase:true
page_state_key:SENSORS
site_nav:sensors
ref_id_lowercase:true
copyright:2021,permissive
trans_1st_pub:2019-08-23
conformance:w3c

●●class_map
E:error
et:event-type
e:element
a:attr
op:op

●●tag_map
I:code
E:code
m:code
c:code
mb:code
cite:cite
et:code
a:code
e:code
i:i
op:span

●●original_id_map

●●mdn_urls
absoluteorientationsensor:API/AbsoluteOrientationSensor
orientationsensor:API/OrientationSensor
relativeorientationsensor:API/RelativeOrientationSensor

●●link_map

	●IDL

Exposed:~WEBIDLjs#Exposed
SecureContext:~WEBIDLjs#SecureContext

double:~WEBIDL#idl-double
undefined:~WEBIDL#idl-undefined
Float32Array:~WEBIDL#idl-Float32Array
Float64Array:~WEBIDL#idl-Float64Array
I.Float32Array:~WEBIDL#idl-Float32Array
I.Float64Array:~WEBIDL#idl-Float64Array
FrozenArray:~WEBIDL#idl-frozen-array

E.NotReadableError:~WEBIDL#notreadableerror
E.SecurityError:~WEBIDL#securityerror
E.TypeError:~WEBIDL#exceptiondef-typeerror
	I.DOMException:~WEBIDL#idl-DOMException
I.AbsoluteOrientationSensor:#absoluteorientationsensor
I.Accelerometer:~ACCELEROMETER#accelerometer
I.DOMMatrix:~GEOMETRY#dommatrix
I.DeviceOrientationEvent:~DEVICEORIENTATION#deviceorientationevent
	https://www.w3.org/TR/2016/CR-orientation-event-20160818/#deviceorientation_event
I.Gyroscope:~GYROSCOPE#gyroscope
I.Magnetometer:~MAGNETOMETER#magnetometer
I.OrientationSensor:#orientationsensor
I.OrientationSensorLocalCoordinateSystem:#enumdef-orientationsensorlocalcoordinatesystem
I.OrientationSensorOptions:#dictdef-orientationsensoroptions
I.RelativeOrientationSensor:#relativeorientationsensor
I.RotationMatrixType:#typedefdef-rotationmatrixtype
I.Sensor:~SENSORS#sensor
I.SensorOptions:~SENSORS#dictdef-sensoroptions

l.device:#dom-orientationsensorlocalcoordinatesystem-device
l.screen:#dom-orientationsensorlocalcoordinatesystem-screen


m.onerror:~SENSORS#dom-sensor-onerror
m.populateMatrix:#dom-orientationsensor-populatematrix
m.quaternion:#dom-orientationsensor-quaternion
mb.referenceFrame:#dom-orientationsensoroptions-referenceframe
m.start:~SENSORS#dom-sensor-start

m.new AbsoluteOrientationSensor:#dom-absoluteorientationsensor-absoluteorientationsensor
m.new RelativeOrientationSensor:#dom-relativeorientationsensor-relativeorientationsensor

	%sensorOptions:#dom-absoluteorientationsensor-absoluteorientationsensor-sensoroptions-sensoroptions
	%sensorOptions:#dom-relativeorientationsensor-relativeorientationsensor-sensoroptions-sensoroptions
	%targetMatrix:#dom-orientationsensor-populatematrix-targetmatrix-targetmatrix

vsT.absolute-orientation:~DEVICEORIENTATION#absolute-orientation-virtual-sensor-type
vsT.relative-orientation:~DEVICEORIENTATION#relative-orientation-virtual-sensor-type

	●用語
i.方位~sensor:#orientation-sensor
i.絶対~方位~sensor:#absolute-orientation-sensor-type
i.相対~方位~sensor:#relative-orientation-sensor-type
方位~sensor~objを初期化する:#construct-an-orientation-sensor-object
	方位~sensor~objを構築する:#construct-an-orientation-sensor-object
~stationary基準~座標系:#stationary-reference-coordinate-system
地球の基準~座標系:#earths-reference-coordinate-system
四元数を回転~行列に変換する:#converting-a-quaternion-to-rotation-matrix
~Euler角度から四元数を作成する:#create-a-quaternion-from-euler-angles

	●用語（sensor

~sensor型:~SENSORS#sensor-type
拡張~sensor~interface:~SENSORS#extension-sensor-interface
属する~virtual~sensor型:~SENSORS#_virtual-sensor-type
	~virtual~sensor型:~SENSORS#virtual-sensor-type
~sensor融合:~SENSORS#sensor-fusion
~supportする~sensor~option群:~SENSORS#supported-sensor-options
~sensor~hub:~SENSORS#smart-sensors
	廃）~SENSORS#sensor-hubs
低level:~SENSORS#low-level
局所~座標系:~SENSORS#local-coordinate-system
最新な読取り~map:~SENSORS#latest-reading

~sensor~accessを要請する:~SENSORS#request-sensor-access
~sensor~objを初期化する:~SENSORS#initialize-a-sensor-object
~sensor施策により制御される特能を検査する:~SENSORS#check-sensor-policy-controlled-features
最新な読取り~mapから値を取得する:~SENSORS#get-value-from-latest-reading

~virtual~sensor~metadata:~SENSORS#virtual-sensor-metadata
型ごとの~virtual~sensor~metadata:~SENSORS#per-type-virtual-sensor-metadata
vsM.読取り構文解析~algo:~SENSORS#virtual-sensor-metadata-reading-parsing-algorithm

方位~data読取りを構文解析する:~DEVICEORIENTATION#parse-orientation-data-reading
~screen座標系:~ACCELEROMETER#screen-coordinate-system
~device座標系:~ACCELEROMETER#device-coordinate-system

	●用語（外部

~list:~INFRA#list
~size:~INFRA#list-size
~map:~INFRA#ordered-map
map.~entry:~INFRA#map-entry
map.~key:~INFRA#map-key
map.値:~INFRA#map-value
	~THROW:~WEBIDL#dfn-throw

構築子~手続き:~WEBIDL#constructor-steps
凍結d配列:~WEBIDL#dfn-frozen-array-type
	不要）
	継承した~interfaceたち:~WEBIDL#dfn-inherited-interfaces
	識別子:~WEBIDL#dfn-identifier
	~interface:~WEBIDL#dfn-interface

~event~handler:~WAPI#event-handlers

施策により制御される特能:~PERMISSIONS-POLICY#policy-controlled-feature
既定の許容list:~PERMISSIONS-POLICY#policy-controlled-feature-default-allowlist

行列を~3D行列に初期化する:~GEOMETRY#_initialize-matrix-3d

●●words_table1

MOTION-SENSORS:motion-sensors-ja.html
ACCELEROMETER:accelerometer-ja.html
MAGNETOMETER:magnetometer-ja.html
GYROSCOPE:gyroscope-ja.html


theta:<var>θ</var>

●●words_table

	●幾何
motion::::モーション
gyroscope::::ジャイロスコープ
磁場:magnetic field::~
hub::::ハブ
地球:Earth:~
Cartesian:::直交
垂直:perpendicular::~
磁北:magnetic north::~
四元数:quaternion::~
回転:rotation::~
地面:ground::~
天:sky::~
平面:plane::~
慣性-:inertial::~
東:east::~
基準:reference::~
次元な:dimensional::次元の
vector-product:vector product:::クロス積
stationary:
drift:
drifting:
真北:true north::~
w:
x:
y:
z:
度d:degree:度°
radian::::ラジアン
3D:
列主導順:column-major order:~
	周り:about
行列:matrix::~
Euler::::オイラー
角度:angle::~
norm::::ノルム
	~z位置:z-position
	接して:tangential
	へ向かって:toward
	指す:point／points towards
	`cos^op:cosine
	`sin^op:sine

	●sensor／計測
device:
hub:
sensor::::センサー
低level:low-level:低 level::低レベル
融合:fusion::~
最新な:latest:~
virtual:

	次第にずれる:drift／:drift over time

	●変数
number:
alpha:
beta:
gamma:

	%V*:V*
	%q*
	%方位~interface:orientation_interface
	%M:targetMatrix
	%回転~行列:rotationMatrix
	%cosZ
	%sinZ
	%cosX
	%sinX
	%cosY
	%sinY
	%~alpha:alpha
	%~beta:beta
	%~gamma:gamma
	%~alpha:alphaInRadian
	%~beta:betaInRadian
	%~gamma:gammaInRadian
	%読取り:reading
	-:quaternionX
	-:quaternionY
	-:quaternionZ
	-:quaternionW

	●仕様
WebGL:
	汎用~sensor~API／^en:Generic Sensor API
	方位~sensor~API／^en:Orientation Sensor API
追跡器:tracker::~::トラッカー
為され:makeされ:~

	来る:go
	~~未然に~~防ぐ:obviating
	との関係で:in relation to
	-:according to
	満たす:satisfy
	図:figure
	したがって:and consequently
	単純さ:simplicity
	見込みがずっと高い:much more likely
	関心がある:interested in
	寄せられたし: 〜 is welcome 
	自前で:on their own
	選び取っ:pick

	●仕様（ status
追求-:pursue:~
横断的:horizontal:~
	始まって以降の:since 〜 took place
	当~WG:the group

	●未分類
許容list:allowlist::許容 list:許容リスト
偏り:bias:~
凍結d:frozen::~
安定的:stable:~
描く:drawする:~
	~~登録:subscribe
compass::::コンパス
換算-:convert:~

	環境設定-可能:configurable
	-:in other words
	含む:includeする
	^cite:WebDriver
	対応-:corresponding

	●指示語
	大部分:most
	16:sixteen
	3 :three
	4 個の:four
	非:non
	部分:part


●●images
＠orientation-sensor/
absolute_orientation_sensor_coordinate_system｜height:375px;｜｜.png
quaternion_to_rotation_matrix｜height:102px;｜｜.png

●●ref_key_map
ORIENTATIONEVENT:DEVICEORIENTATION

●●ref_normative

[ACCELEROMETER]
    Anssi Kostiainen. ＜Accelerometer＞. URL: https://w3c.github.io/accelerometer/
[GENERIC-SENSOR]
    Rick Waldron. ＜Generic Sensor API＞. URL: https://w3c.github.io/sensors/
[GEOMETRY-1]
    Simon Pieters; Chris Harrelson. ＜Geometry Interfaces Module Level 1＞. URL: https://drafts.fxtf.org/geometry/
[GYROSCOPE]
    Anssi Kostiainen. ＜Gyroscope＞. URL: https://w3c.github.io/gyroscope/
[INFRA]
    Anne van Kesteren; Domenic Denicola. ＜Infra Standard＞. Living Standard. URL: https://infra.spec.whatwg.org/
[MAGNETOMETER]
    Anssi Kostiainen; Rijubrata Bhaumik. ＜Magnetometer＞. URL: https://w3c.github.io/magnetometer/
[MOTION-SENSORS]
    Kenneth Christiansen; Alexander Shalamov. ＜Motion Sensors Explainer＞. URL: https://w3c.github.io/motion-sensors/
[ORIENTATION-EVENT]
    Reilly Grant; Raphael Kubo da Costa. ＜DeviceOrientation Event Specification＞. URL: https://w3c.github.io/deviceorientation/
[PERMISSIONS-POLICY-1]
    Ian Clelland. ＜Permissions Policy＞. URL: https://w3c.github.io/webappsec-permissions-policy/
[RFC2119]
    S. Bradner. ＜Key words for use in RFCs to Indicate Requirement Levels＞. March 1997. Best Current Practice. URL: https://datatracker.ietf.org/doc/html/rfc2119
[WEBIDL]
    Edgar Chen; Timothy Gu. ＜Web IDL Standard＞. Living Standard. URL: https://webidl.spec.whatwg.org/

●●ref_informative

[HTML]
    Anne van Kesteren; et al. ＜HTML Standard＞. Living Standard. URL: https://html.spec.whatwg.org/multipage/
[QUATCONV]
    Watt, Alan H., and Mark Watt.. ＜Advanced animation and rendering techniques., page 362＞. 1992. Informational. URL: https://www.cs.cmu.edu/afs/cs/academic/class/15462-s14/www/lec_slides/3DRotationNotes.pdf
[QUATERNIONS]
    ＜Quaternion＞. URL: https://en.wikipedia.org/wiki/Quaternion
[SI]
    ＜SI Brochure: The International System of Units (SI), 8th edition＞. 2014. URL: http://www.bipm.org/en/publications/si-brochure/


●●trans_metadata
<p>
~THIS_PAGEは、~W3Cにより
編集者草案として公開された
<a href="~SPEC_URL">Orientation Sensor</a>
を日本語に翻訳したものです。
~PUB

●●spec_metadata

最新公表バージョン
	https://www.w3.org/TR/orientation-sensor/
公表履歴
	https://www.w3.org/standards/history/orientation-sensor/
commit 履歴
	https://github.com/w3c/orientation-sensor/commits/main/index.bs
フィードバック
	<a href="mailto:public-device-apis@w3.org?subject=%5Borientation-sensor%5D%20YOUR%20TOPIC%20HERE">public-device-apis@w3.org</a> with subject line “<kbd>[orientation-sensor] <i>… message topic …</i></kbd>” (<a href="https://lists.w3.org/Archives/Public/public-device-apis/" rel="discussion">archives</a>)
	<a href="https://github.com/w3c/orientation-sensor/issues">Orientation Sensor Issues Repository</a>

編集
	<a href="https://intel.com/">Kenneth Rohde Christiansen</a> (Intel Corporation)
	<a href="https://intel.com/">Anssi Kostiainen</a> (Intel Corporation)
前任編集者
	<a href="https://intel.com/">Mikhail Pozdnyakov</a> (Intel Corporation)
	<a href="https://intel.com/">Alexander Shalamov</a> (Intel Corporation)

テスト一式
	<a href="https://github.com/web-platform-tests/wpt/tree/master/orientation-sensor">web-platform-tests on GitHub</a>
mailing list
	<a href="mailto:public-device-apis@w3.org?Subject=%5Borientation-sensor%5D%20PUT%20SUBJECT%20HERE">public-device-apis@w3.org</a> (<a href="mailto:public-device-apis-request@w3.org?subject=subscribe">subscribe</a>, <a href="https://lists.w3.org/Archives/Public/public-device-apis/">archives</a>)
公表者
	<a href="https://www.w3.org/groups/wg/das">Devices and Sensors WG</a>
</script>
</head>
<body>

<header>
	<hgroup>
<h1>方位センサー — Orientation Sensor</h1>
	</hgroup>
</header>

<div id="MAIN" hidden>
	<section id="abstract">
◎要約

<p>
この仕様は、［
~deviceの物理的な方位を~stationary【定常／静止】な 3 次元な~Cartesian座標系との関係で監視する
］ための，基底~方位~sensor~interface,
および各種~具象-~sensor下位classを定義する。
◎
This specification defines a base orientation sensor interface and concrete sensor subclasses to monitor the device’s physical orientation in relation to a stationary three dimensional Cartesian coordinate system.
</p>

	</section>
	<section id="sotd">
◎位置付け

<p>
これは編集者草案の公な複製です…
【以下、この節の他の内容は，~SOTD-W3Cに移譲。】
</p>

<p>
`Devices and Sensors ~WG^cite
は、この仕様に対する現代の［
~security／~privacy
］考査を追求している
— この仕様と［
~privacy／~security
］についての横断的な考査の実施が
`2019年 10月 14日に始まって＠https://github.com/w3c/sensors/issues/299#issuecomment-541607278$以降の変更の量を考慮に入れる下で。
類似に，当~WGは、この仕様に対する，
`Technical Architecture Group^cite（ TAG, 技術-~architecture~group）による
— 最新な~architecture上の考査の実施を織り込む下での —
考査の更新を追求している。
◎
The Devices and Sensors Working Group is pursuing modern security and privacy reviews for this specification in consideration of the amount of change in both this specification and in privacy and security review practices since the horizontal reviews took place on 14 October 2019. Similarly, the group is pursuing an update to the Technical Architecture Group review for this specification to account for the latest architectural review practices.
</p>

	</section>

<main id="MAIN0">

	<section id="_conventions">
<h2 class="trans-note">【この訳に特有な表記規約】</h2>

◎表記記号

	</section>
	<section id="intro">
<h2 title="Introduction">1. 序論</h2>

<p>
方位~sensor~API （ `Orientation Sensor API^en ）は、［
~deviceの物理的~方位を
3 次元な~Cartesian座標系との関係で述べる汎用~情報
］を供するため，
汎用~sensor~API（ `Generic Sensor API^en ） `GENERIC-SENSOR$r を拡張する。
◎
The Orientation Sensor API extends the Generic Sensor API [GENERIC-SENSOR] to provide generic information describing the device’s physical orientation in relation to a three dimensional Cartesian coordinate system.
</p>

<p>
`AbsoluteOrientationSensor$I ~classは、
`OrientationSensor$I ~interfaceを継承し，
~deviceの物理的~方位を`地球の基準~座標系$との関係で述べる。
◎
The AbsoluteOrientationSensor class inherits from the OrientationSensor interface and describes the device’s physical orientation in relation to the Earth’s reference coordinate system.
</p>

<p>
他の下位classは、［
真北【北極】や非~stationary方向などの，他の~stationary方向
］との関係で方位を述べる
— ~deviceの自前の~z位置との関係で，最新な最も安定的な~z位置へ向かって次第にずれる（ `drift^en ）様な。【？】
◎
Other subclasses describe the orientation in relation to other stationary directions, such as true north, or non stationary directions, like in relation to a devices own z-position, drifting towards its latest most stable z-position.
</p>

<p>
`OrientationSensor$I 下位classが供する~dataは、
`DeviceOrientationEvent$I からの~dataに類似するが，
方位~sensor~APIには，次に挙げる有意な相違点がある
— `OrientationSensor$I 下位classは：
◎
The data provided by the OrientationSensor subclasses are similar to data from DeviceOrientationEvent, but the Orientation Sensor API has the following significant differences:
</p>
<ol>
	<li>
~WebGLに互換な形式（四元数（ `quaternion^en ）, 回転~行列）で方位~dataを表現する。
◎
The Orientation Sensor API represents orientation data in WebGL-compatible formats (quaternion, rotation matrix).
</li>
	<li>
より厳密な待時間~要件を満たす。
◎
The Orientation Sensor API satisfies stricter latency requirements.
</li>
	<li>
方位~dataを得するときに，どの`低level$な~motion~sensorを利用するかを明示的に定義する
— したがって，アリな相互運用能の課題を~~未然に~~防ぐ。
◎
Unlike DeviceOrientationEvent, the OrientationSensor subclasses explicitly define which low-level motion sensors are used to obtain the orientation data, thus obviating possible interoperability issues.
</li>
	<li>
その各~instanceは、
`SensorOptions$I 構築子~parameterを介して環境設定-可能である。
◎
Instances of OrientationSensor subclasses are configurable via SensorOptions constructor parameter.
</li>
</ol>

	</section>
	<section id="usecases-requirements">
<h2 title="Use Cases and Requirements">2. 利用事例と要件</h2>

<p>
利用事例と要件は、
`MOTION-SENSORS$r `§ 利用事例と要件＠~MOTION-SENSORS#usecases-and-requirements$
にて論じられている。
◎
The use cases and requirements are discussed in the Motion Sensors Explainer document.
</p>

	</section>
	<section id="examples">
<h2 title="Examples">3. 例</h2>

<div class="example">

<pre class="lang-js">
const %sensor = new AbsoluteOrientationSensor();
const %mat4 = new Float32Array(16);
%sensor.start();
%sensor.onerror = %event =&gt; console.log(%event.error.name, %event.error.message);

%sensor.onreading = () =&gt; {
  %sensor.populateMatrix(%mat4);
};
</pre>
</div>

<div class="example">

<pre class="lang-js">
const %sensor = new AbsoluteOrientationSensor({ frequency: 60 });
const %mat4 = new Float32Array(16);
%sensor.start();
%sensor.onerror = %event =&gt; console.log(%event.error.name, %event.error.message);

function draw(%timestamp) {
  window.requestAnimationFrame(draw);
  try {
    %sensor.populateMatrix(%mat4);
  } catch(%e) {
    /* <span class="comment">
%mat4 は更新されなかった
◎
mat4 has not been updated.
</span> */
  }
    /* <span class="comment">
何か描く…
◎
Drawing...
</span> */
}

window.requestAnimationFrame(draw);
</pre>
</div>

	</section>
	<section id="security-and-privacy">
<h2 title="Security and Privacy Considerations">4. ~securityと~privacyの考慮点</h2>

<p>
汎用~sensor~API `GENERIC-SENSOR$r に述べられたものを超える，特有な~security／~privacyの考慮点は無い。
◎
There are no specific security and privacy considerations beyond those described in the Generic Sensor API [GENERIC-SENSOR].
</p>

	</section>
	<section id="model">
<h2 title="Model">5. ~model</h2>

<p>
`OrientationSensor$I ~classは、
`Sensor$I ~classを拡張し，~device方位~dataを表現している汎用~interfaceを供する。
◎
The OrientationSensor class extends the Sensor class and provides generic interface representing device orientation data.
</p>

<p>
`~sensor型$
`方位~sensor@i
（ `Orientation Sensor^en ）の`最新な読取り~map$に~accessするためには、~UAは
各，具象-方位~sensorが利用する`低level$な~sensorに対し
`~sensor~accessを要請する$ 抽象-演算を呼出すモノトスル。
下の表tに、具象-方位~sensorと，`低level$な~sensorにより定義される許可~tokenたちとの間の対応付けを述べる。
◎
To access the Orientation Sensor sensor type’s latest reading, the user agent must invoke request sensor access abstract operation for each of the low-level sensors used by the concrete orientation sensor. The table below describes mapping between concrete orientation sensors and permission tokens defined by low-level sensors.
</p>

<table><thead>

<tr><th>`OrientationSensor^I 下位class
<th>許可~token
<tbody>

<tr><td>`AbsoluteOrientationSensor$I
<td>`accelerometer^l, `gyroscope^l, `magnetometer^l

<tr><td>`RelativeOrientationSensor$I
<td>`accelerometer^l, `gyroscope^l
</table>

<p>
`AbsoluteOrientationSensor$I は、
`施策により制御される特能$であり，文字列［
`accelerometer^l ／ `gyroscope^l ／ `magnetometer^l
］により識別される。
その`既定の許容list$は `'self'^l とする。
◎
The AbsoluteOrientationSensor is a policy-controlled feature identified by strings "accelerometer", "gyroscope" and "magnetometer" . Its default allowlist is 'self'.
</p>

<p>
`RelativeOrientationSensor$I は、
`施策により制御される特能$であり，文字列［
`accelerometer^l ／ `gyroscope^l
］により識別される。
その`既定の許容list$は `'self'^l とする。
◎
The RelativeOrientationSensor is a policy-controlled feature identified by strings "accelerometer" and "gyroscope". Its default allowlist is 'self'.
</p>

<div class="p">
<p>
`~sensor型$ `方位~sensor$i の `Sensor$I 用の`最新な読取り~map$は、
次のような`~entry$mapを含む：
</p>
<ul>
	<li>
`~key$map ~EQ `quaternion^l
</li>
	<li>
<p>
`値$mapは、
単位~四元数【 ~norm ~EQ 1 を満たす四元数】
`QUATERNIONS$r を成す 4 個の成分からなり，順に次で与えられる
⇒＃
%X ~EQ %Vx ~MUL `sin^op( ~theta ~DIV 2 ),
%Y ~EQ %Vy ~MUL `sin^op( ~theta ~DIV 2 ),
%Z ~EQ %Vz ~MUL `sin^op( ~theta ~DIV 2 ),
%W ~EQ `cos^op( ~theta ~DIV 2 )
</p>

<p>
ここで
⇒＃
[ %Vx, %Vy, %Vz ] は，回転の軸を表現している単位~vectorを表す。
~theta は，この軸~周りの回転~角度を表す。
</p>

<div>
<p id="_quaternion-rotation-matrix">
この四元数は、
次のような回転~行列に`変換されて＠#converting-a-quaternion-to-rotation-matrix$から利用されることになる `QUATCONV$r ：
</p>

<p class="alt" hidden id="_dgm-quaternion_to_rotation_matrix">
四元数から回転~行列への変換-法。
</p>

<p class="trans-note">【
この行列に関する記述は，原文では他所にあるが、
各~変数を説明する都合により，ここに移動している。
】</p>
</div>

	</li>
</ul>
◎
A latest reading for a Sensor of Orientation Sensor sensor type includes an entry whose key is "quaternion" and whose value contains a four element list. The elements of the list are equal to components of a unit quaternion [QUATERNIONS] [Vx * sin(θ/2), Vy * sin(θ/2), Vz * sin(θ/2), cos(θ/2)] where V is the unit vector (whose elements are Vx, Vy, and Vz) representing the axis of rotation, and θ is the rotation angle about the axis defined by the unit vector V.
◎
↓↓</div>

<p class="note">注記：
この`~list$においては、四元数~成分 `QUATERNIONS$r は，
[ %X, %Y, %Z, %W ]【！[ %q1, %q2, %q3, %q0 ]】
として配列される。
すなわち，四元数の~vectorを表現する成分たち【 i, j, k 成分】が，
~scalar成分 %W【！`cos^op(~theta ~DIV 2）】 より前に来る。
この順序が利用されているのは，既存の~WebGL~frameworkを成す大部分との互換性をより良く得るためであるが、他の~libraryには
— [ %W, %X, %Y, %Z ]【！[ %q0, %q1, %q2, %q3 ]】 のように —
異なる順序を利用する配列として四元数を公開するものもある。
◎
Note: The quaternion components are arranged in the list as [q1, q2, q3, q0] [QUATERNIONS], i.e. the components representing the vector part of the quaternion go first and the scalar part component which is equal to cos(θ/2) goes after. This order is used for better compatibility with the most of the existing WebGL frameworks, however other libraries could use a different order when exposing quaternion as an array, e.g. [q0, q1, q2, q3].
</p>

<p>
具象- `OrientationSensor$I 下位classのうち［
`低level$な~motion~sensorたちが成す`~sensor融合$を通して作成されるもの
］は、次の表tに呈示される：
◎
The concrete OrientationSensor subclasses that are created through sensor-fusion of the low-level motion sensors are presented in the table below:
</p>

<table class="def"><thead>
<tr><th>`OrientationSensor^I 下位class
<th>`低level$な~motion~sensorたち
<tbody>

<tr><td>`AbsoluteOrientationSensor$I
<td>`Accelerometer$I, `Gyroscope$I, `Magnetometer$I

<tr><td>`RelativeOrientationSensor$I
<td>`Accelerometer$I, `Gyroscope$I
</table>

<p class="note">注記：
`低level$な~sensor［
`Accelerometer$I ／ `Gyroscope$I ／ `Magnetometer$I
］は［
`ACCELEROMETER$r ／ `GYROSCOPE$r ／ `MAGNETOMETER$r
］仕様に定義される。
`~sensor融合$は，~platformに特有であり、
~software内でも，~hardware（すなわち，`~sensor~hub$）内でも起こり得る。
◎
Note: Accelerometer, Gyroscope and Magnetometer low-level sensors are defined in [ACCELEROMETER], [GYROSCOPE], and [MAGNETOMETER] specifications respectively. The sensor fusion is platform specific and can happen in software or hardware, i.e. on a sensor hub.
</p>

<div class="example">

<p>
この例の~codeは、
`start()$m を~callする前に，
`AbsoluteOrientationSensor$I 用の許可を明示的に~queryする。
◎
This example code explicitly queries permissions for AbsoluteOrientationSensor before calling start().
</p>

<pre class="lang-js">
const %sensor = new AbsoluteOrientationSensor();
Promise.all(
  [navigator.permissions.query({ name: "accelerometer" }),
        navigator.permissions.query({ name: "magnetometer" }),
        navigator.permissions.query({ name: "gyroscope" })])
  .then(%results =&gt; {
        if (%results.every(%result =&gt; %result.state === "granted")) {
          %sensor.start();
          ...
        } else {
          console.log("AbsoluteOrientationSensor を利用する許可はありません。");
        }
  });
</pre>
<!-- No permissions to use AbsoluteOrientationSensor -->

<p>
単純に
`start()$m を~callして `onerror$m `~event~handler$を~~登録する，別の~approachもある。
◎
Another approach is to simply call start() and subscribe to onerror event handler.
</p>

<pre class="lang-js">
const %sensor = new AbsoluteOrientationSensor();
%sensor.onerror = %event =&gt; {
  if (%event.error.name === 'NotAllowedError')
    console.log("AbsoluteOrientationSensor を利用する許可はありません。");
};
%sensor.start();
</pre>
<!-- No permissions to use AbsoluteOrientationSensor -->
</div>

		<section id="absoluteorientationsensor-model">
<h3 title="The AbsoluteOrientationSensor Model">5.1. `AbsoluteOrientationSensor^I の~model</h3>

<p>
`~sensor型$
`絶対~方位~sensor@i
は、
`MOTION-SENSORS$r `§ 絶対~方位~sensor＠~MOTION-SENSORS#absolute-orientation$
にて述べられる~sensorを表現する：
◎
The Absolute Orientation Sensor sensor type represents the sensor described in Motion Sensors Explainer § absolute-orientation.＼
</p>
<ul>
	<li>
その`拡張~sensor~interface$は、
`OrientationSensor$I の下位class `AbsoluteOrientationSensor$I である。
◎
Its associated extension sensor interface is AbsoluteOrientationSensor, a subclass of OrientationSensor.＼
</li>
	<li>
それが`属する~virtual~sensor型$は、
`absolute-orientation$vsT とする。
◎
Its associated virtual sensor type is "absolute-orientation".
</li>
</ul>

<p>
絶対~方位~sensor用の`最新な読取り~map$[ `quaternion^l ] の値は、
3 次元な~Cartesian座標系として定義される
`地球の基準~座標系@
との関係で，~deviceの`局所~座標系$の回転を表現する
— ここで、
地球の基準~座標系の：
◎
For the absolute orientation sensor the value of latest reading["quaternion"] represents the rotation of a device’s local coordinate system in relation to the Earth’s reference coordinate system defined as a three dimensional Cartesian coordinate system (x, y, z), where:
</p>

<ul>
	<li>
~x軸は、 ~y, ~z の~vector-productであり、地面に接していて東を指す。
◎
x-axis is a vector product of y.z that is tangential to the ground and points east,
</li>
	<li>
~y軸は、地面に接していて磁北（ `magnetic north^en 【~compassの針が指す向き】）を指す。
◎
y-axis is tangential to the ground and points towards magnetic north, and
</li>
	<li>
~z軸は、~x軸, ~y軸が成す平面に垂直であり，天を指す。
◎
z-axis points towards the sky and is perpendicular to the plane made up of x and y axes.
</li>
</ul>

<p>
~deviceの`局所~座標系$は、`低level$~motion~sensor用に定義されるそれと同じである。
それは、`~device座標系$にも`~screen座標系$にもなり得る。
◎
The device’s local coordinate system is the same as defined for the low-level motion sensors. It can be either the device coordinate system or the screen coordinate system.
</p>

<p class="note">注記：
下の図は、~deviceの`局所~座標系$と`地球の基準~座標系$が整列される事例を表現する
— したがって，方位~sensorの`最新な読取り~map$は、各~軸~周りに 0 rad `SI$r の回転を表現することになる。
◎
Note: Figure below represents the case where device’s local coordinate system and the Earth’s reference coordinate system are aligned, therefore, orientation sensor’s latest reading would represent 0 (rad) [SI] rotation about each axis.
</p>

<p class="alt" hidden id="_dgm-absolute_orientation_sensor_coordinate_system">
`AbsoluteOrientationSensor^I 座標系。
◎
AbsoluteOrientationSensor coordinate system.
</p>

		</section>
		<section id="relativeorientationsensor-model">
<h3 title="The RelativeOrientationSensor Model">5.2. `RelativeOrientationSensor^I ~model</h3>

<p>
`~sensor型$
`相対~方位~sensor@i
は、
`MOTION-SENSORS$r `§ 相対~方位~sensor＠~MOTION-SENSORS#relative-orientation$
にて述べられる~sensorを表現する：
◎
The Relative Orientation Sensor sensor type represents the sensor described in Motion Sensors Explainer § relative-orientation.＼
</p>
<ul>
	<li>
それに結付けられる`拡張~sensor~interface$は、
`OrientationSensor$I の下位class `RelativeOrientationSensor$I である。
◎
Its associated extension sensor interface is RelativeOrientationSensor, a subclass of OrientationSensor.＼
</li>
	<li>
それが`属する~virtual~sensor型$は、
`relative-orientation$vsT とする。
◎
Its associated virtual sensor type is "relative-orientation".
</li>
</ul>

<p>
相対~方位~sensor用の`最新な読取り~map$[ `quaternion^l ] の値は、`~stationary基準~座標系$との関係で，~deviceの`局所~座標系$の回転を表現する。
`~stationary基準~座標系$は、~gyroscope~sensorが導入する偏りに因り，次第にずれ得る
— その結果、~sensorが供する回転~値も次第にずれ得る。
◎
For the relative orientation sensor the value of latest reading["quaternion"] represents the rotation of a device’s local coordinate system in relation to a stationary reference coordinate system. The stationary reference coordinate system may drift due to the bias introduced by the gyroscope sensor, thus, the rotation value provided by the sensor, may drift over time.
</p>

<p>
`~stationary基準~座標系@
は、［
~sensorを~hostしている~deviceが環境の中で移動しても，~stationaryであり続ける
］ような， 3 次元な~Cartesian慣性-座標系として定義される。
◎
The stationary reference coordinate system is defined as an inertial three dimensional Cartesian coordinate system that remains stationary as the device hosting the sensor moves through the environment.
</p>

<p>
~deviceの`局所~座標系$は、`低level$な~motion~sensor用に定義されるそれと同じであり，`~device座標系$にも`~screen座標系$にもなり得る。
◎
The device’s local coordinate system is the same as defined for the low-level motion sensors. It can be either the device coordinate system or the screen coordinate system.
</p>

<p class="note">注記：
相対~方位~sensor~dataは、絶対~方位~sensorが供するものより正確aになることもある
— ~sensorは，磁場により影響されないので。
◎
Note: The relative orientation sensor data could be more accurate than the one provided by absolute orientation sensor, as the sensor is not affected by magnetic fields.
</p>

		</section>
	</section>
	<section id="api">
<h2 title="API">6. ~API</h2>

		<section id="orientationsensor-interface">
<h3 title="The OrientationSensor Interface">6.1. `OrientationSensor^I ~interface</h3>

<pre class="idl">
typedef (`Float32Array$ or `Float64Array$ or `DOMMatrix$I) `RotationMatrixType@I;

[`SecureContext$, `Exposed$=Window]
interface `OrientationSensor@I : `Sensor$I {
  readonly attribute `FrozenArray$&lt;`double$&gt;? `quaternion@m;
  `undefined$ `populateMatrix@m(`RotationMatrixType$I %targetMatrix);
};

enum `OrientationSensorLocalCoordinateSystem@I { `device@l, `screen@l };

dictionary `OrientationSensorOptions@I : `SensorOptions$I {
  `OrientationSensorLocalCoordinateSystem$I `referenceFrame@mb = "device";
};
</pre>

<div class="algo" id="orientationsensor-quaternion">
`quaternion@m
属性は、~device方位を表現している単位~四元数を成す 4 個の成分からなる`凍結d配列$を返す。
その取得子~手続きは
⇒
~RET `最新な読取り~mapから値を取得する$( コレ, `quaternion^l )
◎
6.1.1. OrientationSensor.quaternion
◎
Returns a four-element FrozenArray whose elements contain the components of the unit quaternion representing the device orientation.＼
◎
In other words, this attribute returns the result of invoking get value from latest reading with this and "quaternion" as arguments.
</div>

<div class="algo">
<p id="orientationsensor-populatematrix">
`populateMatrix(targetMatrix)@m
~method手続きは：
◎
6.1.2. OrientationSensor.populateMatrix()
◎
The populateMatrix(targetMatrix) method steps are:
</p>
<ol>
	<li>
%種別 ~LET %targetMatrix に応じて
⇒＃
`Float32Array$I であるならば `配列^i ／
`Float64Array$I であるならば `配列^i ／
`DOMMatrix$I であるならば `行列^i
◎
↓</li>
	<li>
~IF［
%種別 ~EQ `配列^i
］~AND［
%targetMatrix の~size ~LT 16
］
⇒
~THROW `TypeError$E
◎
If targetMatrix is of type Float32Array or Float64Array with a size less than sixteen, throw a "TypeError" exception and abort these steps.
</li>
	<li>
%四元数 ~LET `最新な読取り~mapから値を取得する$( コレ, `quaternion^l )
◎
Let quaternion be the result of invoking get value from latest reading with this and "quaternion" as arguments.
</li>
	<li>
~IF［
%四元数 ~EQ ~NULL
］
⇒
~THROW `NotReadableError$E
◎
If quaternion is null, throw a "NotReadableError" DOMException and abort these steps.
</li>
	<li>
%回転~行列 ~LET `四元数を回転~行列に変換する$( %四元数 )
◎
Let rotationMatrix be the result of converting a quaternion to rotation matrix with quaternion[0], quaternion[1], quaternion[2], and quaternion[3].
</li>
	<li>
~IF［
%種別 ~EQ `配列^i
］
⇒
~EACH( 整数 %i ~IN { 0 〜 15 } )
に対し
⇒
%targetMatrix[ %i ] ~SET %回転~行列[ %i ]
◎
If targetMatrix is of Float32Array or Float64Array type, run these sub-steps:
• Set targetMatrix[0] = rotationMatrix[0]
• Set targetMatrix[1] = rotationMatrix[1]
• Set targetMatrix[2] = rotationMatrix[2]
• Set targetMatrix[3] = rotationMatrix[3]
• Set targetMatrix[4] = rotationMatrix[4]
• Set targetMatrix[5] = rotationMatrix[5]
• Set targetMatrix[6] = rotationMatrix[6]
• Set targetMatrix[7] = rotationMatrix[7]
• Set targetMatrix[8] = rotationMatrix[8]
• Set targetMatrix[9] = rotationMatrix[9]
• Set targetMatrix[10] = rotationMatrix[10]
• Set targetMatrix[11] = rotationMatrix[11]
• Set targetMatrix[12] = rotationMatrix[12]
• Set targetMatrix[13] = rotationMatrix[13]
• Set targetMatrix[14] = rotationMatrix[14]
• Set targetMatrix[15] = rotationMatrix[15]
</li>
	<li>
~ELSE（ %種別 ~EQ `行列^i ）
⇒
`行列を~3D行列に初期化する$( %targetMatrix, %回転~行列 )
◎
If targetMatrix is of DOMMatrix type, run these sub-steps:
• Set targetMatrix.m11 = rotationMatrix[0]
• Set targetMatrix.m12 = rotationMatrix[1]
• Set targetMatrix.m13 = rotationMatrix[2]
• Set targetMatrix.m14 = rotationMatrix[3]
• Set targetMatrix.m21 = rotationMatrix[4]
• Set targetMatrix.m22 = rotationMatrix[5]
• Set targetMatrix.m23 = rotationMatrix[6]
• Set targetMatrix.m24 = rotationMatrix[7]
• Set targetMatrix.m31 = rotationMatrix[8]
• Set targetMatrix.m32 = rotationMatrix[9]
• Set targetMatrix.m33 = rotationMatrix[10]
• Set targetMatrix.m34 = rotationMatrix[11]
• Set targetMatrix.m41 = rotationMatrix[12]
• Set targetMatrix.m42 = rotationMatrix[13]
• Set targetMatrix.m43 = rotationMatrix[14]
• Set targetMatrix.m44 = rotationMatrix[15]
</li>
</ol>
</div>

		</section>
		<section id="absoluteorientationsensor-interface">
<h3 title="The AbsoluteOrientationSensor Interface">6.2. `AbsoluteOrientationSensor^I ~interface</h3>

<pre class="idl">
[`SecureContext$, `Exposed$=Window]
interface `AbsoluteOrientationSensor@I : `OrientationSensor$I {
  `AbsoluteOrientationSensor$mc(optional `OrientationSensorOptions$I %sensorOptions = {});
};
</pre>

<div class="algo">
`new AbsoluteOrientationSensor@m
構築子~手続きは
⇒
`方位~sensor~objを初期化する$( コレ )
◎
To construct an AbsoluteOrientationSensor object the user agent must invoke the construct an orientation sensor object abstract operation for the AbsoluteOrientationSensor interface.
</div>

<p>
`AbsoluteOrientationSensor$I が`~supportする~sensor~option群$は
⇒
`frequency^l,
`referenceFrame^l
◎
Supported sensor options for AbsoluteOrientationSensor are "frequency" and "referenceFrame".
</p>

		</section>
		<section id="relativeorientationsensor-interface">
<h3 title="The RelativeOrientationSensor Interface">6.3. `RelativeOrientationSensor^I ~interface</h3>

<pre class="idl">
[`SecureContext$, `Exposed$=Window]
interface `RelativeOrientationSensor@I : `OrientationSensor$I {
  `RelativeOrientationSensor$mc(optional `OrientationSensorOptions$I %sensorOptions = {});
};
</pre>

<div class="algo">
`new RelativeOrientationSensor@m
構築子~手続きは
⇒
`方位~sensor~objを初期化する$( コレ )
◎
To construct a RelativeOrientationSensor object the user agent must invoke the construct an orientation sensor object abstract operation for the RelativeOrientationSensor interface.
</div>

<p>
`RelativeOrientationSensor$I が`~supportする~sensor~option群$は
⇒
`frequency^l,
`referenceFrame^l
◎
Supported sensor options for RelativeOrientationSensor are "frequency" and "referenceFrame".
</p>

		</section>
	</section>
	<section id="abstract-operations">
<h2 title="Abstract Operations">7. 抽象-演算</h2>

<div class="algo">
<p>
`方位~sensor~objを初期化する@
ときは、所与の
( %方位, %~option群 )
に対し：
◎
7.1. Construct an Orientation Sensor object
</p>
<ol>
	<li>
~Assert：
%方位 は `OrientationSensor$I ~interfaceを実装する
◎
input
• orientation_interface, an interface identifier whose inherited interfaces contains OrientationSensor.
</li>
	<li>
~Assert：
%~option群 は `OrientationSensorOptions$I 辞書である
◎
• options, a OrientationSensorOptions object.
◎
output
• An OrientationSensor object.
</li>
	<li>
~IF［
`~sensor施策により制御される特能を検査する$( `方位~sensor$i ) ~EQ ~F
］
⇒
~THROW `SecurityError$E
◎
Let allowed be the result of invoking check sensor policy-controlled features with the interface identified by orientation_interface.
◎
If allowed is false, then:
• Throw a SecurityError DOMException.
</li>
	<li>
`~sensor~objを初期化する$( %方位, %~option群 )
◎
Let orientation be a new instance of the interface identified by orientation_interface.
◎
Invoke initialize a sensor object with orientation and options.
</li>
	<li>
%方位 用の`局所~座標系$を
%~option群[ "`referenceFrame$mb" ]
に応じて，次で定義する
⇒＃
`screen^l ならば `~screen座標系$／
`device^l ならば `~device座標系$
◎
If options.referenceFrame is "screen", then:
• Define local coordinate system for orientation as the screen coordinate system.
◎
Otherwise, define local coordinate system for orientation as the device coordinate system.
◎
Return orientation.
</li>
</ol>

<p class="trans-note">【
原文の この~algoは，新たな~instanceを作成して返しているが、
`WEBIDL$r の`構築子~手続き$の規約に則って，この訳では初期化のみ行うよう改めている。
】</p>
</div>

<div class="algo">
<p id="convert-quaternion-to-rotation-matrix">
`四元数を回転~行列に変換する@
ときは、
所与の
( `~list$ %四元数 )
に対し：
</p>

<p class="note">注記：
これは、
`上で述べた回転~行列＠#_quaternion-rotation-matrix$を列主導順な~listで表現して返す。
</p>

<ol>
	<li>
~Assert：
［
%四元数 の`~size$ ~EQ 4
］~AND［
%四元数 を成す各~itemは，いずれも~numberである
］
</li>
	<li>
( %x, %y, %z, %w ) ~LET ( %四元数[ 0 ], %四元数[ 1 ], %四元数[ 2 ], %四元数[ 3 ] )
</li>
	<li>
~RET « 次に挙げる 16 個の~item »
⇒＃
1 ~MINUS 2 ~MUL %y ~MUL %y ~MINUS 2 ~MUL %z ~MUL %z,
2 ~MUL %x ~MUL %y ~MINUS 2 ~MUL %z ~MUL %w,
2 ~MUL %x ~MUL %z + 2 ~MUL %y ~MUL %w,
0,
2 ~MUL %x ~MUL %y + 2 ~MUL %z ~MUL %w,
1 ~MINUS 2 ~MUL %x ~MUL %x ~MINUS 2 ~MUL %z ~MUL %z,
2 ~MUL %y ~MUL %z ~MINUS 2 ~MUL %x ~MUL %w,
0,
2 ~MUL %x ~MUL %z ~MINUS 2 ~MUL %y ~MUL %w,
2 ~MUL %y ~MUL %z + 2 ~MUL %x ~MUL %w,
1 ~MINUS 2 ~MUL %x ~MUL %x ~MINUS 2 ~MUL %y ~MUL %y,
0,
0,
0,
0,
1
</li>
</ol>

◎
7.2. Convert quaternion to rotation matrix
◎
↑↑ The convert a quaternion to rotation matrix algorithm creates a list representation of a rotation matrix in column-major order converted from a quaternion [QUATCONV], as shown below:
◎
↑↑ Converting quaternion to rotation matrix.
◎
To convert a quaternion to rotation matrix given a number x, a number y, a number z, and a number w:
◎
• Let m11 be 1 - 2 * y * y - 2 * z * z
• Let m12 be 2 * x * y - 2 * z * w
• Let m13 be 2 * x * z + 2 * y * w
• Let m14 be 0
• Let m21 be 2 * x * y + 2 * z * w
• Let m22 be 1 - 2 * x * x - 2 * z * z
• Let m23 be 2 * y * z - 2 * x * w
• Let m24 be 0
• Let m31 be 2 * x * z - 2 * y * w
• Let m32 be 2 * y * z + 2 * x * w
• Let m33 be 1 - 2 * x * x - 2 * y * y
• Let m34 be 0
• Let m41 be 0
• Let m42 be 0
• Let m43 be 0
• Let m44 be 1
• Return « m11, m12, m13, m14, m21, m22, m23, m24, m31, m32, m33, m34, m41, m42, m43, m44 ».
</div>

<div class="algo">
<p id="helper-create-quaternion-from-euler-angles">
`~Euler角度から四元数を作成する@
ときは、
所与の
( ~number %~alpha, ~number %~beta, ~number %~gamma )
に対し：
◎
7.3. Create a quaternion from Euler angles
◎
To create a quaternion from Euler angles given a number alpha, a number beta and a number gamma:
</p>

<ol>
	<li>
( %~alpha, %~beta, %~gamma ) ~SET 順に，
( %~alpha, %~beta, %~gamma ) を度d数から~radian数へ換算した結果
◎
Let alphaInRadians be alpha converted from degrees to radians.
◎
Let betaInRadians be beta converted from degrees to radians.
◎
Let gammaInRadians be gamma converted from degrees to radians.
</li>
	<li>
%cosZ ~LET `cos^op( 0.5 ~MUL %~alpha )
◎
Let cosZ be the cosine of (0.5 * alphaInRadians).
</li>
	<li>
%sinZ ~LET `sin^op( 0.5 ~MUL %~alpha )
◎
Let sinZ be the sine of (0.5 * alphaInRadians).
</li>
	<li>
%cosX ~LET `cos^op( 0.5 ~MUL %~beta )
◎
Let cosX be the cosine of (0.5 * betaInRadians).
</li>
	<li>
%sinX ~LET `sin^op( 0.5 ~MUL %~beta )
◎
Let sinX be the sine of (0.5 * betaInRadians).
</li>
	<li>
%cosY ~LET `cos^op( 0.5 ~MUL %~gamma )
◎
Let cosY be the cosine of (0.5 * gammaInRadians).
</li>
	<li>
%sinY ~LET `sin^op( 0.5 ~MUL %~gamma )
◎
Let sinY be the sine of (0.5 * gammaInRadians).
</li>
	<li>
<p>
~RET « 次に挙げる 4 個の~item »
⇒＃
%sinX ~MUL %cosY ~MUL %cosZ ~MINUS %cosX ~MUL %sinY ~MUL %sinZ,
%cosX ~MUL %sinY ~MUL %cosZ ~PLUS %sinX ~MUL %cosY ~MUL %sinZ,
%cosX ~MUL %cosY ~MUL %sinZ ~PLUS %sinX ~MUL %sinY ~MUL %cosZ,
%cosX ~MUL %cosY ~MUL %cosZ ~MINUS %sinX ~MUL %sinY ~MUL %sinZ
</p>
<p>
（順に，四元数の［
~x, ~y, ~z, ~w
］成分を与える。）
</p>
◎
Let quaternionX be (sinX * cosY * cosZ - cosX * sinY * sinZ).
◎
Let quaternionY be (cosX * sinY * cosZ + sinX * cosY * sinZ).
◎
Let quaternionZ be (cosX * cosY * sinZ + sinX * sinY * cosZ).
◎
Let quaternionW be (cosX * cosY * cosZ - sinX * sinY * sinZ).
◎
Return « quaternionX, quaternionY, quaternionZ, quaternionW ».
</li>
</ol>
</div>

	</section>
	<section id="automation">
<h2 title="Automation">8. 自動化</h2>

<p>
この節では、
`GENERIC-SENSOR$r に定義される`自動化＠~SENSORS#automation$を拡張する
— `方位~sensor$i に特有な`~virtual~sensor~metadata$を供することにより。
◎
This section extends Generic Sensor API § 9 Automation by providing Orientation Sensor-specific virtual sensor metadata.
</p>

		<section id="modifications-to-other-specifications">
<h3 title="Modifications to other specifications">8.1. 他の仕様に対する改変</h3>

<p>
この仕様は、
次に従って
`ORIENTATION-EVENT$r `§ 自動化＠~DEVICEORIENTATION#automation$
を統合する。
◎
This specification integrates with DeviceOrientation Event Specification § automation as follows.
</p>

<div class="algo">
`方位~data読取りを構文解析する$
~algoは、［
%読取り を返す段（最後の段）の直前に，次を遂行する段を追加する
］よう改変される
⇒
%読取り[ `quaternion^l ] ~SET `~Euler角度から四元数を作成する$( %読取り[ `alpha^l ], %読取り[ `beta^l ], %読取り[ `gamma^l ] )
◎
The parse orientation data reading algorithm is modified as follows:
• Add the following steps after setting reading’s "alpha", "beta", and "gamma" keys and before returning reading:
•• Set reading["quaternion"] to the result of invoking create a quaternion from Euler angles with reading["alpha"], reading["beta"], and reading["gamma"].
</div>

<p class="note">注記：
この仕様は、
現時点では，
`WebDriver＠https://w3c.github.io/webdriver/$cite
において四元数を直に指定するための
（したがって，四元数から~Euler角度を導出するための）
仕方を供さない。
この裁定が為されたわけは、
単純さを得るための他に，［
自動化の利用者は，入力として~Euler角度で作業する
（あるいは，自前で、
特定の四元数~値を選び取って，対応する~Euler角度の値を供する）
見込みがずっと高い
］ことが前提にある。
異なる利用事例で，四元数~値を直に供せるようにすることに関心がある利用者は、
`この仕様の課題~追跡器＠https://github.com/w3c/orientation-sensor/issues$
を介して~feedbackを寄せられたし。
◎
Note: This specification does not currently provide a way for specifying quaternions in WebDriver (and consequently deriving Euler angles from the quaternion) directly. This decision was made for simplicity and under the assumption that automation users are much more likely to work with Euler angles as inputs (or pick specific quaternion values and provide the corresponding Euler angle values on their own). Feedback from users with different use cases who are interested in being able to provide quaternion values directly is welcome via this specification’s issue tracker.
</p>

		</section>
		<section id="absolute-orientation-sensor-automation">
<h3 title="Absolute Orientation Sensor automation">8.2. 絶対~方位~sensorの自動化</h3>

<p>
`絶対~方位~sensor$i が`属する~virtual~sensor型$ `absolute-orientation$vsT,
それに対応する［
`型ごとの~virtual~sensor~metadata$を成す`~entry$map
］は、
`ORIENTATION-EVENT$r `§ 自動化＠~DEVICEORIENTATION#automation$
にて定義される。
◎
The absolute-orientation virtual sensor type and its corresponding entry in the per-type virtual sensor metadata map are defined in DeviceOrientation Event Specification § automation.
</p>

		</section>
		<section id="relative-orientation-sensor-automation">
<h3 title="Relative Orientation Sensor automation">8.3. 相対~方位~sensorの自動化</h3>

<p>
`相対~方位~sensor$i が`属する~virtual~sensor型$ `relative-orientation$vsT,
それに対応する［
`型ごとの~virtual~sensor~metadata$を成す`~entry$map
］は、
`ORIENTATION-EVENT$r `§ 自動化＠~DEVICEORIENTATION#automation$
にて定義される。
◎
The relative-orientation virtual sensor type and its corresponding entry in the per-type virtual sensor metadata map are defined in DeviceOrientation Event Specification § automation.
</p>

		</section>
	</section>
	<section id="acknowledgements">
<h2 title="Acknowledgements">謝辞</h2>

<p>
汎用~sensor~APIの作業を為された `Tobie Langel^en 氏に。
◎
Tobie Langel for the work on Generic Sensor API.
</p>

	</section>
</main></div>
